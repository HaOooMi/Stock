"""
ä»InfluxDBå¯¼å‡ºè‚¡ç¥¨æ•°æ®åˆ°CSVæ–‡ä»¶
ç”¨äºVeighNaæ‰‹åŠ¨å¯¼å…¥
"""
import sys
import os
from datetime import datetime, timedelta
import pandas as pd

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

# å¯¼å…¥InfluxDBæ•°æ®æ¨¡å—
try:
    import utils
    from stock_market_data_akshare import get_history_data
    INFLUXDB_AVAILABLE = True
    print("âœ… InfluxDBæ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    INFLUXDB_AVAILABLE = False
    print(f"âŒ InfluxDBæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")


def export_stock_data_to_csv(symbol: str, start_date: str = "2022-01-01", end_date: str = "2023-12-31", output_dir: str = "csv_data"):
    """
    ä»InfluxDBå¯¼å‡ºè‚¡ç¥¨æ•°æ®åˆ°CSVæ–‡ä»¶
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ '000001'
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
        output_dir: è¾“å‡ºç›®å½•
    """
    if not INFLUXDB_AVAILABLE:
        print("âŒ InfluxDBæ¨¡å—ä¸å¯ç”¨")
        return False
    
    try:
        print(f"ğŸš€ å¼€å§‹å¯¼å‡ºè‚¡ç¥¨ {symbol} æ•°æ®...")
        
        # è·å–InfluxDBå®¢æˆ·ç«¯
        client = utils.get_influxdb_client()
        if client is None:
            print("âŒ æ— æ³•è¿æ¥åˆ°InfluxDB")
            return False
        
        query_api = client.query_api()
        
        # è½¬æ¢æ—¥æœŸæ ¼å¼
        start_str_rfc = f"{start_date}T00:00:00Z"
        end_str_rfc = f"{end_date}T23:59:59Z"
        
        # è·å–å†å²æ•°æ®
        df = get_history_data(query_api, symbol, start_str_rfc, end_str_rfc)
        
        if df.empty:
            print(f"âŒ InfluxDBä¸­æœªæ‰¾åˆ° {symbol} çš„æ•°æ®")
            return False
        
        # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯datetimeç±»å‹å¹¶æ’åº
        if 'æ—¥æœŸ' in df.columns:
            df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
            df = df.sort_values('æ—¥æœŸ').reset_index(drop=True)
        
        print(f"âœ… æˆåŠŸè·å– {len(df)} æ¡ {symbol} æ•°æ®")
        print(f"ğŸ“… æ•°æ®æ—¶é—´èŒƒå›´: {df['æ—¥æœŸ'].min().date()} åˆ° {df['æ—¥æœŸ'].max().date()}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆåœ¨å½“å‰æ–‡ä»¶å¤¹å†…ï¼‰
        script_dir = os.path.dirname(os.path.abspath(__file__))
        output_path_full = os.path.join(script_dir, output_dir)
        os.makedirs(output_path_full, exist_ok=True)
        
        # å‡†å¤‡VeighNaæ ‡å‡†CSVæ ¼å¼æ•°æ®
        vnpy_df = df.copy()
        
        # é‡å‘½ååˆ—ä»¥ç¬¦åˆVeighNaæ ‡å‡†
        column_mapping = {
            'æ—¥æœŸ': 'datetime',
            'å¼€ç›˜': 'open',
            'æœ€é«˜': 'high', 
            'æœ€ä½': 'low',
            'æ”¶ç›˜': 'close',
            'æˆäº¤é‡': 'volume',
            'æˆäº¤é¢': 'turnover'
        }
        
        vnpy_df = vnpy_df.rename(columns=column_mapping)
        
        # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
        required_columns = ['datetime', 'open', 'high', 'low', 'close', 'volume']
        for col in required_columns:
            if col not in vnpy_df.columns:
                print(f"âŒ ç¼ºå°‘å¿…è¦åˆ—: {col}")
                return False
        
        # æ·»åŠ å…¶ä»–VeighNaéœ€è¦çš„åˆ—
        if 'turnover' not in vnpy_df.columns:
            vnpy_df['turnover'] = 0.0
        
        vnpy_df['open_interest'] = 0  # è‚¡ç¥¨æ²¡æœ‰æŒä»“é‡ï¼Œè®¾ä¸º0
        
        # æ ¼å¼åŒ–æ—¥æœŸæ—¶é—´
        vnpy_df['datetime'] = vnpy_df['datetime'].dt.strftime('%Y-%m-%d %H:%M:%S')
        
        # é€‰æ‹©å’Œæ’åºåˆ—
        final_columns = ['datetime', 'open', 'high', 'low', 'close', 'volume', 'turnover', 'open_interest']
        vnpy_df = vnpy_df[final_columns]
        
        # ç”Ÿæˆæ–‡ä»¶å
        exchange = 'SZSE' if symbol.startswith('00') or symbol.startswith('30') else 'SSE'
        filename = f"{symbol}.{exchange}_d_{start_date}_{end_date}.csv"
        csv_output_path = os.path.join(output_path_full, filename)
        
        # ä¿å­˜CSVæ–‡ä»¶
        vnpy_df.to_csv(csv_output_path, index=False, encoding='utf-8')
        
        print(f"âœ… æ•°æ®å·²å¯¼å‡ºåˆ°: {csv_output_path}")
        print(f"ğŸ“Š å¯¼å‡ºäº† {len(vnpy_df)} æ¡è®°å½•")
        
        # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
        print("\nğŸ“‹ æ•°æ®é¢„è§ˆï¼ˆå‰5è¡Œï¼‰:")
        print(vnpy_df.head().to_string(index=False))
        
        # æ˜¾ç¤ºVeighNaå¯¼å…¥è¯´æ˜
        print(f"\nğŸ’¡ VeighNaå¯¼å…¥é…ç½®ï¼š")
        print(f"ğŸ“ é€‰æ‹©æ–‡ä»¶: {csv_output_path}")
        print(f"ğŸ·ï¸ ä»£ç : {symbol}")
        print(f"ğŸ¢ äº¤æ˜“æ‰€: {exchange}")
        print(f"ğŸ“… å‘¨æœŸ: DAILY (æ”¹æˆDAILYï¼Œä¸æ˜¯MINUTE)")
        print(f"ğŸŒ æ—¶åŒº: Asia/Shanghai")
        print(f"â° æ—¶é—´æ ¼å¼: %Y-%m-%d %H:%M:%S")
        print(f"ğŸ“‹ å­—æ®µæ˜ å°„: ä¿æŒé»˜è®¤")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def batch_export_stocks(symbols: list, start_date: str = "2022-01-01", end_date: str = "2023-12-31", output_dir: str = "csv_data"):
    """æ‰¹é‡å¯¼å‡ºå¤šåªè‚¡ç¥¨æ•°æ®"""
    print(f"\nğŸ”„ å¼€å§‹æ‰¹é‡å¯¼å‡º {len(symbols)} åªè‚¡ç¥¨æ•°æ®...")
    print(f"ğŸ“… æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    success_count = 0
    failed_symbols = []
    
    for i, symbol in enumerate(symbols, 1):
        print(f"\n[{i}/{len(symbols)}] å¤„ç†è‚¡ç¥¨: {symbol}")
        
        if export_stock_data_to_csv(symbol, start_date, end_date, output_dir):
            success_count += 1
        else:
            failed_symbols.append(symbol)
    
    print(f"\n{'='*60}")
    print(f"\nğŸ“Š æ‰¹é‡å¯¼å‡ºç»“æœï¼š")
    print(f"âœ… æˆåŠŸ: {success_count}/{len(symbols)}")
    print(f"âŒ å¤±è´¥: {len(failed_symbols)}")
    
    if failed_symbols:
        print(f"å¤±è´¥çš„è‚¡ç¥¨: {', '.join(failed_symbols)}")
    
    # æ˜¾ç¤ºå®Œæ•´è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    full_output_path = os.path.join(script_dir, output_dir)
    print(f"ğŸ“ æ‰€æœ‰CSVæ–‡ä»¶ä¿å­˜åœ¨: {full_output_path}")
    print(f"{'='*60}")


if __name__ == "__main__":
    print("ğŸš€ InfluxDBè‚¡ç¥¨æ•°æ®CSVå¯¼å‡ºå·¥å…·")
    print("=" * 50)
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not INFLUXDB_AVAILABLE:
        print("âŒ InfluxDBæ¨¡å—ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥å®‰è£…")
        exit(1)
    
    # å•åªè‚¡ç¥¨å¯¼å‡ºç¤ºä¾‹
    print("\nğŸ“‹ å•åªè‚¡ç¥¨å¯¼å‡ºç¤ºä¾‹ï¼š")
    symbol = "000001"  # å¹³å®‰é“¶è¡Œ
    success = export_stock_data_to_csv(
        symbol=symbol,
        start_date="2022-01-01",
        end_date="2024-12-31",
        output_dir="csv_data"
    )
    
    if success:
        print(f"\nğŸ‰ {symbol} æ•°æ®å¯¼å‡ºå®Œæˆï¼")
        print(f"\nğŸš€ ä½¿ç”¨æ­¥éª¤ï¼š")
        print(f"1. è¿è¡Œå¯¼å‡ºè„šæœ¬ âœ…")
        print(f"2. åœ¨VeighNaä¸­å¯¼å…¥CSVæ•°æ®:")
        print(f"   ğŸ“ é€‰æ‹©æ–‡ä»¶: ç”Ÿæˆçš„CSVæ–‡ä»¶")
        print(f"   ğŸ·ï¸ ä»£ç : {symbol}")
        print(f"   ğŸ¢ äº¤æ˜“æ‰€: SZSE (æ·±äº¤æ‰€)")
        print(f"   ğŸ“… å‘¨æœŸ: DAILY (é‡è¦ï¼šæ”¹æˆDAILY)")
        print(f"   ğŸŒ æ—¶åŒº: Asia/Shanghai")
        print(f"   ğŸ“‹ å­—æ®µæ˜ å°„: ä¿æŒé»˜è®¤")
        print(f"   â° æ—¶é—´æ ¼å¼: %Y-%m-%d %H:%M:%S")
        print(f"3. å¯¼å…¥å®Œæˆååœ¨CtaBacktesterå›æµ‹:")
        print(f"   ğŸ¯ ç­–ç•¥é€‰æ‹©: SimpleMAStrategy")
        print(f"   ğŸ·ï¸ æœ¬åœ°ä»£ç : {symbol}.SZSE")
        print(f"   ğŸ“ˆ Kçº¿å‘¨æœŸ: 1d (æ—¥çº¿)")
        print(f"4. ä¼˜åŠ¿:")
        print(f"   âœ… ç»•è¿‡æ•°æ®æœåŠ¡é…ç½®é—®é¢˜")
        print(f"   âœ… ä½¿ç”¨æ‚¨è‡ªå·±çš„InfluxDBæ•°æ®")
        print(f"   âœ… å®Œæ•´çš„VeighNaå›æµ‹å›¾è¡¨åŠŸèƒ½")
        print(f"   âœ… æ•°æ®å¯æ§ï¼Œéšæ—¶æ›´æ–°")
    
    # æ‰¹é‡å¯¼å‡ºç¤ºä¾‹ï¼ˆå–æ¶ˆæ³¨é‡Šä»¥ä½¿ç”¨ï¼‰
    # print("\nğŸ“‹ æ‰¹é‡å¯¼å‡ºç¤ºä¾‹ï¼š")
    # symbols = ["000001", "000002", "600000", "600036"]  # å¤šåªè‚¡ç¥¨
    # batch_export_stocks(
    #     symbols=symbols,
    #     start_date="2022-01-01", 
    #     end_date="2023-12-31",
    #     output_dir="csv_data"
    # )
    
    print("\nâœ¨ ç°åœ¨å¯ä»¥åœ¨VeighNaä¸­æ‰‹åŠ¨å¯¼å…¥è¿™äº›CSVæ–‡ä»¶äº†ï¼")
