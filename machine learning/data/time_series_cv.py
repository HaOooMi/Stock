#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ—¶åºäº¤å‰éªŒè¯æ¨¡å—ï¼ˆPurged + Embargo + Walk-Forwardï¼‰

åŠŸèƒ½ï¼š
1. å•æ¬¡æ—¶é—´åˆ‡åˆ†ï¼ˆtrain/valid/testï¼‰
2. Purgedï¼šè¾¹ç•Œå‰å‰”é™¤ â‰¥ max_horizon å¤©æ ·æœ¬ï¼ˆé¿å…ç›®æ ‡é‡å ï¼‰
3. Embargoï¼šè¾¹ç•Œåç¦æ­¢è‹¥å¹²æ—¥å‚ä¸è¯„ä¼°ï¼ˆé¿å…ä¿¡æ¯æ³„æ¼ï¼‰
4. Walk-Forwardï¼šæ»šåŠ¨æˆ–æ‰©å¼ çª—å£å¤šæŠ˜

è®¾è®¡åŸåˆ™ï¼š
- åªåšç´¢å¼•åˆ‡åˆ†ï¼Œä¸ç¢°ç‰¹å¾/æ ‡ç­¾æœ¬èº«
- æ”¯æŒ MultiIndex [date, ticker] å’Œæ™®é€š DatetimeIndex
- ä¸ configs/ml_baseline.yml ä¸­çš„ split é…ç½®é›†æˆ
- å¯å¤ç”¨äºä»»ä½• pipeline

æ ¸å¿ƒå…¬å¼ï¼ˆPurged + Embargoï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Train       â”‚      Valid      â”‚       Test       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†‘                 â†‘
           è¾¹ç•Œå‰purgeæ—¥       è¾¹ç•Œå‰purgeæ—¥
           è¾¹ç•Œåembargoæ—¥     è¾¹ç•Œåembargoæ—¥

åˆ›å»º: 2025-12-02 | ç‰ˆæœ¬: v1.0
ä½œè€…: AI Assistant
"""

import os
import sys
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Union, Generator
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
ml_root = os.path.dirname(current_dir)
project_root = os.path.dirname(ml_root)
if ml_root not in sys.path:
    sys.path.insert(0, ml_root)


class TimeSeriesCV:
    """
    æ—¶åºäº¤å‰éªŒè¯å™¨
    
    æ”¯æŒï¼š
    1. å•æ¬¡æ—¶é—´åˆ‡åˆ†ï¼ˆå¸¦ Purged + Embargoï¼‰
    2. Walk-Forward å¤šæŠ˜éªŒè¯
    3. æ»šåŠ¨çª—å£ vs æ‰©å¼ çª—å£
    
    å¥‘çº¦ï¼š
    ------
    è¾“å…¥ï¼š
        - data: DataFrame æˆ– Indexï¼Œéœ€åŒ…å«æ—¥æœŸä¿¡æ¯
          - MultiIndex [date, ticker]ï¼šè‡ªåŠ¨æå– date level
          - DatetimeIndexï¼šç›´æ¥ä½¿ç”¨
          - æ™®é€š DataFrameï¼šéœ€æŒ‡å®š date_col
    
    è¾“å‡ºï¼š
        - å•æ¬¡åˆ‡åˆ†ï¼š(train_idx, valid_idx, test_idx)
        - WFAï¼šGenerator[(fold_id, train_idx, valid_idx, test_idx), ...]
    """
    
    def __init__(self,
                 train_ratio: float = 0.6,
                 valid_ratio: float = 0.2,
                 test_ratio: float = 0.2,
                 purge_days: int = 10,
                 embargo_days: int = 5,
                 max_horizon: int = 10):
        """
        åˆå§‹åŒ–æ—¶åº CV
        
        Parameters:
        -----------
        train_ratio : float
            è®­ç»ƒé›†æ¯”ä¾‹ï¼ˆé»˜è®¤ 0.6ï¼‰
        valid_ratio : float
            éªŒè¯é›†æ¯”ä¾‹ï¼ˆé»˜è®¤ 0.2ï¼‰
        test_ratio : float
            æµ‹è¯•é›†æ¯”ä¾‹ï¼ˆé»˜è®¤ 0.2ï¼‰
        purge_days : int
            Purge å¤©æ•°ï¼ˆè¾¹ç•Œå‰å‰”é™¤ï¼Œé¿å…ç›®æ ‡é‡å ï¼‰
            å»ºè®®è®¾ä¸º max(target_horizon)
        embargo_days : int
            Embargo å¤©æ•°ï¼ˆè¾¹ç•Œåç¦æ­¢ï¼Œé¿å…ä¿¡æ¯æ³„æ¼ï¼‰
            å»ºè®®è®¾ä¸º target_horizon / 2
        max_horizon : int
            æœ€å¤§é¢„æµ‹å‘¨æœŸï¼ˆç”¨äºè‡ªåŠ¨è®¡ç®— purge_daysï¼‰
        """
        # éªŒè¯æ¯”ä¾‹
        total_ratio = train_ratio + valid_ratio + test_ratio
        if abs(total_ratio - 1.0) > 0.01:
            raise ValueError(f"åˆ‡åˆ†æ¯”ä¾‹æ€»å’Œå¿…é¡»ä¸º1ï¼Œå½“å‰ä¸º {total_ratio}")
        
        self.train_ratio = train_ratio
        self.valid_ratio = valid_ratio
        self.test_ratio = test_ratio
        self.purge_days = max(purge_days, max_horizon)  # purge è‡³å°‘ä¸º max_horizon
        self.embargo_days = embargo_days
        self.max_horizon = max_horizon
        
        # åˆ‡åˆ†å…ƒæ•°æ®ï¼ˆç”¨äºè®°å½•å’Œå¤ç°ï¼‰
        self.split_meta = {}
        
        print(f"ğŸ“… æ—¶åºCVåˆå§‹åŒ–")
        print(f"   åˆ‡åˆ†æ¯”ä¾‹: {train_ratio:.0%} / {valid_ratio:.0%} / {test_ratio:.0%}")
        print(f"   Purge: {self.purge_days} å¤© | Embargo: {embargo_days} å¤©")
    
    @classmethod
    def from_config(cls, config: dict) -> 'TimeSeriesCV':
        """
        ä»é…ç½®å­—å…¸åˆ›å»ºå®ä¾‹
        
        Parameters:
        -----------
        config : dict
            é…ç½®å­—å…¸ï¼ŒæœŸæœ›åŒ…å« 'split' é”®
            
        Returns:
        --------
        TimeSeriesCV
            å®ä¾‹
        """
        split_cfg = config.get('split', {})
        target_cfg = config.get('target', {})
        
        # ä»é…ç½®è¯»å–å‚æ•°
        train_ratio = split_cfg.get('train_ratio', 0.6)
        valid_ratio = split_cfg.get('valid_ratio', 0.2)
        test_ratio = split_cfg.get('test_ratio', 0.2)
        purge_days = split_cfg.get('purge_days', 10)
        embargo_days = split_cfg.get('embargo_days', 5)
        max_horizon = target_cfg.get('forward_periods', 10)
        
        return cls(
            train_ratio=train_ratio,
            valid_ratio=valid_ratio,
            test_ratio=test_ratio,
            purge_days=purge_days,
            embargo_days=embargo_days,
            max_horizon=max_horizon
        )
    
    def _extract_dates(self, data: Union[pd.DataFrame, pd.Index]) -> pd.DatetimeIndex:
        """
        ä»æ•°æ®ä¸­æå–æ—¥æœŸç´¢å¼•
        
        Parameters:
        -----------
        data : DataFrame æˆ– Index
            è¾“å…¥æ•°æ®
            
        Returns:
        --------
        pd.DatetimeIndex
            å”¯ä¸€æ—¥æœŸåˆ—è¡¨ï¼ˆå·²æ’åºï¼‰
        """
        if isinstance(data, pd.DataFrame):
            index = data.index
        else:
            index = data
        
        # MultiIndex [date, ticker]
        if isinstance(index, pd.MultiIndex):
            if 'date' in index.names:
                dates = index.get_level_values('date').unique()
            else:
                # å‡è®¾ç¬¬ä¸€å±‚æ˜¯æ—¥æœŸ
                dates = index.get_level_values(0).unique()
        # DatetimeIndex
        elif isinstance(index, pd.DatetimeIndex):
            dates = index.unique()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ç´¢å¼•ç±»å‹: {type(index)}")
        
        return pd.DatetimeIndex(dates).sort_values()
    
    def _get_date_boundaries(self, dates: pd.DatetimeIndex) -> Tuple[pd.Timestamp, pd.Timestamp]:
        """
        è®¡ç®— train/valid å’Œ valid/test çš„è¾¹ç•Œæ—¥æœŸ
        
        Parameters:
        -----------
        dates : pd.DatetimeIndex
            å”¯ä¸€æ—¥æœŸåˆ—è¡¨
            
        Returns:
        --------
        Tuple[pd.Timestamp, pd.Timestamp]
            (train_end, valid_end)
        """
        n_dates = len(dates)
        
        train_end_idx = int(n_dates * self.train_ratio) - 1
        valid_end_idx = int(n_dates * (self.train_ratio + self.valid_ratio)) - 1
        
        train_end = dates[train_end_idx]
        valid_end = dates[valid_end_idx]
        
        return train_end, valid_end
    
    def single_split(self, 
                    data: Union[pd.DataFrame, pd.Index],
                    return_masks: bool = False) -> Union[
                        Tuple[pd.Index, pd.Index, pd.Index],
                        Tuple[pd.Series, pd.Series, pd.Series]
                    ]:
        """
        å•æ¬¡æ—¶é—´åˆ‡åˆ†ï¼ˆå¸¦ Purged + Embargoï¼‰
        
        Parameters:
        -----------
        data : DataFrame æˆ– Index
            è¾“å…¥æ•°æ®
        return_masks : bool
            True: è¿”å›å¸ƒå°”æ©ç  (ç”¨äº DataFrame.loc[mask])
            False: è¿”å›ç´¢å¼• (ç”¨äº DataFrame.loc[idx])
            
        Returns:
        --------
        å¦‚æœ return_masks=False:
            Tuple[pd.Index, pd.Index, pd.Index]
                (train_idx, valid_idx, test_idx)
        å¦‚æœ return_masks=True:
            Tuple[pd.Series, pd.Series, pd.Series]
                (train_mask, valid_mask, test_mask)
        """
        print("\n" + "=" * 70)
        print("å•æ¬¡æ—¶é—´åˆ‡åˆ†ï¼ˆPurged + Embargoï¼‰")
        print("=" * 70)
        
        # æå–æ—¥æœŸ
        dates = self._extract_dates(data)
        train_end, valid_end = self._get_date_boundaries(dates)
        
        # è®¡ç®— Purge å’Œ Embargo è¾¹ç•Œ
        # train/valid è¾¹ç•Œ
        train_purge_start = train_end - pd.Timedelta(days=self.purge_days)
        valid_embargo_end = train_end + pd.Timedelta(days=self.embargo_days)
        
        # valid/test è¾¹ç•Œ
        valid_purge_start = valid_end - pd.Timedelta(days=self.purge_days)
        test_embargo_end = valid_end + pd.Timedelta(days=self.embargo_days)
        
        # è®°å½•å…ƒæ•°æ®
        self.split_meta = {
            'mode': 'single_split',
            'train_end': train_end.isoformat(),
            'valid_end': valid_end.isoformat(),
            'purge_days': self.purge_days,
            'embargo_days': self.embargo_days,
            'n_dates': len(dates),
            'date_range': (dates.min().isoformat(), dates.max().isoformat())
        }
        
        # è·å–åŸå§‹ç´¢å¼•
        if isinstance(data, pd.DataFrame):
            original_index = data.index
        else:
            original_index = data
        
        # æ„å»ºæ©ç 
        if isinstance(original_index, pd.MultiIndex):
            date_values = original_index.get_level_values('date')
        else:
            date_values = original_index
        
        # Train: æ—¥æœŸ <= train_purge_startï¼ˆæ’é™¤ purge åŒºé—´ï¼‰
        train_mask = date_values <= train_purge_start
        
        # Valid: valid_embargo_end <= æ—¥æœŸ <= valid_purge_start
        valid_mask = (date_values >= valid_embargo_end) & (date_values <= valid_purge_start)
        
        # Test: æ—¥æœŸ >= test_embargo_end
        test_mask = date_values >= test_embargo_end
        
        # ç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“Š åˆ‡åˆ†ç»Ÿè®¡:")
        print(f"   æ—¥æœŸèŒƒå›´: {dates.min().date()} ~ {dates.max().date()}")
        print(f"   æ€»æ—¥æœŸæ•°: {len(dates)}")
        print(f"\n   Train:")
        print(f"      ç»“æŸ: {train_purge_start.date()} (purgeå‰)")
        print(f"      æ ·æœ¬: {train_mask.sum()}")
        print(f"\n   Valid:")
        print(f"      å¼€å§‹: {valid_embargo_end.date()} (embargoå)")
        print(f"      ç»“æŸ: {valid_purge_start.date()} (purgeå‰)")
        print(f"      æ ·æœ¬: {valid_mask.sum()}")
        print(f"\n   Test:")
        print(f"      å¼€å§‹: {test_embargo_end.date()} (embargoå)")
        print(f"      æ ·æœ¬: {test_mask.sum()}")
        
        # Purge + Embargo é€ æˆçš„æ ·æœ¬æŸå¤±
        total_samples = len(original_index)
        used_samples = train_mask.sum() + valid_mask.sum() + test_mask.sum()
        purged_samples = total_samples - used_samples
        print(f"\n   âš ï¸  Purge+Embargo å‰”é™¤: {purged_samples} æ ·æœ¬ ({purged_samples/total_samples*100:.1f}%)")
        
        if return_masks:
            return (
                pd.Series(train_mask, index=original_index),
                pd.Series(valid_mask, index=original_index),
                pd.Series(test_mask, index=original_index)
            )
        else:
            return (
                original_index[train_mask],
                original_index[valid_mask],
                original_index[test_mask]
            )
    
    def walk_forward_split(self,
                          data: Union[pd.DataFrame, pd.Index],
                          n_splits: int = 5,
                          min_train_days: int = 252,
                          expanding: bool = True) -> Generator[
                              Tuple[int, pd.Index, pd.Index, pd.Index], 
                              None, None
                          ]:
        """
        Walk-Forward éªŒè¯åˆ‡åˆ†
        
        Parameters:
        -----------
        data : DataFrame æˆ– Index
            è¾“å…¥æ•°æ®
        n_splits : int
            æŠ˜æ•°ï¼ˆé»˜è®¤ 5ï¼‰
        min_train_days : int
            æœ€å°è®­ç»ƒæ—¥æ•°ï¼ˆé»˜è®¤ 252ï¼Œçº¦1å¹´ï¼‰
        expanding : bool
            True: æ‰©å¼ çª—å£ï¼ˆè®­ç»ƒé›†ä¸æ–­å¢é•¿ï¼‰
            False: æ»šåŠ¨çª—å£ï¼ˆè®­ç»ƒé›†å¤§å°å›ºå®šï¼‰
            
        Yields:
        -------
        Tuple[int, pd.Index, pd.Index, pd.Index]
            (fold_id, train_idx, valid_idx, test_idx)
        """
        print("\n" + "=" * 70)
        print(f"Walk-Forward éªŒè¯ ({'æ‰©å¼ çª—å£' if expanding else 'æ»šåŠ¨çª—å£'})")
        print("=" * 70)
        
        dates = self._extract_dates(data)
        n_dates = len(dates)
        
        # è®¡ç®—æ¯æŠ˜çš„ valid+test å¤©æ•°
        valid_test_days = int(n_dates * (self.valid_ratio + self.test_ratio))
        valid_days = int(valid_test_days * self.valid_ratio / (self.valid_ratio + self.test_ratio))
        test_days = valid_test_days - valid_days
        
        # æ¯æŠ˜ç§»åŠ¨çš„æ­¥é•¿
        step = (n_dates - min_train_days - valid_test_days) // max(n_splits - 1, 1)
        
        if step <= 0:
            raise ValueError(f"æ•°æ®é‡ä¸è¶³ä»¥è¿›è¡Œ {n_splits} æŠ˜ WFAï¼Œ"
                           f"æ€»æ—¥æœŸæ•°={n_dates}, min_train={min_train_days}, "
                           f"valid+test={valid_test_days}")
        
        # è®°å½•å…ƒæ•°æ®
        self.split_meta = {
            'mode': 'walk_forward',
            'n_splits': n_splits,
            'expanding': expanding,
            'min_train_days': min_train_days,
            'valid_days': valid_days,
            'test_days': test_days,
            'step': step
        }
        
        # è·å–åŸå§‹ç´¢å¼•
        if isinstance(data, pd.DataFrame):
            original_index = data.index
        else:
            original_index = data
        
        if isinstance(original_index, pd.MultiIndex):
            date_values = original_index.get_level_values('date')
        else:
            date_values = original_index
        
        print(f"\nğŸ“Š WFA é…ç½®:")
        print(f"   æ€»æ—¥æœŸæ•°: {n_dates}")
        print(f"   æŠ˜æ•°: {n_splits}")
        print(f"   æ¯æŠ˜æ­¥é•¿: {step} å¤©")
        print(f"   Valid: {valid_days} å¤© | Test: {test_days} å¤©")
        print(f"   Purge: {self.purge_days} å¤© | Embargo: {self.embargo_days} å¤©")
        
        for fold in range(n_splits):
            # è®¡ç®—å½“å‰æŠ˜çš„è¾¹ç•Œ
            if expanding:
                train_start_idx = 0
            else:
                train_start_idx = fold * step
            
            train_end_idx = min_train_days + fold * step - 1
            valid_start_idx = train_end_idx + 1
            valid_end_idx = valid_start_idx + valid_days - 1
            test_start_idx = valid_end_idx + 1
            test_end_idx = test_start_idx + test_days - 1
            
            # è¾¹ç•Œæ£€æŸ¥
            if test_end_idx >= n_dates:
                break
            
            # è·å–è¾¹ç•Œæ—¥æœŸ
            train_start = dates[train_start_idx]
            train_end = dates[train_end_idx]
            valid_start = dates[valid_start_idx]
            valid_end = dates[valid_end_idx]
            test_start = dates[test_start_idx]
            test_end = dates[test_end_idx]
            
            # åº”ç”¨ Purge + Embargo
            train_purge_end = train_end - pd.Timedelta(days=self.purge_days)
            valid_embargo_start = valid_start + pd.Timedelta(days=self.embargo_days)
            valid_purge_end = valid_end - pd.Timedelta(days=self.purge_days)
            test_embargo_start = test_start + pd.Timedelta(days=self.embargo_days)
            
            # æ„å»ºæ©ç 
            train_mask = (date_values >= train_start) & (date_values <= train_purge_end)
            valid_mask = (date_values >= valid_embargo_start) & (date_values <= valid_purge_end)
            test_mask = (date_values >= test_embargo_start) & (date_values <= test_end)
            
            # è·å–ç´¢å¼•
            train_idx = original_index[train_mask]
            valid_idx = original_index[valid_mask]
            test_idx = original_index[test_mask]
            
            print(f"\n   ğŸ“ Fold {fold + 1}/{n_splits}:")
            print(f"      Train: {train_start.date()} ~ {train_purge_end.date()} ({len(train_idx)} æ ·æœ¬)")
            print(f"      Valid: {valid_embargo_start.date()} ~ {valid_purge_end.date()} ({len(valid_idx)} æ ·æœ¬)")
            print(f"      Test:  {test_embargo_start.date()} ~ {test_end.date()} ({len(test_idx)} æ ·æœ¬)")
            
            yield (fold, train_idx, valid_idx, test_idx)
    
    def get_split_meta(self) -> dict:
        """è·å–åˆ‡åˆ†å…ƒæ•°æ®"""
        return self.split_meta.copy()
    
    def validate_no_leakage(self,
                           train_idx: pd.Index,
                           valid_idx: pd.Index,
                           test_idx: pd.Index,
                           target_horizon: int = 5) -> bool:
        """
        éªŒè¯åˆ‡åˆ†æ— æ•°æ®æ³„æ¼
        
        Parameters:
        -----------
        train_idx, valid_idx, test_idx : pd.Index
            åˆ‡åˆ†ç´¢å¼•
        target_horizon : int
            ç›®æ ‡é¢„æµ‹å‘¨æœŸ
            
        Returns:
        --------
        bool
            True = æ— æ³„æ¼
        """
        print("\nğŸ” éªŒè¯æ•°æ®æ³„æ¼...")
        
        # æå–æ—¥æœŸ
        def get_dates(idx):
            if isinstance(idx, pd.MultiIndex):
                return idx.get_level_values('date').unique()
            return idx.unique()
        
        train_dates = get_dates(train_idx)
        valid_dates = get_dates(valid_idx)
        test_dates = get_dates(test_idx)
        
        # æ£€æŸ¥ 1: æ—¥æœŸä¸é‡å 
        train_valid_overlap = len(set(train_dates) & set(valid_dates))
        valid_test_overlap = len(set(valid_dates) & set(test_dates))
        train_test_overlap = len(set(train_dates) & set(test_dates))
        
        if train_valid_overlap > 0 or valid_test_overlap > 0 or train_test_overlap > 0:
            print(f"   âŒ æ—¥æœŸé‡å ! Train-Valid: {train_valid_overlap}, "
                  f"Valid-Test: {valid_test_overlap}, Train-Test: {train_test_overlap}")
            return False
        
        # æ£€æŸ¥ 2: Train çš„æœ€å¤§æ—¥æœŸ + horizon < Valid çš„æœ€å°æ—¥æœŸ
        train_max = train_dates.max()
        valid_min = valid_dates.min()
        gap_train_valid = (valid_min - train_max).days
        
        if gap_train_valid < target_horizon:
            print(f"   âš ï¸  Train-Valid é—´éš”ä¸è¶³: {gap_train_valid} å¤© < {target_horizon} å¤©")
            # ä¸ç«‹å³å¤±è´¥ï¼Œåªè­¦å‘Š
        
        # æ£€æŸ¥ 3: Valid çš„æœ€å¤§æ—¥æœŸ + horizon < Test çš„æœ€å°æ—¥æœŸ
        valid_max = valid_dates.max()
        test_min = test_dates.min()
        gap_valid_test = (test_min - valid_max).days
        
        if gap_valid_test < target_horizon:
            print(f"   âš ï¸  Valid-Test é—´éš”ä¸è¶³: {gap_valid_test} å¤© < {target_horizon} å¤©")
        
        print(f"   âœ… æ— æ—¥æœŸé‡å ")
        print(f"   ğŸ“Š Train-Valid é—´éš”: {gap_train_valid} å¤©")
        print(f"   ğŸ“Š Valid-Test é—´éš”: {gap_valid_test} å¤©")
        
        return True


def create_cv_from_config(config_path: str = "configs/ml_baseline.yml") -> TimeSeriesCV:
    """
    ä¾¿æ·å‡½æ•°ï¼šä»é…ç½®æ–‡ä»¶åˆ›å»º CV å®ä¾‹
    
    Parameters:
    -----------
    config_path : str
        é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
    --------
    TimeSeriesCV
        å®ä¾‹
    """
    import yaml
    
    if not os.path.isabs(config_path):
        config_path = os.path.join(ml_root, config_path)
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    return TimeSeriesCV.from_config(config)


if __name__ == '__main__':
    """æµ‹è¯•ä»£ç """
    print("=" * 70)
    print("æ—¶åºäº¤å‰éªŒè¯æ¨¡å—æµ‹è¯•")
    print("=" * 70)
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    np.random.seed(42)
    
    dates = pd.date_range('2020-01-01', '2024-12-31', freq='D')
    dates = dates[dates.dayofweek < 5]  # åªä¿ç•™å·¥ä½œæ—¥
    tickers = ['000001', '000002', '000003', '000004', '000005']
    
    # åˆ›å»º MultiIndex
    index = pd.MultiIndex.from_product(
        [dates, tickers],
        names=['date', 'ticker']
    )
    
    # æ¨¡æ‹Ÿæ•°æ®
    test_data = pd.DataFrame({
        'feature_1': np.random.randn(len(index)),
        'feature_2': np.random.randn(len(index)),
        'close': np.random.randn(len(index)).cumsum() + 100
    }, index=index)
    
    print(f"\nğŸ“Š æµ‹è¯•æ•°æ®:")
    print(f"   å½¢çŠ¶: {test_data.shape}")
    print(f"   æ—¥æœŸèŒƒå›´: {dates.min().date()} ~ {dates.max().date()}")
    print(f"   è‚¡ç¥¨æ•°: {len(tickers)}")
    
    # 1. å•æ¬¡åˆ‡åˆ†æµ‹è¯•
    print("\n" + "=" * 70)
    print("æµ‹è¯• 1: å•æ¬¡åˆ‡åˆ†")
    print("=" * 70)
    
    cv = TimeSeriesCV(
        train_ratio=0.6,
        valid_ratio=0.2,
        test_ratio=0.2,
        purge_days=10,
        embargo_days=5,
        max_horizon=10
    )
    
    train_idx, valid_idx, test_idx = cv.single_split(test_data)
    
    print(f"\nğŸ“Š åˆ‡åˆ†ç»“æœ:")
    print(f"   Train: {len(train_idx)} æ ·æœ¬")
    print(f"   Valid: {len(valid_idx)} æ ·æœ¬")
    print(f"   Test:  {len(test_idx)} æ ·æœ¬")
    
    # éªŒè¯æ— æ³„æ¼
    cv.validate_no_leakage(train_idx, valid_idx, test_idx, target_horizon=10)
    
    # 2. Walk-Forward æµ‹è¯•
    print("\n" + "=" * 70)
    print("æµ‹è¯• 2: Walk-Forward éªŒè¯")
    print("=" * 70)
    
    wfa_results = []
    for fold, train_idx, valid_idx, test_idx in cv.walk_forward_split(
        test_data, n_splits=3, min_train_days=252, expanding=True
    ):
        wfa_results.append({
            'fold': fold,
            'train_size': len(train_idx),
            'valid_size': len(valid_idx),
            'test_size': len(test_idx)
        })
    
    print(f"\nğŸ“Š WFA ç»“æœæ±‡æ€»:")
    for r in wfa_results:
        print(f"   Fold {r['fold']+1}: Train={r['train_size']}, "
              f"Valid={r['valid_size']}, Test={r['test_size']}")
    
    # 3. ä»é…ç½®æ–‡ä»¶åˆ›å»º
    print("\n" + "=" * 70)
    print("æµ‹è¯• 3: ä»é…ç½®æ–‡ä»¶åˆ›å»º")
    print("=" * 70)
    
    try:
        cv_from_cfg = create_cv_from_config()
        print("   âœ… ä»é…ç½®æ–‡ä»¶åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"   âš ï¸  ä»é…ç½®æ–‡ä»¶åˆ›å»ºå¤±è´¥: {e}")
    
    print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
