# Evaluation æ¨¡å—

## ğŸ“‹ æ¦‚è¿°

`evaluation/` æ¨¡å—æ˜¯å› å­ä¸æ¨¡å‹è¯„ä¼°çš„æ ¸å¿ƒæ¡†æ¶ï¼Œæä¾›ä¸¤å¥—è¯„ä¼°ä½“ç³»ï¼š
1. **æ¨ªæˆªé¢è¯„ä¼°æ¡†æ¶**ï¼ˆAlphalens é£æ ¼ï¼‰ï¼šå› å­ ICã€åˆ†ä½æ•°æ”¶ç›Šã€Spreadã€å•è°ƒæ€§ç­‰
2. **ä¼ ç»Ÿè¯„ä¼°æ¡†æ¶**ï¼šMSEã€MAEã€åˆ†æ¡¶åˆ†æã€æŠ¥å‘Šç”Ÿæˆ

## ğŸ“ æ–‡ä»¶ç»“æ„

```
evaluation/
â”œâ”€â”€ __init__.py                  # æ¨¡å—å¯¼å‡º
â”œâ”€â”€ README.md                    # æœ¬æ–‡æ¡£
â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚  æ¨ªæˆªé¢è¯„ä¼°æ¡†æ¶ï¼ˆAlphalens é£æ ¼ï¼‰â­æ ¸å¿ƒ
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”œâ”€â”€ cross_section_analyzer.py    # åˆ†æå™¨ä¸»ç±»ï¼ˆç»Ÿä¸€å…¥å£ï¼‰
â”œâ”€â”€ cross_section_metrics.py     # æ ¸å¿ƒåº¦é‡è®¡ç®—ï¼ˆIC/ICIR/Spreadï¼‰
â”œâ”€â”€ factor_preprocessing.py      # å› å­é¢„å¤„ç†ï¼ˆWinsorize/æ ‡å‡†åŒ–/ä¸­æ€§åŒ–ï¼‰
â”œâ”€â”€ visualization.py             # 7ç§å¯è§†åŒ–å›¾è¡¨
â”œâ”€â”€ tearsheet.py                 # HTMLæŠ¥å‘Š + CSVå¯¼å‡º
â”œâ”€â”€ drift_detector.py            # æ¼‚ç§»æ£€æµ‹ï¼ˆPSI/KSï¼‰
â”œâ”€â”€ cross_section_adapter.py     # é€‚é…å™¨ï¼ˆå¯¹æ¥ DataLoaderï¼‰
â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚  ä¼ ç»Ÿè¯„ä¼°æ¡†æ¶
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”œâ”€â”€ metrics.py                   # ä¼ ç»ŸæŒ‡æ ‡ï¼ˆMSE/MAE/ICï¼‰
â”œâ”€â”€ bucketing.py                 # åˆ†æ¡¶åˆ†æ
â”œâ”€â”€ reporting.py                 # æŠ¥å‘Šç”Ÿæˆ
â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”‚  èšç±»è¯„ä¼°
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â””â”€â”€ cluster/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ cluster_evaluate.py      # KMeans èšç±»æ”¶ç›Šè¯„ä¼°
```

## ğŸ”— æ¨¡å—ä¾èµ–å…³ç³»

```
CrossSectionAnalyzer (ç»Ÿä¸€å…¥å£)
â”œâ”€â”€ cross_section_metrics       # IC/ICIR/Spread/å•è°ƒæ€§/æ¢æ‰‹ç‡
â”œâ”€â”€ factor_preprocessing        # Winsorize/æ ‡å‡†åŒ–/ä¸­æ€§åŒ–
â”œâ”€â”€ visualization               # 7ç§å›¾è¡¨
â””â”€â”€ tearsheet                   # HTMLæŠ¥å‘Š

DriftDetector (æ¼‚ç§»æ£€æµ‹)
â””â”€â”€ CrossSectionAnalyzer        # å¤ç”¨åˆ†æé€»è¾‘

CrossSectionAdapter (é€‚é…å™¨)
â”œâ”€â”€ DataLoader                  # æ•°æ®åŠ è½½
â”œâ”€â”€ MarketDataLoader            # å¸‚åœºæ•°æ®
â””â”€â”€ CrossSectionAnalyzer        # è¯„ä¼°åˆ†æ
```

---

## ğŸ“¦ æ¨ªæˆªé¢è¯„ä¼°æ¡†æ¶ï¼ˆæ ¸å¿ƒï¼‰

### 1. CrossSectionAnalyzer (`cross_section_analyzer.py`)

**å› å­è¯„ä¼°ç»Ÿä¸€å…¥å£**ï¼Œå°è£…æ‰€æœ‰æ¨ªæˆªé¢è¯„ä¼°é€»è¾‘ã€‚

```python
from evaluation import CrossSectionAnalyzer

analyzer = CrossSectionAnalyzer(
    factors=factors_df,              # MultiIndex [date, ticker]
    forward_returns=forward_returns, # æˆ–æä¾› prices è‡ªåŠ¨è®¡ç®—
    prices=prices_df,                # å¯é€‰
    tradable_mask=tradable_mask,     # å¯é€‰ï¼Œè¿‡æ»¤ä¸å¯äº¤æ˜“æ ·æœ¬
    market_cap=market_cap,           # å¯é€‰ï¼Œç”¨äºä¸­æ€§åŒ–
    industry=industry                # å¯é€‰ï¼Œç”¨äºä¸­æ€§åŒ–
)

# è¿è¡Œåˆ†æ
analyzer.analyze(
    periods=[5, 10, 20],             # æ”¶ç›ŠæœŸ
    n_quantiles=5,                   # åˆ†ä½æ•°
    preprocess=True,                 # æ˜¯å¦é¢„å¤„ç†
    winsorize_quantile=0.01,         # Winsorize åˆ†ä½æ•°
    check_quality=True               # æ·±åº¦è´¨é‡æ£€æŸ¥ï¼ˆICè¡°å‡/PSI/KSï¼‰
)

# è·å–ç»“æœ
results = analyzer.get_results()
```

**è¾“å‡ºç»“æœåŒ…å«**ï¼š
| é”® | ç±»å‹ | è¯´æ˜ |
|---|------|------|
| `daily_ic` | DataFrame | æ¯æ—¥ IC åºåˆ— |
| `ic_summary` | Dict | IC ç»Ÿè®¡æ‘˜è¦ï¼ˆmean/std/ICIR/t_statï¼‰ |
| `quantile_returns` | Dict | åˆ†ä½æ•°ç»„åˆæ”¶ç›Š |
| `cumulative_returns` | Dict | ç´¯è®¡å‡€å€¼ |
| `spreads` | Dict | Top-Mean / Top-Bottom Spread |
| `monotonicity` | Dict | å•è°ƒæ€§æŒ‡æ ‡ï¼ˆKendall Ï„ï¼‰ |
| `turnover_stats` | Dict | æ¢æ‰‹ç‡ç»Ÿè®¡ |
| `quality_checks` | Dict | æ·±åº¦è´¨é‡æ£€æŸ¥ï¼ˆICè¡°å‡/PSI/KSï¼‰ |

### 2. cross_section_metrics (`cross_section_metrics.py`)

**æ ¸å¿ƒåº¦é‡è®¡ç®—**ï¼Œä½¿ç”¨ Numba JIT åŠ é€Ÿã€‚

```python
from evaluation import (
    calculate_forward_returns,
    calculate_daily_ic,
    calculate_ic_summary,
    calculate_quantile_returns,
    calculate_spread,
    calculate_monotonicity,
    calculate_turnover
)

# è®¡ç®—è¿œæœŸæ”¶ç›Š
forward_returns = calculate_forward_returns(
    prices=prices_df,
    periods=[1, 5, 10, 20],
    method='simple'  # 'simple' æˆ– 'log'
)

# è®¡ç®—æ¯æ—¥ ICï¼ˆSpearmanï¼‰
daily_ic = calculate_daily_ic(
    factors=factors_df,
    forward_returns=forward_returns,
    method='spearman'
)

# IC æ±‡æ€»ç»Ÿè®¡
ic_summary = calculate_ic_summary(ic_series)
# è¿”å›: mean, std, icir, icir_annual, t_stat, positive_ratio

# åˆ†ä½æ•°æ”¶ç›Š
quantile_returns = calculate_quantile_returns(
    factors=factors_df,
    forward_returns=forward_returns,
    n_quantiles=5
)

# Spread è®¡ç®—
spread = calculate_spread(
    quantile_returns=quantile_returns,
    method='top_bottom'  # 'top_bottom' æˆ– 'top_mean'
)

# å•è°ƒæ€§æ£€éªŒ
monotonicity = calculate_monotonicity(quantile_mean_returns)
# è¿”å› Kendall Ï„

# æ¢æ‰‹ç‡
turnover = calculate_turnover(
    factors=factors_df,
    n_quantiles=5
)
```

**æ€§èƒ½ä¼˜åŒ–**ï¼š
- ä½¿ç”¨ `@numba.jit` åŠ é€Ÿ Spearman ç›¸å…³è®¡ç®—
- å‘é‡åŒ–æ“ä½œï¼Œé¿å… `groupby().apply()` å¼€é”€
- æ”¯æŒ Numba ä¸å¯ç”¨æ—¶çš„ fallback

### 3. factor_preprocessing (`factor_preprocessing.py`)

**å› å­é¢„å¤„ç†ç®¡é“**ã€‚

```python
from evaluation import (
    winsorize_factor,
    standardize_factor,
    neutralize_factor,
    preprocess_factor_pipeline
)

# Winsorizeï¼ˆæå€¼å¤„ç†ï¼‰
factors_win = winsorize_factor(
    factors=factors_df,
    lower_quantile=0.01,
    upper_quantile=0.99,
    cross_section=True  # æŒ‰æ—¥æ¨ªæˆªé¢å¤„ç†
)

# æ ‡å‡†åŒ–
factors_std = standardize_factor(
    factors=factors_df,
    method='z_score',    # 'z_score', 'min_max', 'rank'
    cross_section=True
)

# ä¸­æ€§åŒ–ï¼ˆè¡Œä¸š/å¸‚å€¼ï¼‰
factors_neutral = neutralize_factor(
    factors=factors_df,
    market_cap=market_cap,  # å¸‚å€¼ä¸­æ€§åŒ–
    industry=industry,      # è¡Œä¸šä¸­æ€§åŒ–
    method='ols'            # 'ols' æˆ– 'demean'
)

# å®Œæ•´ç®¡é“
factors_processed = preprocess_factor_pipeline(
    factors=factors_df,
    winsorize=True,
    standardize=True,
    neutralize=True,
    market_cap=market_cap,
    industry=industry
)
```

### 4. visualization (`visualization.py`)

**7ç§å¯è§†åŒ–å›¾è¡¨**ã€‚

```python
from evaluation import (
    plot_ic_time_series,
    plot_ic_distribution,
    plot_quantile_cumulative_returns,
    plot_quantile_mean_returns,
    plot_spread_cumulative_returns,
    plot_monthly_ic_heatmap,
    plot_turnover_time_series,
    create_factor_tearsheet_plots
)

# IC æ—¶é—´åºåˆ—ï¼ˆèµ°å»Šå›¾ï¼‰
fig = plot_ic_time_series(
    ic_series=daily_ic['factor_name'],
    title='IC Time Series',
    save_path='ic_series.png'
)

# IC åˆ†å¸ƒç›´æ–¹å›¾
fig = plot_ic_distribution(ic_series, save_path='ic_dist.png')

# åˆ†ä½æ•°ç´¯è®¡æ”¶ç›Š
fig = plot_quantile_cumulative_returns(
    cumulative_returns=cum_ret_df,
    save_path='quantile_cumret.png'
)

# åˆ†ä½æ•°å¹³å‡æ”¶ç›ŠæŸ±çŠ¶å›¾
fig = plot_quantile_mean_returns(
    quantile_mean=quantile_mean_df,
    save_path='quantile_meanret.png'
)

# Spread ç´¯è®¡æ”¶ç›Š
fig = plot_spread_cumulative_returns(
    spread_series=spread,
    save_path='spread_cumret.png'
)

# æœˆåº¦ IC çƒ­åŠ›å›¾
fig = plot_monthly_ic_heatmap(
    ic_series=daily_ic,
    save_path='ic_heatmap.png'
)

# ä¸€é”®ç”Ÿæˆæ‰€æœ‰å›¾è¡¨
plot_paths = create_factor_tearsheet_plots(
    analyzer_results=results,
    factor_name='ROC_20',
    return_period='5d',
    output_dir='figures/'
)
```

### 5. tearsheet (`tearsheet.py`)

**HTML æŠ¥å‘Š + CSV å¯¼å‡º**ã€‚

```python
from evaluation import (
    generate_html_tearsheet,
    generate_full_tearsheet,
    save_ic_to_csv,
    save_quantile_returns_to_csv
)

# ç”Ÿæˆ HTML Tearsheet
generate_html_tearsheet(
    analyzer_results=results,
    factor_name='ROC_20',
    return_period='5d',
    output_path='tearsheet_ROC_20_5d.html',
    plot_paths=plot_paths  # å¯é€‰ï¼ŒåµŒå…¥å›¾è¡¨
)

# ä¿å­˜ IC åºåˆ—åˆ° CSV
save_ic_to_csv(
    ic_series=daily_ic,
    output_path='ic_ROC_20_5d.csv'
)

# ä¿å­˜åˆ†ä½æ•°æ”¶ç›Šåˆ° CSV
save_quantile_returns_to_csv(
    quantile_returns=quantile_ret,
    output_path='quantile_returns_ROC_20_5d.csv'
)
```

### 6. drift_detector (`drift_detector.py`)

**æ¼‚ç§»æ£€æµ‹ï¼ˆTrain vs Valid vs Testï¼‰**ã€‚

```python
from evaluation import DriftDetector, compare_splits_with_analyzer

detector = DriftDetector(
    drift_threshold=0.2,       # 20% å·®å¼‚é˜ˆå€¼
    significance_level=0.05
)

# æ¯”è¾ƒ IC æ±‡æ€»
comparison = detector.compare_ic_summaries(
    train_summary=train_ic_summary,
    valid_summary=valid_ic_summary,
    test_summary=test_ic_summary
)

# è®¡ç®— PSIï¼ˆPopulation Stability Indexï¼‰
psi = detector.calculate_psi(
    reference_data=train_features['factor'],
    current_data=test_features['factor']
)
# PSI < 0.1: æ— æ¼‚ç§»
# 0.1 â‰¤ PSI < 0.2: è½»å¾®æ¼‚ç§»
# PSI â‰¥ 0.2: æ˜¾è‘—æ¼‚ç§»

# KS æ£€éªŒ
ks_stat, p_value = detector.ks_test(
    reference_data=train_features,
    current_data=test_features
)

# ä¸€é”®å¯¹æ¯”ï¼ˆä¸ CrossSectionAnalyzer é›†æˆï¼‰
results = compare_splits_with_analyzer(
    factors=factors_df,
    forward_returns=forward_returns,
    train_idx=train_idx,
    valid_idx=valid_idx,
    test_idx=test_idx,
    output_dir='reports/cv/',
    drift_threshold=0.2
)
```

---

## ğŸ“¦ ä¼ ç»Ÿè¯„ä¼°æ¡†æ¶

### 7. metrics (`metrics.py`)

**ä¼ ç»Ÿå›å½’æŒ‡æ ‡**ã€‚

```python
from evaluation import calculate_metrics, calculate_ic_by_date

# è®¡ç®—è¯„ä¼°æŒ‡æ ‡
metrics = calculate_metrics(y_true, y_pred)
# è¿”å›: mse, mae, rmse, r2, ic, rank_ic, n_samples

# æŒ‰æ—¥æœŸè®¡ç®— IC
daily_ic = calculate_ic_by_date(predictions_df)
# predictions_df éœ€è¦åŒ…å« y_true, y_pred åˆ—
```

### 8. bucketing (`bucketing.py`)

**åˆ†æ¡¶åˆ†æ**ã€‚

```python
from evaluation import bucket_predictions, analyze_bucket_performance

# åˆ†æ¡¶
predictions_with_bucket = bucket_predictions(
    predictions_df=predictions_df,
    n_buckets=5,
    method='quantile',      # 'quantile' æˆ– 'equal_width'
    cross_section=True      # æŒ‰æ—¥æ¨ªæˆªé¢åˆ†æ¡¶
)

# åˆ†æåˆ†æ¡¶è¡¨ç°
bucket_perf = analyze_bucket_performance(predictions_with_bucket)
# è¿”å›æ¯ä¸ªæ¡¶çš„å¹³å‡æ”¶ç›Šã€æ ·æœ¬æ•°ç­‰
```

### 9. reporting (`reporting.py`)

**æŠ¥å‘Šç”Ÿæˆ**ã€‚

```python
from evaluation import generate_report

generate_report(
    results={
        'model_metrics': {...},
        'bucket_performance': bucket_perf_df,
        'predictions': predictions_df
    },
    output_dir='reports/evaluation/',
    bucket_performance_file='model_bucket_performance.csv',
    predictions_file='test_predictions.csv',
    summary_file='summary.json'
)
```

---

## ğŸ“¦ èšç±»è¯„ä¼°

### 10. cluster_evaluate (`cluster/cluster_evaluate.py`)

**KMeans èšç±»æ”¶ç›Šè¯„ä¼°**ã€‚

```python
from evaluation.cluster.cluster_evaluate import ClusterEvaluator

evaluator = ClusterEvaluator(reports_dir='ML output/reports')

# åŠ è½½æ•°æ®
states_train, states_test, targets = evaluator.load_pca_states_and_targets(
    states_train_path='states/states_pca_train.npy',
    states_test_path='states/states_pca_test.npy',
    targets_path='datasets/with_targets.csv'
)

# è¿è¡Œèšç±»åˆ†æï¼ˆk=4,5,6ï¼‰
evaluator.run_cluster_analysis(states_train, states_test, targets)

# ç”ŸæˆæŠ¥å‘Š
evaluator.generate_report()

# è·å–æœ€ä½³èšç±»
best_cluster = evaluator.get_best_cluster()
```

---

## ğŸ¯ ä½¿ç”¨åœºæ™¯

| åœºæ™¯ | æ¨èæ¨¡å— |
|------|---------|
| å› å­ç ”ç©¶ | `CrossSectionAnalyzer` + `visualization` + `tearsheet` |
| å› å­é¢„å¤„ç† | `factor_preprocessing` |
| æ¨¡å‹è¯„ä¼°ï¼ˆæ’åºï¼‰ | `CrossSectionAnalyzer`ï¼ˆè¯„ä¼°é¢„æµ‹åˆ†æ•°çš„ ICï¼‰ |
| æ¨¡å‹è¯„ä¼°ï¼ˆä¼ ç»Ÿï¼‰ | `metrics` + `bucketing` + `reporting` |
| æ¼‚ç§»æ£€æµ‹ | `DriftDetector` |
| èšç±»ç­–ç•¥ | `cluster/cluster_evaluate` |

---

## ğŸ“Š ä¸ Pipeline çš„é›†æˆ

```
prepare_factors.py
â””â”€â”€ CrossSectionAnalyzer.analyze()        # å› å­è¯„ä¼°
    â”œâ”€â”€ cross_section_metrics             # IC/ICIR/Spread
    â”œâ”€â”€ factor_preprocessing              # é¢„å¤„ç†
    â”œâ”€â”€ visualization                     # å›¾è¡¨
    â””â”€â”€ tearsheet                         # HTMLæŠ¥å‘Š

run_baseline_pipeline.py
â”œâ”€â”€ DriftDetector.calculate_psi()         # æ¼‚ç§»æ£€æµ‹
â””â”€â”€ CrossSectionAnalyzer.analyze()        # æ¨¡å‹é¢„æµ‹è¯„ä¼°

run_cluster_analysis.py
â””â”€â”€ ClusterEvaluator.run_cluster_analysis()  # èšç±»è¯„ä¼°
```

---

## ğŸ“ è¾“å‡ºæ–‡ä»¶

```
ML output/
â”œâ”€â”€ reports/baseline_v1/
â”‚   â”œâ”€â”€ factors/
â”‚   â”‚   â”œâ”€â”€ tearsheet_{factor}_5d.html    # HTML å› å­æŠ¥å‘Š
â”‚   â”‚   â”œâ”€â”€ ic_{factor}_5d.csv            # IC æ—¶é—´åºåˆ—
â”‚   â”‚   â””â”€â”€ quantile_returns_{factor}_5d.csv
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ model_bucket_performance.csv  # åˆ†æ¡¶è¡¨ç°
â”‚   â”‚   â”œâ”€â”€ test_predictions.csv          # é¢„æµ‹æ˜ç»†
â”‚   â”‚   â””â”€â”€ summary.json                  # è¯„ä¼°æ‘˜è¦
â”‚   â”œâ”€â”€ ranking/
â”‚   â”‚   â””â”€â”€ drift_report.json             # æ¼‚ç§»æ£€æµ‹æŠ¥å‘Š
â”‚   â””â”€â”€ clustering/
â”‚       â”œâ”€â”€ clustering_analysis_report.txt
â”‚       â””â”€â”€ cluster_comparison.csv
â””â”€â”€ figures/baseline_v1/factors/{factor}/
    â”œâ”€â”€ ic_series_{factor}_5d.png         # IC æ—¶é—´åºåˆ—å›¾
    â”œâ”€â”€ ic_dist_{factor}_5d.png           # IC åˆ†å¸ƒå›¾
    â”œâ”€â”€ ic_heatmap_{factor}_5d.png        # æœˆåº¦ IC çƒ­åŠ›å›¾
    â”œâ”€â”€ quantile_cumret_{factor}_5d.png   # åˆ†ä½æ•°ç´¯è®¡æ”¶ç›Š
    â”œâ”€â”€ quantile_meanret_{factor}_5d.png  # åˆ†ä½æ•°å¹³å‡æ”¶ç›Š
    â””â”€â”€ spread_cumret_{factor}_5d.png     # Spread ç´¯è®¡æ”¶ç›Š
```

---

## ğŸ“ é…ç½®å‚æ•°

`configs/ml_baseline.yml` ç›¸å…³é…ç½®ï¼š

```yaml
evaluation:
  # æ¨ªæˆªé¢è¯„ä¼°
  cross_section:
    periods: [5, 10, 20]        # æ”¶ç›ŠæœŸ
    n_quantiles: 5              # åˆ†ä½æ•°
    preprocess: true            # æ˜¯å¦é¢„å¤„ç†
    winsorize_quantile: 0.01    # Winsorize åˆ†ä½æ•°
  
  # æ¼‚ç§»æ£€æµ‹
  drift:
    threshold: 0.2              # PSI é˜ˆå€¼
    significance_level: 0.05    # ç»Ÿè®¡æ˜¾è‘—æ€§

  # åˆ†æ¡¶åˆ†æ
  bucketing:
    n_buckets: 5
    method: quantile            # 'quantile' æˆ– 'equal_width'
```

---

## âš¡ æ€§èƒ½ä¼˜åŒ–

1. **Numba JIT åŠ é€Ÿ**ï¼š`cross_section_metrics.py` ä¸­çš„ Spearman ç›¸å…³è®¡ç®—
2. **å‘é‡åŒ–æ“ä½œ**ï¼šé¿å… `groupby().apply()` å¼€é”€
3. **ç¼“å­˜æœºåˆ¶**ï¼š`CrossSectionAnalyzer` ç¼“å­˜è®¡ç®—ç»“æœ
4. **æŒ‰éœ€è®¡ç®—**ï¼š`check_quality=False` è·³è¿‡æ·±åº¦æ£€æŸ¥
