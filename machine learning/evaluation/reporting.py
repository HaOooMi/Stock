#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŠ¥å‘Šç”Ÿæˆæ¨¡å—
"""

import os
import json
import pandas as pd
from typing import Dict, List
from datetime import datetime


def generate_report(results: Dict,
                   output_dir: str,
                   bucket_performance_file: str = "model_bucket_performance.csv",
                   predictions_file: str = "test_predictions.csv",
                   summary_file: str = "summary.json"):
    """
    ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
    
    Parameters:
    -----------
    results : dict
        è¯„ä¼°ç»“æœå­—å…¸
    output_dir : str
        è¾“å‡ºç›®å½•
    bucket_performance_file : str
        åˆ†æ¡¶è¡¨ç°æ–‡ä»¶å
    predictions_file : str
        é¢„æµ‹æ˜ç»†æ–‡ä»¶å
    summary_file : str
        æ‘˜è¦æ–‡ä»¶å
    """
    print("ğŸ“ ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š...")
    
    os.makedirs(output_dir, exist_ok=True)
    
    # 1. ä¿å­˜åˆ†æ¡¶è¡¨ç°
    if 'bucket_performance' in results:
        bucket_path = os.path.join(output_dir, bucket_performance_file)
        results['bucket_performance'].to_csv(bucket_path, index=False, encoding='utf-8-sig')
        print(f"   âœ… åˆ†æ¡¶è¡¨ç°å·²ä¿å­˜: {bucket_path}")
    
    # 2. ä¿å­˜é¢„æµ‹æ˜ç»†
    if 'predictions' in results:
        pred_path = os.path.join(output_dir, predictions_file)
        results['predictions'].to_csv(pred_path, encoding='utf-8-sig')
        print(f"   âœ… é¢„æµ‹æ˜ç»†å·²ä¿å­˜: {pred_path}")
    
    # 3. ä¿å­˜æ‘˜è¦
    summary = {
        'timestamp': datetime.now().isoformat(),
        'models': list(results.get('model_metrics', {}).keys()),
        'metrics': results.get('model_metrics', {}),
        'validation': results.get('validation', {})
    }
    
    summary_path = os.path.join(output_dir, summary_file)
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    print(f"   âœ… æ‘˜è¦å·²ä¿å­˜: {summary_path}")
    
    # 4. ç”Ÿæˆå¯è¯»çš„æ–‡æœ¬æŠ¥å‘Š
    report_path = os.path.join(output_dir, "evaluation_report.txt")
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("=" * 70 + "\n")
        f.write("æœºå™¨å­¦ä¹ æ¨¡å‹è¯„ä¼°æŠ¥å‘Š\n")
        f.write("=" * 70 + "\n\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {summary['timestamp']}\n\n")
        
        # æ¨¡å‹æŒ‡æ ‡
        if 'model_metrics' in results:
            f.write("## æ¨¡å‹è¯„ä¼°æŒ‡æ ‡\n\n")
            for model_name, metrics in results['model_metrics'].items():
                f.write(f"### {model_name}\n")
                for metric, value in metrics.items():
                    if isinstance(value, float):
                        f.write(f"  - {metric}: {value:.6f}\n")
                    else:
                        f.write(f"  - {metric}: {value}\n")
                f.write("\n")
        
        # éªŒæ”¶ç»“æœ
        if 'validation' in results:
            f.write("## éªŒæ”¶ç»“æœ\n\n")
            validation = results['validation']
            f.write(f"  âœ… Topæ¡¶ > å…¨ä½“å‡å€¼: {validation.get('top_vs_mean', False)}\n")
            f.write(f"  âœ… Spread > 0: {validation.get('spread_positive', False)}\n")
            f.write(f"  ğŸ“Š Topæ¡¶å¹³å‡æ”¶ç›Š: {validation.get('top_mean', 0):.6f}\n")
            f.write(f"  ğŸ“Š å…¨ä½“å¹³å‡æ”¶ç›Š: {validation.get('overall_mean', 0):.6f}\n")
            f.write(f"  ğŸ“ˆ Top-Bottom Spread: {validation.get('spread', 0):.6f}\n")
        
        f.write("\n" + "=" * 70 + "\n")
    
    print(f"   âœ… è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    print(f"\nâœ… æ‰€æœ‰æŠ¥å‘Šå·²ç”Ÿæˆåˆ°: {output_dir}")
