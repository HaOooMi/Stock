#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨ªæˆªé¢è¯„ä¼°é€‚é…å™¨ - å¯¹æ¥ç°æœ‰DataLoaderå’Œè®­ç»ƒæµç¨‹

åŠŸèƒ½ï¼š
1. ä» DataLoader è¾“å‡ºè‡ªåŠ¨æå–å› å­ã€ä»·æ ¼ã€å…ƒæ•°æ®
2. ä¸ train_models.py æ— ç¼é›†æˆ
3. æ”¯æŒå•è‚¡ç¥¨æ—¶åº å’Œ å¤šè‚¡ç¥¨æ¨ªæˆªé¢ ä¸¤ç§æ¨¡å¼
4. è‡ªåŠ¨ä» InfluxDB/CSV åŠ è½½ prices æ•°æ®
5. æä¾›ä¸€é”®è¯„ä¼°æ¥å£

é€‚é…å¯¹è±¡ï¼š
- data/data_loader.py
- data/market_data_loader.py  
- pipelines/train_models.py
"""

import os
import sys
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Union
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
ml_root = os.path.dirname(current_dir)
project_root = os.path.dirname(ml_root)
if ml_root not in sys.path:
    sys.path.insert(0, ml_root)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# å¯¼å…¥ç°æœ‰æ¨¡å—
from data.data_loader import DataLoader
from data.market_data_loader import MarketDataLoader

# å¯¼å…¥è‚¡ç¥¨å…ƒæ•°æ®æ¨¡å—
try:
    from get_stock_info.stock_meta_akshare import get_basic_info_mysql
    from sqlalchemy import create_engine
    HAVE_STOCK_META = True
except ImportError:
    HAVE_STOCK_META = False
    print("âš ï¸ è‚¡ç¥¨å…ƒæ•°æ®æ¨¡å—æœªæ‰¾åˆ°")

# å¯¼å…¥è¯„ä¼°æ ¸å¿ƒæ¨¡å—
try:
    from evaluation.cross_section_analyzer import CrossSectionAnalyzer
    from evaluation.tearsheet import generate_full_tearsheet
    HAVE_CROSS_SECTION = True
except ImportError:
    HAVE_CROSS_SECTION = False
    print("âš ï¸ æ¨ªæˆªé¢è¯„ä¼°æ¨¡å—æœªæ‰¾åˆ°")


class CrossSectionAdapter:
    """
    æ¨ªæˆªé¢è¯„ä¼°é€‚é…å™¨
    
    åŠŸèƒ½ï¼š
    1. è‡ªåŠ¨ä» DataLoader æå–æ•°æ®
    2. ä» MarketDataLoader è·å– prices
    3. æä¾›ä¸€é”®è¯„ä¼°æ¥å£
    4. æ”¯æŒå•è‚¡ç¥¨å’Œå¤šè‚¡ç¥¨æ¨¡å¼
    """
    
    def __init__(self, 
                 data_loader: DataLoader,
                 market_data_loader: Optional[MarketDataLoader] = None,
                 enable_neutralization: bool = False,
                 db_engine = None):
        """
        åˆå§‹åŒ–é€‚é…å™¨
        
        Parameters:
        -----------
        data_loader : DataLoader
            ç°æœ‰çš„æ•°æ®åŠ è½½å™¨å®ä¾‹
        market_data_loader : MarketDataLoader, optional
            å¸‚åœºæ•°æ®åŠ è½½å™¨ï¼ˆç”¨äºè·å–pricesï¼‰
        enable_neutralization : bool
            æ˜¯å¦å¯ç”¨å¸‚å€¼/è¡Œä¸šä¸­æ€§åŒ–ï¼ˆä»…å¤šè‚¡ç¥¨æ¨¡å¼ï¼‰
        db_engine : sqlalchemy.Engine, optional
            MySQLæ•°æ®åº“å¼•æ“ï¼ˆç”¨äºè·å–å¸‚å€¼å’Œè¡Œä¸šæ•°æ®ï¼‰
        """
        self.data_loader = data_loader
        self.market_data_loader = market_data_loader
        self.enable_neutralization = enable_neutralization
        self.db_engine = db_engine
        
        if not HAVE_CROSS_SECTION:
            raise ImportError("è¯·å…ˆå®ç° cross_section_analyzer.py å’Œ tearsheet.py")
        
        print(f"ğŸ”Œ æ¨ªæˆªé¢è¯„ä¼°é€‚é…å™¨åˆå§‹åŒ–")
        print(f"   æ•°æ®åŠ è½½å™¨: âœ…")
        print(f"   å¸‚åœºæ•°æ®: {'âœ…' if market_data_loader else 'âŒ'}")
        print(f"   æ•°æ®åº“è¿æ¥: {'âœ…' if db_engine else 'âŒ'}")
        print(f"   ä¸­æ€§åŒ–: {'âœ…' if enable_neutralization else 'âŒ'}")
    
    def evaluate_feature(self,
                        features: pd.DataFrame,
                        targets: pd.Series,
                        feature_col: str,
                        symbol: str,
                        start_date: str,
                        end_date: str,
                        forward_periods: List[int] = [5],
                        quantiles: int = 5,
                        output_dir: Optional[str] = None) -> Dict:
        """
        è¯„ä¼°å•ä¸ªç‰¹å¾çš„é¢„æµ‹èƒ½åŠ›ï¼ˆå¯¹æ¥ DataLoader è¾“å‡ºï¼‰
        
        Parameters:
        -----------
        features : pd.DataFrame
            DataLoader è¿”å›çš„ç‰¹å¾æ•°æ®ï¼ˆMultiIndex[date, ticker]ï¼‰
        targets : pd.Series
            DataLoader è¿”å›çš„ç›®æ ‡æ•°æ®
        feature_col : str
            è¦è¯„ä¼°çš„ç‰¹å¾åˆ—å
        symbol : str
            è‚¡ç¥¨ä»£ç ï¼ˆç”¨äºåŠ è½½pricesï¼‰
        start_date : str
            å¼€å§‹æ—¥æœŸ
        end_date : str
            ç»“æŸæ—¥æœŸ
        forward_periods : List[int]
            å‘å‰æœŸæ•°ï¼ˆå¤©ï¼‰
        quantiles : int
            åˆ†ä½æ•°æ•°é‡
        output_dir : str, optional
            è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼šML output/reports/baseline_v1/factorsï¼‰
            
        Returns:
        --------
        Dict
            è¯„ä¼°ç»“æœå­—å…¸
        """
        print(f"\n{'='*60}")
        print(f"ğŸ“Š è¯„ä¼°ç‰¹å¾: {feature_col}")
        print(f"{'='*60}")
        
        # 1. æå–å› å­æ•°æ®ï¼ˆå•åˆ—ï¼‰
        if feature_col not in features.columns:
            raise ValueError(f"ç‰¹å¾åˆ— '{feature_col}' ä¸å­˜åœ¨äºfeaturesä¸­")
        
        factor_df = features[[feature_col]].copy()
        
        # 2. æ£€æµ‹æ˜¯å¦ä¸ºå•è‚¡ç¥¨åœºæ™¯
        n_symbols = factor_df.index.get_level_values('ticker').nunique()
        is_single_stock = (n_symbols == 1)
        
        print(f"\n   ğŸ“ˆ æ•°æ®ä¿¡æ¯:")
        print(f"      è‚¡ç¥¨æ•°é‡: {n_symbols} ({'å•è‚¡ç¥¨' if is_single_stock else 'å¤šè‚¡ç¥¨'})")
        print(f"      æ ·æœ¬æ•°é‡: {len(factor_df)}")
        print(f"      æ—¶é—´èŒƒå›´: {factor_df.index.get_level_values('date').min().date()} ~ "
              f"{factor_df.index.get_level_values('date').max().date()}")
        
        # 3. è·å– prices æ•°æ®
        prices_df = self._load_prices(
            symbol=symbol,
            start_date=start_date,
            end_date=end_date,
            index=factor_df.index
        )
        
        # 4. å‡†å¤‡å¯é€‰æ•°æ®ï¼ˆä»…å¤šè‚¡ç¥¨æ¨¡å¼ï¼‰
        market_cap_df = None
        industry_df = None
        
        if not is_single_stock and self.enable_neutralization:
            print(f"\n   ğŸ“Š åŠ è½½å¸‚å€¼å’Œè¡Œä¸šæ•°æ®ç”¨äºä¸­æ€§åŒ–...")
            market_cap_df, industry_df = self._load_market_cap_and_industry(
                index=factor_df.index
            )
        
        # 5. åˆ›å»º CrossSectionAnalyzer
        analyzer = CrossSectionAnalyzer(
            factors=factor_df,
            prices=prices_df,
            market_cap=market_cap_df,
            industry=industry_df,
            tradable_mask=None,  # DataLoader å·²è¿‡æ»¤
            forward_periods=forward_periods,
            quantiles=quantiles,
            return_type='simple'
        )
        
        # 6. é¢„å¤„ç†ï¼ˆæ¨ªæˆªé¢æ ‡å‡†åŒ–ï¼‰
        analyzer.preprocess(
            winsorize=True,
            standardize=True,
            neutralize=(not is_single_stock and self.enable_neutralization)  # å¤šè‚¡ç¥¨ä¸”å¯ç”¨ä¸­æ€§åŒ–
        )
        
        # 7. æ‰§è¡Œåˆ†æ
        results = analyzer.analyze()
        
        # 8. æ‰“å°æ‘˜è¦
        analyzer.summary()
        
        # 9. ç”ŸæˆæŠ¥å‘Šï¼ˆå¦‚æœæŒ‡å®šè¾“å‡ºç›®å½•ï¼‰
        if output_dir:
            # ç¡®å®šè¾“å‡ºç›®å½•
            if not os.path.isabs(output_dir):
                output_dir = os.path.join(ml_root, output_dir)
            
            os.makedirs(output_dir, exist_ok=True)
            
            # ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
            generate_full_tearsheet(
                results,
                factor_name=feature_col,
                output_dir=output_dir,
                show_plots=False
            )
            
            print(f"\n   âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {output_dir}")
        
        return results
    
    def evaluate_all_features(self,
                             features: pd.DataFrame,
                             targets: pd.Series,
                             symbol: str,
                             start_date: str,
                             end_date: str,
                             output_dir: Optional[str] = None,
                             top_k: Optional[int] = None) -> pd.DataFrame:
        """
        æ‰¹é‡è¯„ä¼°æ‰€æœ‰ç‰¹å¾ï¼ˆå¯¹æ¥ DataLoader è¾“å‡ºï¼‰
        
        Parameters:
        -----------
        features : pd.DataFrame
            DataLoader è¿”å›çš„ç‰¹å¾æ•°æ®
        targets : pd.Series
            DataLoader è¿”å›çš„ç›®æ ‡æ•°æ®
        symbol : str
            è‚¡ç¥¨ä»£ç 
        start_date : str
            å¼€å§‹æ—¥æœŸ
        end_date : str
            ç»“æŸæ—¥æœŸ
        output_dir : str, optional
            è¾“å‡ºç›®å½•
        top_k : int, optional
            ä»…è¯„ä¼°å‰Kä¸ªç‰¹å¾
            
        Returns:
        --------
        pd.DataFrame
            ç‰¹å¾è¯„ä¼°æ±‡æ€»è¡¨ï¼ˆICã€ICIRã€ICèƒœç‡ç­‰ï¼‰
        """
        print(f"\n{'='*60}")
        print(f"ğŸ“Š æ‰¹é‡è¯„ä¼°æ‰€æœ‰ç‰¹å¾")
        print(f"{'='*60}")
        
        feature_cols = features.columns.tolist()
        if top_k:
            feature_cols = feature_cols[:top_k]
        
        print(f"\n   å¾…è¯„ä¼°ç‰¹å¾æ•°: {len(feature_cols)}")
        
        # åŠ è½½pricesï¼ˆå…±äº«ï¼‰
        prices_df = self._load_prices(
            symbol=symbol,
            start_date=start_date,
            end_date=end_date,
            index=features.index
        )
        
        # æ‰¹é‡è¯„ä¼°
        summary_list = []
        
        for i, feature_col in enumerate(feature_cols, 1):
            print(f"\n[{i}/{len(feature_cols)}] è¯„ä¼°: {feature_col}")
            
            try:
                # è¯„ä¼°å•ä¸ªç‰¹å¾
                results = self._evaluate_single_feature(
                    features[[feature_col]],
                    targets,
                    prices_df,
                    feature_col
                )
                
                # æå–å…³é”®æŒ‡æ ‡
                ic_summary = results.get('ic_summary_5', {})
                
                summary_list.append({
                    'feature': feature_col,
                    'ic_mean': ic_summary.get('ic_mean', np.nan),
                    'ic_std': ic_summary.get('ic_std', np.nan),
                    'icir': ic_summary.get('ic_ir', np.nan),
                    'icir_annual': ic_summary.get('ic_ir_annual', np.nan),
                    'ic_win_rate': ic_summary.get('ic_win_rate', np.nan),
                    'p_value': ic_summary.get('p_value', np.nan),
                    't_stat': ic_summary.get('t_stat', np.nan),
                    'qualified': (ic_summary.get('ic_ir', 0) > 0.5 and 
                                 ic_summary.get('p_value', 1) < 0.05)
                })
                
                # å¿«é€Ÿåé¦ˆ
                if summary_list[-1]['qualified']:
                    print(f"   âœ… åˆæ ¼ç‰¹å¾ (IC={summary_list[-1]['ic_mean']:.4f}, "
                          f"ICIR={summary_list[-1]['icir']:.2f})")
                else:
                    print(f"   âŒ å¼±ç‰¹å¾ (IC={summary_list[-1]['ic_mean']:.4f}, "
                          f"ICIR={summary_list[-1]['icir']:.2f})")
                
            except Exception as e:
                print(f"   âš ï¸  è¯„ä¼°å¤±è´¥: {e}")
                summary_list.append({
                    'feature': feature_col,
                    'ic_mean': np.nan,
                    'ic_std': np.nan,
                    'icir': np.nan,
                    'icir_annual': np.nan,
                    'ic_win_rate': np.nan,
                    'p_value': np.nan,
                    't_stat': np.nan,
                    'qualified': False
                })
        
        # æ±‡æ€»ç»“æœ
        summary_df = pd.DataFrame(summary_list)
        summary_df = summary_df.sort_values('icir', ascending=False)
        
        # æ‰“å°TOPç‰¹å¾
        print(f"\n{'='*60}")
        print(f"ğŸ“ˆ TOP 10 ç‰¹å¾ï¼ˆæŒ‰ICIRæ’åºï¼‰")
        print(f"{'='*60}")
        print(summary_df.head(10).to_string(index=False))
        
        # ä¿å­˜æ±‡æ€»è¡¨
        if output_dir:
            if not os.path.isabs(output_dir):
                output_dir = os.path.join(ml_root, output_dir)
            
            os.makedirs(output_dir, exist_ok=True)
            summary_path = os.path.join(output_dir, 'feature_evaluation_summary.csv')
            summary_df.to_csv(summary_path, index=False, encoding='utf-8')
            print(f"\n   âœ… æ±‡æ€»è¡¨å·²ä¿å­˜: {summary_path}")
        
        return summary_df
    
    def _evaluate_single_feature(self,
                                 factor_df: pd.DataFrame,
                                 targets: pd.Series,
                                 prices_df: pd.DataFrame,
                                 feature_name: str) -> Dict:
        """
        è¯„ä¼°å•ä¸ªç‰¹å¾ï¼ˆå†…éƒ¨æ–¹æ³•ï¼Œä¸ç”ŸæˆæŠ¥å‘Šï¼‰
        
        Parameters:
        -----------
        factor_df : pd.DataFrame
            å•åˆ—å› å­æ•°æ®
        targets : pd.Series
            ç›®æ ‡æ•°æ®
        prices_df : pd.DataFrame
            ä»·æ ¼æ•°æ®
        feature_name : str
            ç‰¹å¾åç§°
            
        Returns:
        --------
        Dict
            è¯„ä¼°ç»“æœ
        """
        analyzer = CrossSectionAnalyzer(
            factors=factor_df,
            prices=prices_df,
            market_cap=None,
            industry=None,
            tradable_mask=None,
            forward_periods=[5],
            quantiles=5,
            return_type='simple'
        )
        
        analyzer.preprocess(
            winsorize=True,
            standardize=True,
            neutralize=False
        )
        
        results = analyzer.analyze()
        
        return results
    
    def _load_prices(self,
                    symbol: str,
                    start_date: str,
                    end_date: str,
                    index: pd.MultiIndex) -> pd.DataFrame:
        """
        åŠ è½½ä»·æ ¼æ•°æ®ï¼ˆä» MarketDataLoader æˆ– features ä¸­æå–ï¼‰
        
        Parameters:
        -----------
        symbol : str
            è‚¡ç¥¨ä»£ç 
        start_date : str
            å¼€å§‹æ—¥æœŸ
        end_date : str
            ç»“æŸæ—¥æœŸ
        index : pd.MultiIndex
            ç›®æ ‡ç´¢å¼•ï¼ˆç”¨äºå¯¹é½ï¼‰
            
        Returns:
        --------
        pd.DataFrame
            ä»·æ ¼æ•°æ®ï¼ˆMultiIndex[date, ticker]ï¼ŒåŒ…å«'close'åˆ—ï¼‰
        """
        print(f"\n   ğŸ“Š åŠ è½½ä»·æ ¼æ•°æ®...")
        
        # æ–¹å¼1: ä» MarketDataLoader åŠ è½½ï¼ˆæ¨èï¼‰
        if self.market_data_loader is not None:
            try:
                market_df = self.market_data_loader.load_market_data(
                    symbol=symbol,
                    start_date=start_date,
                    end_date=end_date
                )
                
                if not market_df.empty and 'close' in market_df.columns:
                    # å¯¹é½åˆ°ç›®æ ‡ç´¢å¼•
                    prices_df = market_df[['close']].reindex(index)
                    
                    print(f"      âœ… ä» MarketDataLoader åŠ è½½: {len(prices_df)} è¡Œ")
                    return prices_df
                    
            except Exception as e:
                print(f"      âš ï¸  MarketDataLoader åŠ è½½å¤±è´¥: {e}")
        
        # æ–¹å¼2: ä» DataLoader çš„åŸå§‹æ–‡ä»¶ä¸­æå–ï¼ˆå¤‡ç”¨ï¼‰
        try:
            data_root = self.data_loader.data_root
            target_files = [f for f in os.listdir(data_root) 
                          if f.startswith(f"with_targets_{symbol}_complete_")]
            
            if target_files:
                target_files.sort(reverse=True)
                target_file = os.path.join(data_root, target_files[0])
                
                df = pd.read_csv(target_file, index_col=0, parse_dates=True)
                
                if 'close' in df.columns:
                    # è½¬æ¢ä¸º MultiIndex
                    dates = df.index
                    tickers = [symbol] * len(dates)
                    multi_index = pd.MultiIndex.from_arrays(
                        [dates, tickers], 
                        names=['date', 'ticker']
                    )
                    
                    prices_df = pd.DataFrame({
                        'close': df['close'].values
                    }, index=multi_index)
                    
                    # å¯¹é½åˆ°ç›®æ ‡ç´¢å¼•
                    prices_df = prices_df.reindex(index)
                    
                    print(f"      âœ… ä» CSV æ–‡ä»¶æå–: {len(prices_df)} è¡Œ")
                    return prices_df
                    
        except Exception as e:
            print(f"      âš ï¸  CSV æ–‡ä»¶æå–å¤±è´¥: {e}")
        
        # æ–¹å¼3: ä½¿ç”¨ç›®æ ‡æ•°æ®åæ¨ï¼ˆæœ€åå¤‡é€‰ï¼‰
        print(f"      âš ï¸  æ— æ³•åŠ è½½ä»·æ ¼æ•°æ®ï¼Œå°†ä½¿ç”¨ç›®æ ‡æ•°æ®ä¼°ç®—")
        
        # æ³¨æ„ï¼šè¿™ç§æ–¹å¼æœ‰å‰è§†åå·®ï¼Œä»…ç”¨äºæµ‹è¯•
        # future_return = (price_future - price_now) / price_now
        # => price_now = price_future / (1 + future_return)
        
        # è¿™é‡Œæˆ‘ä»¬æ— æ³•å‡†ç¡®ä¼°ç®—ï¼Œè¿”å›ç©ºDataFrame
        prices_df = pd.DataFrame({'close': np.nan}, index=index)
        
        return prices_df
    
    def _load_market_cap_and_industry(self,
                                      index: pd.MultiIndex) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        ä»MySQLæ•°æ®åº“åŠ è½½å¸‚å€¼å’Œè¡Œä¸šæ•°æ®
        
        Parameters:
        -----------
        index : pd.MultiIndex
            ç›®æ ‡ç´¢å¼•ï¼ˆdate, tickerï¼‰
            
        Returns:
        --------
        Tuple[pd.DataFrame, pd.DataFrame]
            (å¸‚å€¼æ•°æ®, è¡Œä¸šæ•°æ®)ï¼Œå‡ä¸ºMultiIndex[date, ticker]
        """
        if not HAVE_STOCK_META or self.db_engine is None:
            print(f"      âš ï¸  æ— æ³•åŠ è½½å¸‚å€¼å’Œè¡Œä¸šæ•°æ®ï¼šç¼ºå°‘æ•°æ®åº“è¿æ¥æˆ–è‚¡ç¥¨å…ƒæ•°æ®æ¨¡å—")
            return None, None
        
        try:
            # æå–æ‰€æœ‰å”¯ä¸€è‚¡ç¥¨ä»£ç 
            tickers = index.get_level_values('ticker').unique().tolist()
            
            # ä»MySQLè·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            with self.db_engine.connect() as conn:
                stock_info = get_basic_info_mysql(conn, tuple(tickers))
            
            if not stock_info:
                print(f"      âš ï¸  æœªæ‰¾åˆ°è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯")
                return None, None
            
            # æ„å»ºå¸‚å€¼DataFrameï¼ˆä½¿ç”¨æµé€šå¸‚å€¼ï¼‰
            market_cap_data = []
            industry_data = []
            
            for (date, ticker) in index:
                if ticker in stock_info:
                    info = stock_info[ticker]
                    # å¸‚å€¼ï¼ˆä½¿ç”¨æµé€šå¸‚å€¼ï¼Œå•ä½ï¼šå…ƒï¼‰
                    market_cap = info.get('æµé€šå¸‚å€¼')
                    if pd.notna(market_cap):
                        market_cap_data.append({
                            'date': date,
                            'ticker': ticker,
                            'market_cap': float(market_cap)
                        })
                    
                    # è¡Œä¸š
                    industry = info.get('æ‰€å±è¡Œä¸š')
                    if pd.notna(industry):
                        industry_data.append({
                            'date': date,
                            'ticker': ticker,
                            'industry': str(industry)
                        })
            
            # è½¬æ¢ä¸ºDataFrame
            if market_cap_data:
                market_cap_df = pd.DataFrame(market_cap_data)
                market_cap_df = market_cap_df.set_index(['date', 'ticker'])
                print(f"      âœ… åŠ è½½å¸‚å€¼æ•°æ®: {len(market_cap_df)} è¡Œ")
            else:
                market_cap_df = None
                print(f"      âš ï¸  æœªæ‰¾åˆ°å¸‚å€¼æ•°æ®")
            
            if industry_data:
                industry_df = pd.DataFrame(industry_data)
                industry_df = industry_df.set_index(['date', 'ticker'])
                print(f"      âœ… åŠ è½½è¡Œä¸šæ•°æ®: {len(industry_df)} è¡Œ")
            else:
                industry_df = None
                print(f"      âš ï¸  æœªæ‰¾åˆ°è¡Œä¸šæ•°æ®")
            
            return market_cap_df, industry_df
            
        except Exception as e:
            print(f"      âš ï¸  åŠ è½½å¸‚å€¼å’Œè¡Œä¸šæ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None, None


def quick_evaluate(symbol: str,
                  feature_col: str,
                  data_root: str = "ML output/datasets/baseline_v1",
                  target_col: str = 'future_return_5d',
                  use_scaled: bool = True,
                  output_dir: Optional[str] = None,
                  enable_neutralization: bool = False,
                  db_config: Optional[Dict] = None) -> Dict:
    """
    å¿«é€Ÿè¯„ä¼°æ¥å£ï¼ˆä¸€é”®è°ƒç”¨ï¼‰
    
    Parameters:
    -----------
    symbol : str
        è‚¡ç¥¨ä»£ç 
    feature_col : str
        è¦è¯„ä¼°çš„ç‰¹å¾åˆ—
    data_root : str
        æ•°æ®æ ¹ç›®å½•
    target_col : str
        ç›®æ ‡åˆ—å
    use_scaled : bool
        æ˜¯å¦ä½¿ç”¨æ ‡å‡†åŒ–ç‰¹å¾
    output_dir : str, optional
        è¾“å‡ºç›®å½•
    enable_neutralization : bool
        æ˜¯å¦å¯ç”¨å¸‚å€¼/è¡Œä¸šä¸­æ€§åŒ–ï¼ˆä»…å¤šè‚¡ç¥¨æ¨¡å¼ï¼‰
    db_config : dict, optional
        æ•°æ®åº“é…ç½®ï¼Œæ ¼å¼: {'host': 'localhost', 'user': 'root', 'password': 'xxx', 'database': 'stock_data'}
        
    Returns:
    --------
    Dict
        è¯„ä¼°ç»“æœ
    """
    # åˆå§‹åŒ– DataLoader
    data_loader = DataLoader(
        data_root=data_root,
        enable_snapshot=False,
        enable_filtering=False,
        enable_pit_alignment=False,
        enable_influxdb=False
    )
    
    # åŠ è½½æ•°æ®
    features, targets = data_loader.load_features_and_targets(
        symbol=symbol,
        target_col=target_col,
        use_scaled=use_scaled
    )
    
    # æå–æ—¥æœŸèŒƒå›´
    dates = features.index.get_level_values('date')
    start_date = dates.min().strftime('%Y-%m-%d')
    end_date = dates.max().strftime('%Y-%m-%d')
    
    # åˆ›å»ºæ•°æ®åº“å¼•æ“ï¼ˆå¦‚æœæä¾›äº†é…ç½®ï¼‰
    db_engine = None
    if enable_neutralization and db_config and HAVE_STOCK_META:
        try:
            db_url = f"mysql+pymysql://{db_config['user']}:{db_config['password']}@{db_config['host']}/{db_config['database']}"
            db_engine = create_engine(db_url)
            print(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
    
    # åˆå§‹åŒ–é€‚é…å™¨
    adapter = CrossSectionAdapter(
        data_loader=data_loader,
        market_data_loader=None,
        enable_neutralization=enable_neutralization,
        db_engine=db_engine
    )
    
    # æ‰§è¡Œè¯„ä¼°
    results = adapter.evaluate_feature(
        features=features,
        targets=targets,
        feature_col=feature_col,
        symbol=symbol,
        start_date=start_date,
        end_date=end_date,
        output_dir=output_dir
    )
    
    return results


if __name__ == "__main__":
    """
    ä½¿ç”¨ç¤ºä¾‹
    """
    print("=" * 60)
    print("ğŸ§ª æ¨ªæˆªé¢è¯„ä¼°é€‚é…å™¨æµ‹è¯•")
    print("=" * 60)
    
    # å¿«é€Ÿè¯„ä¼°ç¤ºä¾‹
    symbol = "000001"
    feature_col = "volume"  # æ›¿æ¢ä¸ºä½ çš„ç‰¹å¾åˆ—å
    
    try:
        results = quick_evaluate(
            symbol=symbol,
            feature_col=feature_col,
            output_dir="ML output/reports/baseline_v1/factors"
        )
        
        print(f"\nâœ… è¯„ä¼°å®Œæˆ")
        print(f"   ICå‡å€¼: {results['ic_summary_5']['ic_mean']:.4f}")
        print(f"   ICIR: {results['ic_summary_5']['ic_ir']:.2f}")
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
