#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LightGBMå›å½’æ¨¡å‹
"""

import time
import pandas as pd
import numpy as np
from typing import Dict, Optional
from sklearn.metrics import mean_squared_error, mean_absolute_error

from .base_model import BaseModel

# å°è¯•å¯¼å…¥LightGBM
try:
    import lightgbm as lgb
    HAS_LIGHTGBM = True
except ImportError:
    HAS_LIGHTGBM = False
    print("âš ï¸ LightGBMæœªå®‰è£…ï¼Œè¯¥æ¨¡å‹å°†ä¸å¯ç”¨")


class LightGBMModel(BaseModel):
    """
    LightGBMå›å½’æ¨¡å‹å°è£…
    
    ç‰¹ç‚¹ï¼š
    - æ¢¯åº¦æå‡æ ‘æ¨¡å‹ï¼Œè¡¨è¾¾èƒ½åŠ›å¼º
    - è®­ç»ƒé€Ÿåº¦å¿«ï¼Œå†…å­˜å ç”¨å°
    - æ”¯æŒæ—©åœå’ŒéªŒè¯é›†è¯„ä¼°
    - æä¾›ç‰¹å¾é‡è¦æ€§
    """
    
    def __init__(self, params: Optional[Dict] = None):
        """
        åˆå§‹åŒ–LightGBMæ¨¡å‹
        
        Parameters:
        -----------
        params : dict, optional
            æ¨¡å‹å‚æ•°
        """
        if not HAS_LIGHTGBM:
            raise ImportError("LightGBMæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install lightgbm")
        
        super().__init__(name='LightGBM', params=params)
        
        # é»˜è®¤å‚æ•°
        default_params = {
            'objective': 'regression',
            'metric': 'mse',
            'n_estimators': 500,
            'learning_rate': 0.05,
            'num_leaves': 31,
            'max_depth': 8,
            'min_data_in_leaf': 20,
            'feature_fraction': 0.8,
            'bagging_fraction': 0.8,
            'bagging_freq': 5,
            'lambda_l1': 0.1,
            'lambda_l2': 0.1,
            'random_state': 42,
            'verbose': -1
        }
        default_params.update(self.params)
        self.params = default_params
    
    def fit(self, X: pd.DataFrame, y: pd.Series,
            X_valid: Optional[pd.DataFrame] = None,
            y_valid: Optional[pd.Series] = None) -> Dict:
        """
        è®­ç»ƒLightGBMæ¨¡å‹
        
        Parameters:
        -----------
        X : pd.DataFrame
            è®­ç»ƒç‰¹å¾
        y : pd.Series
            è®­ç»ƒç›®æ ‡
        X_valid : pd.DataFrame, optional
            éªŒè¯ç‰¹å¾ï¼ˆç”¨äºæ—©åœï¼‰
        y_valid : pd.Series, optional
            éªŒè¯ç›®æ ‡
            
        Returns:
        --------
        dict
            è®­ç»ƒç»“æœ
        """
        if not HAS_LIGHTGBM:
            raise ImportError("LightGBMæœªå®‰è£…")
        
        print(f"   ğŸ’¡ è®­ç»ƒ {self.name} æ¨¡å‹...")
        print(f"      ğŸ“Š è¿­ä»£æ¬¡æ•°: {self.params['n_estimators']}, å­¦ä¹ ç‡: {self.params['learning_rate']}")
        
        start_time = time.time()
        
        # ä¿å­˜ç‰¹å¾åç§°
        self.feature_names = list(X.columns)
        
        # åˆ›å»ºæ•°æ®é›†
        train_data = lgb.Dataset(X, label=y)
        
        # å‡†å¤‡å‚æ•°ï¼ˆç§»é™¤n_estimatorsï¼Œå› ä¸ºåœ¨trainingä¸­å•ç‹¬æŒ‡å®šï¼‰
        train_params = self.params.copy()
        n_estimators = train_params.pop('n_estimators', 500)
        
        # å‡†å¤‡è®­ç»ƒå‚æ•°
        callbacks = []
        valid_sets = [train_data]
        valid_names = ['train']
        
        # å¦‚æœæœ‰éªŒè¯é›†ï¼Œä½¿ç”¨æ—©åœ
        if X_valid is not None and y_valid is not None:
            valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)
            valid_sets.append(valid_data)
            valid_names.append('valid')
            
            # æ—©åœ
            callbacks.append(lgb.early_stopping(stopping_rounds=50, verbose=False))
            callbacks.append(lgb.log_evaluation(period=0))  # ä¸æ‰“å°æ—¥å¿—
        
        # è®­ç»ƒæ¨¡å‹
        self.model = lgb.train(
            train_params,
            train_data,
            num_boost_round=n_estimators,
            valid_sets=valid_sets,
            valid_names=valid_names,
            callbacks=callbacks
        )
        
        self.is_fitted = True
        
        training_time = time.time() - start_time
        
        # è¯„ä¼°è®­ç»ƒé›†
        y_pred_train = self.model.predict(X)
        train_mse = mean_squared_error(y, y_pred_train)
        train_mae = mean_absolute_error(y, y_pred_train)
        
        results = {
            'model_name': self.name,
            'training_time': training_time,
            'train_samples': len(X),
            'train_mse': train_mse,
            'train_mae': train_mae,
            'n_features': len(self.feature_names),
            'n_estimators': self.model.num_trees(),
            'best_iteration': self.model.best_iteration
        }
        
        # è¯„ä¼°éªŒè¯é›†
        if X_valid is not None and y_valid is not None:
            y_pred_valid = self.model.predict(X_valid)
            valid_mse = mean_squared_error(y_valid, y_pred_valid)
            valid_mae = mean_absolute_error(y_valid, y_pred_valid)
            
            results['valid_samples'] = len(X_valid)
            results['valid_mse'] = valid_mse
            results['valid_mae'] = valid_mae
            
            print(f"      ğŸ“Š éªŒè¯é›† MSE: {valid_mse:.6f}, MAE: {valid_mae:.6f}")
            print(f"      ğŸ¯ æœ€ä½³è¿­ä»£: {self.model.best_iteration}")
        
        print(f"      â±ï¸  è®­ç»ƒæ—¶é—´: {training_time:.2f}ç§’")
        print(f"      ğŸ“Š è®­ç»ƒé›† MSE: {train_mse:.6f}, MAE: {train_mae:.6f}")
        
        return results
    
    def predict(self, X: pd.DataFrame) -> np.ndarray:
        """
        é¢„æµ‹
        
        Parameters:
        -----------
        X : pd.DataFrame
            ç‰¹å¾æ•°æ®
            
        Returns:
        --------
        np.ndarray
            é¢„æµ‹ç»“æœ
        """
        if not self.is_fitted:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒï¼Œæ— æ³•é¢„æµ‹")
        
        # ç¡®ä¿ç‰¹å¾é¡ºåºä¸€è‡´
        if self.feature_names is not None:
            X = X[self.feature_names]
        
        return self.model.predict(X)
    
    def get_feature_importance(self, importance_type: str = 'gain') -> Optional[pd.Series]:
        """
        è·å–ç‰¹å¾é‡è¦æ€§
        
        Parameters:
        -----------
        importance_type : str
            é‡è¦æ€§ç±»å‹: 'gain' æˆ– 'split'
            
        Returns:
        --------
        pd.Series
            ç‰¹å¾é‡è¦æ€§
        """
        if not self.is_fitted:
            return None
        
        importance = self.model.feature_importance(importance_type=importance_type)
        
        return pd.Series(importance, index=self.feature_names).sort_values(ascending=False)


if __name__ == "__main__":
    """
    æµ‹è¯•LightGBMæ¨¡å‹
    """
    if not HAS_LIGHTGBM:
        print("âŒ LightGBMæœªå®‰è£…ï¼Œè·³è¿‡æµ‹è¯•")
        print("   å®‰è£…å‘½ä»¤: pip install lightgbm")
    else:
        print("ğŸ§ª æµ‹è¯•LightGBMæ¨¡å‹")
        print("=" * 50)
        
        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        np.random.seed(42)
        n_samples = 1000
        n_features = 10
        
        X = pd.DataFrame(
            np.random.randn(n_samples, n_features),
            columns=[f'feature_{i}' for i in range(n_features)]
        )
        # æ·»åŠ éçº¿æ€§å…³ç³»
        y = pd.Series(X['feature_0']**2 + X['feature_1'] * X['feature_2'] + np.random.randn(n_samples) * 0.1)
        
        # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
        split_idx = int(n_samples * 0.8)
        X_train, X_valid = X[:split_idx], X[split_idx:]
        y_train, y_valid = y[:split_idx], y[split_idx:]
        
        # è®­ç»ƒæ¨¡å‹
        print("\nğŸ’¡ è®­ç»ƒLightGBMæ¨¡å‹")
        model = LightGBMModel(params={
            'n_estimators': 100,  # æµ‹è¯•ç”¨è¾ƒå°‘çš„è¿­ä»£
            'learning_rate': 0.1,
            'num_leaves': 15
        })
        results = model.fit(X_train, y_train, X_valid, y_valid)
        print(f"âœ… è®­ç»ƒç»“æœ: {results}")
        
        # æµ‹è¯•é¢„æµ‹
        print("\nğŸ¯ æµ‹è¯•é¢„æµ‹")
        y_pred = model.predict(X_valid)
        print(f"é¢„æµ‹å½¢çŠ¶: {y_pred.shape}")
        print(f"é¢„æµ‹å‰5ä¸ªå€¼: {y_pred[:5]}")
        
        # æµ‹è¯•ç‰¹å¾é‡è¦æ€§
        print("\nğŸ“Š ç‰¹å¾é‡è¦æ€§ (gain)")
        importance_gain = model.get_feature_importance('gain')
        print(f"Top 5 ç‰¹å¾:\n{importance_gain.head()}")
        
        print("\nğŸ“Š ç‰¹å¾é‡è¦æ€§ (split)")
        importance_split = model.get_feature_importance('split')
        print(f"Top 5 ç‰¹å¾:\n{importance_split.head()}")
        
        print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡")
