#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é›†æˆç¤ºä¾‹ï¼šåœ¨è®­ç»ƒæµç¨‹ä¸­ä½¿ç”¨æ¨ªæˆªé¢è¯„ä¼°

åŠŸèƒ½ï¼š
1. å±•ç¤ºå¦‚ä½•åœ¨ train_models.py ä¸­é›†æˆæ¨ªæˆªé¢è¯„ä¼°
2. åœ¨ç‰¹å¾å·¥ç¨‹åè¯„ä¼°ç‰¹å¾è´¨é‡
3. åœ¨æ¨¡å‹è®­ç»ƒåè¯„ä¼°é¢„æµ‹è´¨é‡
"""

import os
import sys
import pandas as pd
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
ml_root = os.path.dirname(current_dir)
if ml_root not in sys.path:
    sys.path.insert(0, ml_root)

# å¯¼å…¥æ¨¡å—
from data.data_loader import DataLoader
from evaluation import CrossSectionAdapter


def example_1_evaluate_single_feature():
    """
    ç¤ºä¾‹1ï¼šè¯„ä¼°å•ä¸ªç‰¹å¾
    
    é€‚ç”¨åœºæ™¯ï¼š
    - æ£€éªŒæŸä¸ªæ–°ç‰¹å¾æ˜¯å¦æœ‰é¢„æµ‹èƒ½åŠ›
    - è°ƒè¯•ç‰¹å¾å·¥ç¨‹
    """
    print("=" * 60)
    print("ç¤ºä¾‹1ï¼šè¯„ä¼°å•ä¸ªç‰¹å¾")
    print("=" * 60)
    
    # 1. åˆå§‹åŒ– DataLoader
    data_loader = DataLoader(
        data_root="ML output/datasets/baseline_v1",
        enable_snapshot=False,
        enable_filtering=False,
        enable_pit_alignment=False,
        enable_influxdb=False
    )
    
    # 2. åŠ è½½æ•°æ®
    symbol = "000001"
    features, targets = data_loader.load_features_and_targets(
        symbol=symbol,
        target_col='future_return_5d',
        use_scaled=True  # ä½¿ç”¨æ ‡å‡†åŒ–åçš„ç‰¹å¾
    )
    
    print(f"\nâœ… æ•°æ®åŠ è½½å®Œæˆ:")
    print(f"   ç‰¹å¾æ•°: {features.shape[1]}")
    print(f"   æ ·æœ¬æ•°: {len(features)}")
    
    # 3. åˆ›å»ºé€‚é…å™¨
    adapter = CrossSectionAdapter(
        data_loader=data_loader,
        market_data_loader=None,  # å¯é€‰
        enable_neutralization=False  # å•è‚¡ç¥¨ä¸éœ€è¦ä¸­æ€§åŒ–
    )
    
    # 4. è¯„ä¼°å•ä¸ªç‰¹å¾ï¼ˆé€‰æ‹©ç¬¬ä¸€ä¸ªç‰¹å¾ä½œä¸ºç¤ºä¾‹ï¼‰
    feature_to_test = features.columns[0]
    
    dates = features.index.get_level_values('date')
    start_date = dates.min().strftime('%Y-%m-%d')
    end_date = dates.max().strftime('%Y-%m-%d')
    
    results = adapter.evaluate_feature(
        features=features,
        targets=targets,
        feature_col=feature_to_test,
        symbol=symbol,
        start_date=start_date,
        end_date=end_date,
        forward_periods=[5],
        quantiles=5,
        output_dir="ML output/reports/baseline_v1/factors"
    )
    
    # 5. è§£è¯»ç»“æœ
    ic_summary = results['ic_summary_5']
    
    print(f"\nğŸ“Š è¯„ä¼°ç»“æœ:")
    print(f"   ç‰¹å¾åç§°: {feature_to_test}")
    print(f"   ICå‡å€¼: {ic_summary['ic_mean']:.4f}")
    print(f"   ICIR: {ic_summary['ic_ir']:.2f}")
    print(f"   ICèƒœç‡: {ic_summary['ic_win_rate']:.2%}")
    print(f"   p-value: {ic_summary['p_value']:.4f}")
    
    if ic_summary['ic_ir'] > 1.0:
        print(f"   âœ… ä¼˜ç§€ç‰¹å¾")
    elif ic_summary['ic_ir'] > 0.5:
        print(f"   âš ï¸  åˆæ ¼ç‰¹å¾")
    else:
        print(f"   âŒ å¼±ç‰¹å¾")


def example_2_batch_evaluate_features():
    """
    ç¤ºä¾‹2ï¼šæ‰¹é‡è¯„ä¼°æ‰€æœ‰ç‰¹å¾
    
    é€‚ç”¨åœºæ™¯ï¼š
    - ç‰¹å¾ç­›é€‰ï¼ˆä¿ç•™é«˜è´¨é‡ç‰¹å¾ï¼‰
    - ç‰¹å¾å·¥ç¨‹åçš„éªŒè¯
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹2ï¼šæ‰¹é‡è¯„ä¼°æ‰€æœ‰ç‰¹å¾")
    print("=" * 60)
    
    # 1. åˆå§‹åŒ–
    data_loader = DataLoader(
        data_root="ML output/datasets/baseline_v1",
        enable_snapshot=False,
        enable_filtering=False,
        enable_pit_alignment=False,
        enable_influxdb=False
    )
    
    adapter = CrossSectionAdapter(
        data_loader=data_loader,
        market_data_loader=None,
        enable_neutralization=False
    )
    
    # 2. åŠ è½½æ•°æ®
    symbol = "000001"
    features, targets = data_loader.load_features_and_targets(
        symbol=symbol,
        target_col='future_return_5d',
        use_scaled=True
    )
    
    # 3. æ‰¹é‡è¯„ä¼°ï¼ˆç¤ºä¾‹ï¼šä»…è¯„ä¼°å‰10ä¸ªç‰¹å¾ä»¥èŠ‚çœæ—¶é—´ï¼‰
    dates = features.index.get_level_values('date')
    start_date = dates.min().strftime('%Y-%m-%d')
    end_date = dates.max().strftime('%Y-%m-%d')
    
    summary_df = adapter.evaluate_all_features(
        features=features,
        targets=targets,
        symbol=symbol,
        start_date=start_date,
        end_date=end_date,
        output_dir="ML output/reports/baseline_v1/factors",
        top_k=10  # ä»…è¯„ä¼°å‰10ä¸ªç‰¹å¾
    )
    
    # 4. ç‰¹å¾ç­›é€‰
    qualified_features = summary_df[summary_df['qualified']]['feature'].tolist()
    
    print(f"\nğŸ“Š ç‰¹å¾ç­›é€‰ç»“æœ:")
    print(f"   æ€»ç‰¹å¾æ•°: {len(summary_df)}")
    print(f"   åˆæ ¼ç‰¹å¾æ•°: {len(qualified_features)}")
    print(f"   åˆæ ¼ç‡: {len(qualified_features) / len(summary_df):.2%}")
    
    if qualified_features:
        print(f"\n   âœ… åˆæ ¼ç‰¹å¾åˆ—è¡¨:")
        for feat in qualified_features:
            ic = summary_df[summary_df['feature'] == feat]['ic_mean'].values[0]
            icir = summary_df[summary_df['feature'] == feat]['icir'].values[0]
            print(f"      - {feat}: IC={ic:.4f}, ICIR={icir:.2f}")


def example_3_integrate_with_training():
    """
    ç¤ºä¾‹3ï¼šé›†æˆåˆ°è®­ç»ƒæµç¨‹ï¼ˆä¼ªä»£ç ï¼‰
    
    å±•ç¤ºå¦‚ä½•åœ¨ train_models.py ä¸­é›†æˆ
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹3ï¼šé›†æˆåˆ°è®­ç»ƒæµç¨‹ï¼ˆä¼ªä»£ç ï¼‰")
    print("=" * 60)
    
    code_example = '''
# åœ¨ train_models.py ä¸­é›†æˆæ¨ªæˆªé¢è¯„ä¼°

def train_with_feature_evaluation(config):
    """è®­ç»ƒæµç¨‹ + ç‰¹å¾è¯„ä¼°"""
    
    # 1. åŠ è½½æ•°æ®
    data_loader = DataLoader(...)
    features, targets = data_loader.load_features_and_targets(...)
    
    # ===== æ–°å¢ï¼šç‰¹å¾è¯„ä¼°é˜¶æ®µ =====
    from evaluation import CrossSectionAdapter
    
    adapter = CrossSectionAdapter(
        data_loader=data_loader,
        market_data_loader=None,
        enable_neutralization=False
    )
    
    # æ‰¹é‡è¯„ä¼°ç‰¹å¾
    summary_df = adapter.evaluate_all_features(
        features=features,
        targets=targets,
        symbol=config['data']['symbol'],
        start_date=...,
        end_date=...,
        output_dir="ML output/reports/baseline_v1/factors"
    )
    
    # ç­›é€‰åˆæ ¼ç‰¹å¾
    qualified_features = summary_df[summary_df['qualified']]['feature'].tolist()
    
    # ä»…ä½¿ç”¨åˆæ ¼ç‰¹å¾è®­ç»ƒ
    features_filtered = features[qualified_features]
    
    print(f"ç‰¹å¾ç­›é€‰: {len(features.columns)} -> {len(qualified_features)}")
    # ===== ç‰¹å¾è¯„ä¼°é˜¶æ®µç»“æŸ =====
    
    # 2. ç»§ç»­åç»­è®­ç»ƒæµç¨‹...
    X_train, X_test, y_train, y_test = time_series_split(...)
    
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)
    
    # 3. æ¨¡å‹è¯„ä¼°...
    '''
    
    print(code_example)


def example_4_quick_api():
    """
    ç¤ºä¾‹4ï¼šä½¿ç”¨å¿«æ·API
    
    é€‚ç”¨åœºæ™¯ï¼š
    - å¿«é€ŸéªŒè¯æŸä¸ªç‰¹å¾
    - Jupyter Notebook äº¤äº’å¼åˆ†æ
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹4ï¼šä½¿ç”¨å¿«æ·API")
    print("=" * 60)
    
    from evaluation import quick_evaluate
    
    # ä¸€è¡Œä»£ç è¯„ä¼°ç‰¹å¾
    results = quick_evaluate(
        symbol="000001",
        feature_col="volume",  # æ›¿æ¢ä¸ºå®é™…ç‰¹å¾å
        data_root="ML output/datasets/baseline_v1",
        target_col='future_return_5d',
        use_scaled=True,
        output_dir="ML output/reports/baseline_v1/factors"
    )
    
    print(f"\nâœ… å¿«é€Ÿè¯„ä¼°å®Œæˆ:")
    print(f"   ICå‡å€¼: {results['ic_summary_5']['ic_mean']:.4f}")
    print(f"   ICIR: {results['ic_summary_5']['ic_ir']:.2f}")


def main():
    """
    è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    """
    print("\n" + "ğŸš€" * 30)
    print("æ¨ªæˆªé¢è¯„ä¼°é›†æˆç¤ºä¾‹")
    print("ğŸš€" * 30 + "\n")
    
    try:
        # ç¤ºä¾‹1ï¼šè¯„ä¼°å•ä¸ªç‰¹å¾
        example_1_evaluate_single_feature()
        
        # ç¤ºä¾‹2ï¼šæ‰¹é‡è¯„ä¼°ï¼ˆå¯é€‰ï¼Œæ¯”è¾ƒè€—æ—¶ï¼‰
        # example_2_batch_evaluate_features()
        
        # ç¤ºä¾‹3ï¼šé›†æˆä¼ªä»£ç 
        example_3_integrate_with_training()
        
        # ç¤ºä¾‹4ï¼šå¿«æ·APIï¼ˆå¯é€‰ï¼‰
        # example_4_quick_api()
        
        print("\n" + "=" * 60)
        print("âœ… æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆ")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ ç¤ºä¾‹è¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
