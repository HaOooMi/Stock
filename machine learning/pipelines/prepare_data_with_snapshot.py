#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®æ¸…æ´—ä¸å¿«ç…§å±‚ - é›†æˆç¤ºä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ–°çš„æ•°æ®æ¸…æ´—å’Œå¿«ç…§åŠŸèƒ½

åŠŸèƒ½æµç¨‹ï¼š
1. åŠ è½½åŸå§‹æ•°æ®
2. åº”ç”¨äº¤æ˜“å¯è¡Œæ€§è¿‡æ»¤ï¼ˆ7å±‚ï¼‰
3. PITå¯¹é½éªŒè¯
4. åˆ›å»ºæ•°æ®å¿«ç…§
5. ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š
"""

import os
import sys
import pandas as pd
import yaml
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
current_dir = os.path.dirname(os.path.abspath(__file__))
ml_root = os.path.dirname(current_dir)
project_root = os.path.dirname(ml_root)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from data.data_loader import DataLoader


def load_config(config_path: str = "configs/ml_baseline.yml"):
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_file = os.path.join(ml_root, config_path)
    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("æ•°æ®æ¸…æ´—ä¸å¿«ç…§å±‚ - é›†æˆæ¼”ç¤º")
    print("=" * 70)
    print(f"è¿è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)
    
    # 1. åŠ è½½é…ç½®
    print("\n[æ­¥éª¤1] åŠ è½½é…ç½®")
    config = load_config()
    
    symbol = config['data']['symbol']
    start_date = config['data']['start_date']
    end_date = config['data']['end_date']
    target_col = config['target']['name']
    random_seed = config['runtime']['random_seed']
    
    print(f"   è‚¡ç¥¨ä»£ç : {symbol}")
    print(f"   æ—¶é—´èŒƒå›´: {start_date} ~ {end_date}")
    print(f"   ç›®æ ‡å˜é‡: {target_col}")
    print(f"   éšæœºç§å­: {random_seed}")
    
    # 2. åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨ï¼ˆå¯ç”¨æ‰€æœ‰åŠŸèƒ½ï¼‰
    print("\n[æ­¥éª¤2] åˆå§‹åŒ–å¢å¼ºç‰ˆæ•°æ®åŠ è½½å™¨")
    
    # æå–è¿‡æ»¤å™¨é…ç½®
    filter_config = {
        'min_volume': config['data']['universe']['min_volume'],
        'min_amount': config['data']['universe']['min_amount'],
        'min_price': config['data']['universe']['min_price'],
        'min_turnover': config['data']['universe']['min_turnover'],
        'min_listing_days': config['data']['universe']['min_listing_days'],
        'exclude_st': config['data']['universe']['exclude_st'],
        'exclude_limit_moves': config['data']['universe']['exclude_limit_moves'],
        'limit_threshold': config['data']['universe']['limit_threshold']
    }
    
    loader = DataLoader(
        data_root=os.path.join(ml_root, "ML output/datasets/baseline_v1"),
        enable_snapshot=config['data']['snapshot']['enabled'],
        enable_filtering=True,
        enable_pit_alignment=config['data']['pit']['enabled'],
        filter_config=filter_config
    )
    
    # 3. åŠ è½½æ•°æ®å¹¶åˆ›å»ºå¿«ç…§
    print("\n[æ­¥éª¤3] åŠ è½½æ•°æ®å¹¶åˆ›å»ºå¿«ç…§")
    
    try:
        features, targets, snapshot_id = loader.load_with_snapshot(
            symbol=symbol,
            start_date=start_date,
            end_date=end_date,
            target_col=target_col,
            use_scaled=config['features']['use_scaled_features'],
            filters=filter_config,
            random_seed=random_seed,
            save_parquet=config['data']['snapshot']['save_parquet']
        )
        
        print(f"\nâœ… æ•°æ®åŠ è½½æˆåŠŸ!")
        print(f"   å¿«ç…§ID: {snapshot_id}")
        print(f"   ç‰¹å¾å½¢çŠ¶: {features.shape}")
        print(f"   ç›®æ ‡å½¢çŠ¶: {targets.shape}")
        
        # 4. å±•ç¤ºæ•°æ®è´¨é‡ç»Ÿè®¡
        print("\n[æ­¥éª¤4] æ•°æ®è´¨é‡ç»Ÿè®¡")
        print(f"   ç‰¹å¾ç¼ºå¤±ç‡: {features.isna().sum().sum() / features.size:.2%}")
        print(f"   ç›®æ ‡ç¼ºå¤±ç‡: {targets.isna().sum() / len(targets):.2%}")
        print(f"   æ—¶é—´èŒƒå›´: {features.index.get_level_values('date').min().date()} ~ "
              f"{features.index.get_level_values('date').max().date()}")
        
        # 5. å±•ç¤ºç‰¹å¾åˆ—è¡¨
        print("\n[æ­¥éª¤5] ç‰¹å¾åˆ—è¡¨ï¼ˆå‰10ä¸ªï¼‰")
        for i, col in enumerate(features.columns[:10], 1):
            print(f"   {i:2d}. {col}")
        print(f"   ... å…± {len(features.columns)} ä¸ªç‰¹å¾")
        
        # 6. å¿«ç…§ä¿¡æ¯
        if snapshot_id and loader.snapshot_mgr:
            print("\n[æ­¥éª¤6] å¿«ç…§ä¿¡æ¯")
            snapshots = loader.snapshot_mgr.list_snapshots()
            print("\nç°æœ‰å¿«ç…§:")
            print(snapshots.to_string(index=False))
            
            # è´¨é‡æŠ¥å‘Šä½ç½®
            quality_report_path = os.path.join(
                loader.snapshot_mgr.quality_reports_dir,
                f"{snapshot_id}.json"
            )
            if os.path.exists(quality_report_path):
                print(f"\n   ğŸ“Š æ•°æ®è´¨é‡æŠ¥å‘Š: {quality_report_path}")
        
        # 7. éªŒæ”¶æ£€æŸ¥
        print("\n[æ­¥éª¤7] æ•°æ®éªŒæ”¶æ£€æŸ¥")
        
        # æ£€æŸ¥1: å¯äº¤æ˜“æ ·æœ¬è§„æ¨¡
        n_samples = len(features)
        min_samples = 200  # æ ¹æ®å®ªç« è¦æ±‚
        sample_check = n_samples >= min_samples
        print(f"   {'âœ…' if sample_check else 'âŒ'} æ ·æœ¬è§„æ¨¡: {n_samples} (æœ€ä½ {min_samples})")
        
        # æ£€æŸ¥2: PITå¯¹é½
        if loader.pit_aligner:
            combined = features.copy()
            combined[target_col] = targets
            pit_results = loader.pit_aligner.validate_pit_alignment(combined, target_col)
            pit_check = pit_results.get('overall_pass', False)
            print(f"   {'âœ…' if pit_check else 'âŒ'} PITå¯¹é½éªŒè¯")
        else:
            pit_check = True
            print(f"   âš ï¸  PITå¯¹é½éªŒè¯ï¼ˆæœªå¯ç”¨ï¼‰")
        
        # æ£€æŸ¥3: æ•°æ®è´¨é‡
        if snapshot_id and loader.snapshot_mgr:
            import json
            with open(quality_report_path, 'r', encoding='utf-8') as f:
                quality_report = json.load(f)
            quality_check = quality_report.get('overall_quality') == 'PASS'
            red_flags = quality_report.get('red_flags_count', 0)
            print(f"   {'âœ…' if quality_check else 'âŒ'} æ•°æ®è´¨é‡: {quality_report.get('overall_quality')} ({red_flags} ä¸ªçº¢ç¯)")
        else:
            quality_check = True
            print(f"   âš ï¸  æ•°æ®è´¨é‡æ£€æŸ¥ï¼ˆæœªå¯ç”¨å¿«ç…§ï¼‰")
        
        # æ€»ä½“éªŒæ”¶
        all_passed = sample_check and pit_check and quality_check
        
        print("\n" + "=" * 70)
        print(f"{'âœ… éªŒæ”¶é€šè¿‡' if all_passed else 'âŒ éªŒæ”¶å¤±è´¥'}")
        print("=" * 70)
        
        if all_passed:
            print(f"\nğŸ‰ æ­å–œ! æ•°æ®æ¸…æ´—ä¸å¿«ç…§å±‚éªŒæ”¶é€šè¿‡")
            print(f"   å¿«ç…§ID: {snapshot_id}")
            print(f"   å¯ç”¨äºåç»­æ¨¡å‹è®­ç»ƒ")
        else:
            print(f"\nâš ï¸  è­¦å‘Š: éƒ¨åˆ†éªŒæ”¶é¡¹æœªé€šè¿‡ï¼Œè¯·æ£€æŸ¥æ•°æ®è´¨é‡")
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
