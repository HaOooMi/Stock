#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å› å­å‡†å¤‡ç®¡é“ - å› å­å·¥å‚å®Œæ•´æµç¨‹

æœ¬ç®¡é“å®Œå…¨åŸºäºå·²æœ‰çš„æ¨ªæˆªé¢è¯„ä¼°æ¡†æ¶ (evaluation/) æ„å»ºï¼Œ
å®ç°ä»å› å­ç”Ÿæˆåˆ°è´¨é‡æ£€æŸ¥ã€æŠ¥å‘Šè¾“å‡ºçš„å…¨æµç¨‹è‡ªåŠ¨åŒ–ã€‚

æµç¨‹ï¼š
1. åŠ è½½å¸‚åœºæ•°æ®ï¼ˆDataLoaderï¼‰
   - ä»InfluxDBåŠ è½½OHLCVæ•°æ®
   - åº”ç”¨å¯äº¤æ˜“æ€§è¿‡æ»¤
   
2. ç”Ÿæˆå› å­ï¼ˆFactorFactoryï¼‰
   - åŠ¨é‡æ—: ROC_N, Price_to_SMA, RankMomentum
   - æ³¢åŠ¨ç‡æ—: RealizedVol, Parkinson, Skewness
   - é‡ä»·æ—: Turnover, VolumePriceCorr, VWAP_Dev
   
3. æ¨ªæˆªé¢è´¨é‡æ£€æŸ¥ â­æ ¸å¿ƒæ­¥éª¤
   ä½¿ç”¨ evaluation/CrossSectionAnalyzer è¿›è¡Œå®Œæ•´è¯„ä¼°ï¼š
   - calculate_forward_returns: è®¡ç®—è¿œæœŸæ”¶ç›Š
   - preprocess: Winsorize + æ ‡å‡†åŒ– + ä¸­æ€§åŒ–
   - analyze: è®¡ç®—IC/ICIR/Spread/å•è°ƒæ€§
   - è¯„ä¼°æ ‡å‡†: ICâ‰¥0.02, ICIRâ‰¥0.5, Spread>0
   
4. å› å­å…¥åº“ï¼ˆFactorLibraryManagerï¼‰
   - åªæœ‰é€šè¿‡æ¨ªæˆªé¢æ£€æŸ¥çš„å› å­æ‰å…¥åº“
   - ä¿å­˜è´¨é‡æŠ¥å‘Šå’Œå…ƒæ•°æ®
   
5. ç”ŸæˆæŠ¥å‘Š â­è¾“å‡ºæ ‡å‡†åŒ–
   ä½¿ç”¨ evaluation/tearsheet ç”ŸæˆæŠ¥å‘Šï¼š
   - HTML tearsheet: tearsheet_{factor}_{period}.html
   - ICåºåˆ—CSV: ic_{factor}_{period}.csv
   - åˆ†ä½æ•°æ”¶ç›ŠCSV: quantile_returns_{factor}_{period}.csv
   - è‡ªåŠ¨ç”Ÿæˆæ‰€æœ‰å›¾è¡¨ (ICèµ°å»Šå›¾ã€ç´¯è®¡æ”¶ç›Šã€Spreadç­‰)

è¾“å‡ºç›®å½•ç»“æ„:
/ML output/reports/baseline_v1/factors/
  â”œâ”€â”€ tearsheet_ROC_20_5d.html
  â”œâ”€â”€ ic_ROC_20_5d.csv
  â””â”€â”€ quantile_returns_ROC_20_5d.csv
/ML output/figures/baseline_v1/factors/
  â”œâ”€â”€ ic_series_ROC_20_5d.png
  â”œâ”€â”€ quantile_cumret_ROC_20_5d.png
  â””â”€â”€ spread_cumret_ROC_20_5d.png
/ML output/datasets/baseline_v1/
  â””â”€â”€ qualified_factors_YYYYMMDD.parquet

éªŒæ”¶æ ‡å‡†:
- â‰¥10ä¸ªç¨³å®šå› å­é€šè¿‡æ£€æŸ¥
- æ¨ªæˆªé¢Rank ICæ˜¾è‘— (IC>0.02, p<0.05)
- åˆå…¥åç»„åˆICæœ‰å®è´¨æå‡ (>0.03)

è¯¦ç»†æ–‡æ¡£: pipelines/README_PREPARE_FACTORS.md
"""

import os
import sys
import yaml
import pandas as pd
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
ml_root = os.path.dirname(current_dir)
if ml_root not in sys.path:
    sys.path.insert(0, ml_root)

from features.factor_factory import FactorFactory
from features.factor_library_manager import FactorLibraryManager
from data.data_loader import DataLoader
# ä½¿ç”¨ä½ å·²æœ‰çš„æ¨ªæˆªé¢è¯„ä¼°æ¡†æ¶ï¼
from evaluation.cross_section_analyzer import CrossSectionAnalyzer
from evaluation.cross_section_metrics import calculate_forward_returns
from evaluation.factor_preprocessing import preprocess_factor_pipeline
from evaluation.tearsheet import generate_html_tearsheet
# ä½¿ç”¨factor_quality_checkerè¿›è¡Œè¡¥å……æ£€æŸ¥ï¼ˆICåŠè¡°æœŸã€PSI/KSï¼‰
from evaluation.factor_quality_checker import FactorQualityChecker


def load_config(config_path: str = "configs/ml_baseline.yml") -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    if not os.path.isabs(config_path):
        config_path = os.path.join(ml_root, config_path)
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    return config


def prepare_factors(config_path: str = "configs/ml_baseline.yml",
                   start_date: str = "2020-01-01",
                   end_date: str = "2024-12-31",
                   tickers: list = None):
    """
    å› å­å‡†å¤‡å®Œæ•´æµç¨‹
    
    Parameters:
    -----------
    config_path : str
        é…ç½®æ–‡ä»¶è·¯å¾„
    start_date : str
        å¼€å§‹æ—¥æœŸ
    end_date : str
        ç»“æŸæ—¥æœŸ
    tickers : list, optional
        è‚¡ç¥¨åˆ—è¡¨ï¼ˆNoneè¡¨ç¤ºå…¨å¸‚åœºï¼‰
    """
    print("=" * 80)
    print("å› å­å·¥å‚ v1 - å®Œæ•´æµç¨‹")
    print("=" * 80)
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"æ•°æ®åŒºé—´: {start_date} ~ {end_date}")
    print(f"è‚¡ç¥¨èŒƒå›´: {tickers if tickers else 'å…¨å¸‚åœº'}")
    print()
    
    # 1. åŠ è½½é…ç½®
    print("\n" + "=" * 80)
    print("æ­¥éª¤ 1: åŠ è½½é…ç½®")
    print("=" * 80)
    config = load_config(config_path)
    
    # ä»é…ç½®ä¸­æå–å‚æ•°
    influxdb_config = config['data']['influxdb']
    target_config = config['targets']
    tradability_config = config['data'].get('tradability_filter', {})
    
    print(f"âœ… é…ç½®åŠ è½½å®Œæˆ")
    print(f"   InfluxDB: {influxdb_config['url']}")
    print(f"   é¢„æµ‹ç›®æ ‡: {target_config['type']} ({target_config['horizon']}æ—¥)")
    
    # 2. åŠ è½½æ•°æ®ï¼ˆä½¿ç”¨MarketDataLoaderæ‰¹é‡åŠ è½½ï¼‰
    print("\n" + "=" * 80)
    print("æ­¥éª¤ 2: åŠ è½½å¸‚åœºæ•°æ®")
    print("=" * 80)
    
    # ä½¿ç”¨MarketDataLoaderæ‰¹é‡åŠ è½½å¤šè‚¡ç¥¨æ•°æ®
    from data.market_data_loader import MarketDataLoader
    
    market_loader = MarketDataLoader(
        url=influxdb_config['url'],
        token=influxdb_config['token'],
        org=influxdb_config['org'],
        bucket=influxdb_config['bucket']
    )
    
    # å¦‚æœæœªæŒ‡å®štickersï¼Œå¯ä»¥ä»é…ç½®æˆ–æ•°æ®åº“è·å–è‚¡ç¥¨æ± 
    if not tickers:
        # TODO: ä»é…ç½®æ–‡ä»¶æˆ–æ•°æ®åº“è·å–è‚¡ç¥¨æ± 
        print(f"\nâš ï¸  æœªæŒ‡å®šè‚¡ç¥¨åˆ—è¡¨ï¼Œè¯·åœ¨é…ç½®ä¸­è®¾ç½®æˆ–ä¼ å…¥tickerså‚æ•°")
        raise ValueError("å¿…é¡»æä¾›tickerså‚æ•°")
    
    # æ‰¹é‡åŠ è½½å¸‚åœºæ•°æ®ï¼ˆè¿”å›MultiIndex[date, ticker]æ ¼å¼ï¼‰
    features_df = market_loader.load_market_data_batch(
        symbols=tickers,
        start_date=start_date,
        end_date=end_date
    )
    
    if features_df.empty:
        raise ValueError(f"æœªåŠ è½½åˆ°ä»»ä½•æ•°æ®ï¼Œè¯·æ£€æŸ¥InfluxDBè¿æ¥å’Œè‚¡ç¥¨ä»£ç ")
    
    # è®¡ç®—ç›®æ ‡å˜é‡ï¼ˆè¿œæœŸæ”¶ç›Šï¼‰
    from evaluation.cross_section_metrics import calculate_forward_returns
    
    prices_df = features_df[['close']]
    targets_df = calculate_forward_returns(
        prices=prices_df,
        periods=[1, 5, 10, 20],
        method='simple'
    )
    
    print(f"\nâœ… æ•°æ®åŠ è½½å®Œæˆ")
    print(f"   ç‰¹å¾æ•°æ®å½¢çŠ¶: {features_df.shape}")
    print(f"   ç›®æ ‡æ•°æ®å½¢çŠ¶: {targets_df.shape}")
    print(f"   æ—¥æœŸèŒƒå›´: {features_df.index.get_level_values('date').min()} ~ {features_df.index.get_level_values('date').max()}")
    print(f"   è‚¡ç¥¨æ•°é‡: {features_df.index.get_level_values('ticker').nunique()}")
    print(f"   è‚¡ç¥¨åˆ—è¡¨: {', '.join(features_df.index.get_level_values('ticker').unique()[:5])}..." if len(tickers) > 5 else f"   è‚¡ç¥¨åˆ—è¡¨: {', '.join(tickers)}")
    
    # 3. ç”Ÿæˆå› å­
    print("\n" + "=" * 80)
    print("æ­¥éª¤ 3: ç”Ÿæˆå› å­")
    print("=" * 80)
    
    factory = FactorFactory()
    
    # ç”Ÿæˆæ‰€æœ‰å› å­æ—
    print("\nğŸ­ ç”Ÿæˆå› å­...")
    all_factors_df = factory.generate_all_factors(features_df)
    
    print(f"\nâœ… å› å­ç”Ÿæˆå®Œæˆ")
    print(f"   ç”Ÿæˆå› å­æ•°: {all_factors_df.shape[1]}")
    print(f"   å› å­æ—ç»Ÿè®¡:")
    
    # ç»Ÿè®¡å„æ—å› å­
    factor_families = factory.get_factor_registry()
    family_counts = {}
    for factor_info in factor_families.values():
        family = factor_info['family']
        family_counts[family] = family_counts.get(family, 0) + 1
    
    for family, count in family_counts.items():
        print(f"   - {family}: {count} ä¸ª")
    
    # 4. æ¨ªæˆªé¢è´¨é‡æ£€æŸ¥ï¼ˆä½¿ç”¨ä½ å·²æœ‰çš„è¯„ä¼°æ¡†æ¶ï¼ï¼‰
    print("\n" + "=" * 80)
    print("æ­¥éª¤ 4: æ¨ªæˆªé¢å› å­è¯„ä¼°ï¼ˆAlphalensé£æ ¼ï¼‰")
    print("=" * 80)
    
    # å‡†å¤‡ä»·æ ¼æ•°æ®ç”¨äºè®¡ç®—forward returns
    prices_df = features_df[['close']] if 'close' in features_df.columns else None
    
    # è®¡ç®—è¿œæœŸæ”¶ç›Šï¼ˆä½¿ç”¨ä½ çš„cross_section_metricsï¼‰
    print(f"\nğŸ“Š è®¡ç®—è¿œæœŸæ”¶ç›Š...")
    forward_horizons = [1, 5, 10, 20]
    forward_returns_df = calculate_forward_returns(
        prices=prices_df,
        periods=forward_horizons,
        method='simple'
    )
    print(f"   âœ… è¿œæœŸæ”¶ç›Šè®¡ç®—å®Œæˆ: {forward_returns_df.shape}")
    
    # å‡†å¤‡å¯äº¤æ˜“æ€§maskï¼ˆå¯é€‰ï¼‰
    # å¦‚æœfeatures_dfä¸­æœ‰tradableåˆ—ï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä¸ºNone
    tradable_mask = None
    if 'tradable' in features_df.columns:
        tradable_mask = features_df[['tradable']]
        print(f"   âœ… ä½¿ç”¨å¯äº¤æ˜“æ€§mask")
    else:
        print(f"   âš ï¸  æœªæä¾›å¯äº¤æ˜“æ€§maskï¼Œå°†ä½¿ç”¨å…¨éƒ¨æ ·æœ¬")
    
    # å‡†å¤‡å¸‚å€¼å’Œè¡Œä¸šæ•°æ®ï¼ˆç”¨äºä¸­æ€§åŒ–ï¼‰
    market_cap = features_df[['market_cap']] if 'market_cap' in features_df.columns else None
    industry = features_df[['industry']] if 'industry' in features_df.columns else None
    
    # è´¨é‡æ£€æŸ¥é˜ˆå€¼
    IC_THRESHOLD = 0.02
    ICIR_THRESHOLD = 0.5
    SPREAD_THRESHOLD = 0.0
    CORR_THRESHOLD = 0.7
    
    # é€ä¸ªå› å­è¯„ä¼°
    qualified_factors = []
    quality_reports = {}
    
    print(f"\nğŸ” å¼€å§‹æ¨ªæˆªé¢è¯„ä¼° (å…± {all_factors_df.shape[1]} ä¸ªå› å­)...\n")
    
    # é¢„å¤„ç†é…ç½®
    preprocess_config = {
        'winsorize': True,
        'winsorize_limits': (0.01, 0.99),
        'standardize': 'zscore',
        'neutralize': None  # å¯é€‰: ['market_cap', 'industry']
    }
    
    for i, factor_name in enumerate(all_factors_df.columns, 1):
        print(f"[{i}/{all_factors_df.shape[1]}] è¯„ä¼°å› å­: {factor_name}")
        
        try:
            # æ„å»ºå•å› å­DataFrame
            single_factor_df = all_factors_df[[factor_name]]
            
            # ä½¿ç”¨ä½ çš„CrossSectionAnalyzerï¼
            analyzer = CrossSectionAnalyzer(
                factors=single_factor_df,
                forward_returns=forward_returns_df,
                tradable_mask=tradable_mask,
                market_cap=market_cap,
                industry=industry
            )
            
            # é¢„å¤„ç†ï¼ˆä½¿ç”¨ä½ çš„é¢„å¤„ç†ç®¡é“ï¼‰
            if preprocess_config.get('winsorize') or preprocess_config.get('standardize'):
                analyzer.preprocess(
                    winsorize=preprocess_config.get('winsorize', True),
                    standardize=preprocess_config.get('standardize') is not None,
                    neutralize=preprocess_config.get('neutralize') is not None,
                    winsorize_limits=preprocess_config.get('winsorize_limits', (0.01, 0.99)),
                    standardize_method=preprocess_config.get('standardize', 'zscore'),
                    neutralize_factors=preprocess_config.get('neutralize')
                )
            
            # è¿è¡Œå®Œæ•´åˆ†æ
            analyzer.analyze(
                n_quantiles=5,
                ic_method='spearman',
                spread_method='top_minus_mean',  # å®ç›˜æ›´ç¨³å¥
                periods_per_year=252
            )
            
            # è·å–ç»“æœ
            results = analyzer.get_results()
            
            # æå–å…³é”®æŒ‡æ ‡ï¼ˆkeyä¸º(factor_name, 'ret_5d')ï¼‰
            key_5d = (factor_name, 'ret_5d')
            ic_summary = results['ic_summary'][key_5d]
            spread_summary = results['spread_summary'][key_5d]
            monotonicity = results['monotonicity'][key_5d]
            
            # åˆ¤æ–­æ˜¯å¦é€šè¿‡ï¼ˆæ¨ªæˆªé¢è¯„ä¼°çš„æ ¸å¿ƒæŒ‡æ ‡ï¼‰
            pass_ic = ic_summary['mean'] >= IC_THRESHOLD and ic_summary['p_value'] < 0.05
            pass_icir = ic_summary['icir_annual'] >= ICIR_THRESHOLD
            pass_spread = spread_summary['mean'] > SPREAD_THRESHOLD
            pass_mono = monotonicity['kendall_tau'] > 0 and monotonicity['p_value'] < 0.05
            
            # ä½¿ç”¨factor_quality_checkerè¿›è¡Œè¡¥å……æ£€æŸ¥ï¼ˆICåŠè¡°æœŸã€PSI/KSã€ç›¸å…³æ€§ï¼‰
            quality_checker = FactorQualityChecker(
                ic_threshold=IC_THRESHOLD,
                icir_threshold=ICIR_THRESHOLD,
                psi_threshold=0.25,
                corr_threshold=CORR_THRESHOLD
            )
            
            # æå–5æ—¥è¿œæœŸæ”¶ç›Š
            forward_return_5d = forward_returns_df['ret_5d']
            
            # è¡¥å……è´¨é‡æ£€æŸ¥
            extra_checks = quality_checker.comprehensive_check(
                factor_values=single_factor_df[factor_name],
                target_values=forward_return_5d,
                prices=prices_df if 'close' in features_df.columns else None,
                existing_factors=all_factors_df[qualified_factors] if qualified_factors else None,
                train_ratio=0.8
            )
            
            # ç»¼åˆåˆ¤æ–­ï¼ˆæ¨ªæˆªé¢æŒ‡æ ‡ + è¡¥å……æ£€æŸ¥ï¼‰
            pass_corr = extra_checks['corr_check']['pass_corr']
            pass_psi = extra_checks['pass_psi']
            
            # æ ¸å¿ƒæŒ‡æ ‡å¿…é¡»é€šè¿‡ï¼Œè¡¥å……æŒ‡æ ‡å¯é™æƒ
            overall_pass = pass_ic and pass_icir and pass_spread and pass_corr
            
            # ä¿å­˜æŠ¥å‘Š
            quality_reports[factor_name] = {
                'ic_mean': ic_summary['mean'],
                'icir_annual': ic_summary['icir_annual'],
                'ic_pvalue': ic_summary['p_value'],
                'spread': spread_summary['mean'],
                'monotonicity_tau': monotonicity['kendall_tau'],
                'max_correlation': extra_checks['corr_check']['max_corr'],
                'ic_half_life': extra_checks.get('ic_half_life', np.nan),
                'psi': extra_checks.get('psi', np.nan),
                'pass_ic': pass_ic,
                'pass_icir': pass_icir,
                'pass_spread': pass_spread,
                'pass_correlation': pass_corr,
                'pass_psi': pass_psi,
                'overall_pass': overall_pass,
                'full_results': results,  # æ¨ªæˆªé¢å®Œæ•´ç»“æœ
                'extra_checks': extra_checks  # è¡¥å……æ£€æŸ¥ç»“æœ
            }
            
            if overall_pass:
                qualified_factors.append(factor_name)
                print(f"   âœ… é€šè¿‡")
                print(f"      IC={ic_summary['mean']:.4f} (ICIR={ic_summary['icir_annual']:.2f})")
                print(f"      Spread={spread_summary['mean']:.4f}, Ï„={monotonicity['kendall_tau']:.3f}")
            else:
                fail_reasons = []
                if not pass_ic: fail_reasons.append("ICä¸æ˜¾è‘—")
                if not pass_icir: fail_reasons.append("ICIRè¿‡ä½")
                if not pass_spread: fail_reasons.append("Spreadâ‰¤0")
                if not pass_corr: fail_reasons.append("ä¸å·²æœ‰å› å­é«˜åº¦ç›¸å…³")
                
                print(f"   âŒ æ‹’ç» | {', '.join(fail_reasons)}")
        
        except Exception as e:
            print(f"   âš ï¸  è¯„ä¼°å¤±è´¥: {str(e)}")
            quality_reports[factor_name] = {
                'overall_pass': False,
                'error': str(e)
            }
        
        print()
    
    print(f"âœ… æ¨ªæˆªé¢è¯„ä¼°å®Œæˆ")
    print(f"   é€šè¿‡å› å­æ•°: {len(qualified_factors)} / {all_factors_df.shape[1]}")
    print(f"   é€šè¿‡ç‡: {len(qualified_factors) / all_factors_df.shape[1] * 100:.1f}%")
    
    # 5. å› å­å…¥åº“
    print("\n" + "=" * 80)
    print("æ­¥éª¤ 5: å› å­å…¥åº“ç®¡ç†")
    print("=" * 80)
    
    manager = FactorLibraryManager()
    
    # æ·»åŠ é€šè¿‡çš„å› å­
    print(f"\nğŸ“¥ å°† {len(qualified_factors)} ä¸ªé€šè¿‡çš„å› å­åŠ å…¥åº“ä¸­...\n")
    
    factor_registry = factory.get_factor_registry()
    
    for factor_name in qualified_factors:
        factor_info = factor_registry.get(factor_name, {})
        quality_report = quality_reports[factor_name]
        
        manager.add_factor(
            factor_name=factor_name,
            quality_report=quality_report,
            formula=factor_info.get('formula', ''),
            family=factor_info.get('family', ''),
            reference=factor_info.get('reference', '')
        )
    
    print(f"\nâœ… å› å­å…¥åº“å®Œæˆ")
    
    # 6. ç”Ÿæˆå®Œæ•´æŠ¥å‘Šï¼ˆä½¿ç”¨ä½ çš„tearsheetï¼ï¼‰
    print("\n" + "=" * 80)
    print("æ­¥éª¤ 6: ç”ŸæˆTearsheetæŠ¥å‘Š")
    print("=" * 80)
    
    # ä¸ºæ¯ä¸ªé€šè¿‡çš„å› å­ç”Ÿæˆå®Œæ•´çš„tearsheetæŠ¥å‘Š
    reports_dir = os.path.join(ml_root, "ML output/reports/baseline_v1/factors")
    figures_dir = os.path.join(ml_root, "ML output/figures/baseline_v1/factors")
    os.makedirs(reports_dir, exist_ok=True)
    os.makedirs(figures_dir, exist_ok=True)
    
    print(f"\nğŸ“ ç”Ÿæˆ {len(qualified_factors)} ä¸ªå› å­çš„è¯¦ç»†æŠ¥å‘Š...\n")
    
    for i, factor_name in enumerate(qualified_factors, 1):
        print(f"[{i}/{len(qualified_factors)}] ç”ŸæˆæŠ¥å‘Š: {factor_name}")
        
        try:
            report = quality_reports[factor_name]
            full_results = report['full_results']
            
            # ç”ŸæˆHTML tearsheetï¼ˆä½¿ç”¨ä½ çš„evaluationæ¨¡å—ï¼ï¼‰
            tearsheet_path = os.path.join(reports_dir, f"tearsheet_{factor_name}_5d.html")
            
            # ä½¿ç”¨æ­£ç¡®çš„tearsheetå‡½æ•°
            from evaluation.tearsheet import generate_html_tearsheet
            generate_html_tearsheet(
                analyzer_results=full_results,
                factor_name=factor_name,
                return_period='ret_5d',
                output_path=tearsheet_path,
                plot_paths=None  # å›¾è¡¨ä¼šè‡ªåŠ¨ç”Ÿæˆåœ¨figuresç›®å½•
            )
            
            # ä¿å­˜ICæ—¶é—´åºåˆ—CSV
            ic_series_path = os.path.join(reports_dir, f"ic_{factor_name}_5d.csv")
            full_results['ic_series'][5].to_csv(ic_series_path)
            
            # ä¿å­˜åˆ†ä½æ•°æ”¶ç›ŠCSV
            quantile_returns_path = os.path.join(reports_dir, f"quantile_returns_{factor_name}_5d.csv")
            full_results['quantile_returns'][5].to_csv(quantile_returns_path)
            
            print(f"   âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
            print(f"      HTML: {tearsheet_path}")
        
        except Exception as e:
            print(f"   âš ï¸  æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
        
        print()
    
    # å› å­æ¸…å•æŠ¥å‘Š
    print(f"\nğŸ“Š ç”Ÿæˆå› å­åº“æ±‡æ€»æŠ¥å‘Š...")
    report_df = manager.generate_factor_report()
    
    # æ—åˆ«è¡¨ç°æŠ¥å‘Š
    family_df = manager.analyze_factor_family_performance()
    
    print(f"\næ—åˆ«è¡¨ç°æ±‡æ€»:")
    print(family_df.to_string(index=False))
    
    # ä¿å­˜é€šè¿‡çš„å› å­æ•°æ®
    print(f"\nğŸ’¾ ä¿å­˜å› å­æ•°æ®...")
    
    qualified_factors_df = all_factors_df[qualified_factors]
    
    # ä¿å­˜è·¯å¾„
    datasets_dir = os.path.join(ml_root, "ML output/datasets/baseline_v1")
    os.makedirs(datasets_dir, exist_ok=True)
    
    # ä¿å­˜Parquetæ ¼å¼
    output_path = os.path.join(datasets_dir, f"qualified_factors_{datetime.now().strftime('%Y%m%d')}.parquet")
    qualified_factors_df.to_parquet(output_path)
    print(f"   âœ… å› å­æ•°æ® (Parquet): {output_path}")
    
    # åŒæ—¶ä¿å­˜CSVæ ¼å¼ï¼ˆå…¼å®¹æ€§ï¼‰
    csv_path = os.path.join(datasets_dir, f"qualified_factors_{datetime.now().strftime('%Y%m%d')}.csv")
    qualified_factors_df.to_csv(csv_path)
    print(f"   âœ… å› å­æ•°æ® (CSV): {csv_path}")
    
    # ä¿å­˜final_feature_list.txt
    feature_list_path = os.path.join(ml_root, "ML output/final_feature_list.txt")
    with open(feature_list_path, 'w', encoding='utf-8') as f:
        f.write("# å› å­å·¥å‚ v1 - åˆæ ¼å› å­æ¸…å•\n")
        f.write(f"# ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"# æ•°æ®åŒºé—´: {start_date} ~ {end_date}\n")
        f.write(f"# é€šè¿‡å› å­æ•°: {len(qualified_factors)}\n")
        f.write("\n")
        for factor_name in qualified_factors:
            report = quality_reports[factor_name]
            f.write(f"{factor_name}\t")
            f.write(f"IC={report['ic_mean']:.4f}\t")
            f.write(f"ICIR={report['icir_annual']:.2f}\t")
            f.write(f"Spread={report['spread']:.4f}\n")
    
    print(f"   âœ… å› å­æ¸…å•: {feature_list_path}")
    
    # 7. éªŒæ”¶æ£€æŸ¥
    print("\n" + "=" * 80)
    print("éªŒæ”¶æ£€æŸ¥")
    print("=" * 80)
    
    acceptance_passed = True
    
    # æ£€æŸ¥1: è‡³å°‘10ä¸ªç¨³å®šå› å­è¿‡æ£€
    print(f"\nâœ“ æ£€æŸ¥1: ç¨³å®šå› å­æ•°é‡")
    print(f"   è¦æ±‚: â‰¥10 ä¸ª")
    print(f"   å®é™…: {len(qualified_factors)} ä¸ª")
    
    if len(qualified_factors) < 10:
        print(f"   âŒ æœªé€šè¿‡")
        acceptance_passed = False
    else:
        print(f"   âœ… é€šè¿‡")
    
    # æ£€æŸ¥2: æ¨ªæˆªé¢ Rank IC æ˜¾è‘—
    print(f"\nâœ“ æ£€æŸ¥2: Rank IC æ˜¾è‘—æ€§")
    
    significant_factors = []
    for factor_name in qualified_factors:
        report = quality_reports[factor_name]
        if report['ic_metrics']['pass_ic']:
            significant_factors.append(factor_name)
    
    print(f"   è¦æ±‚: IC > 0.02 ä¸”ç»Ÿè®¡æ˜¾è‘—")
    print(f"   å®é™…: {len(significant_factors)} / {len(qualified_factors)} ä¸ªå› å­æ˜¾è‘—")
    
    if len(significant_factors) < len(qualified_factors) * 0.8:
        print(f"   âŒ æœªé€šè¿‡ (æ˜¾è‘—å› å­æ¯”ä¾‹è¿‡ä½)")
        acceptance_passed = False
    else:
        print(f"   âœ… é€šè¿‡")
    
    # æ£€æŸ¥3: åˆå…¥åç»„åˆ IC æœ‰å®è´¨æå‡
    print(f"\nâœ“ æ£€æŸ¥3: ç»„åˆ IC æå‡")
    print(f"   åŸºå‡†ç‰¹å¾æ•°: {features_df.shape[1]}")
    print(f"   æ–°å¢å› å­æ•°: {len(qualified_factors)}")
    
    # ç®€å•ç»„åˆæµ‹è¯•ï¼šæ‰€æœ‰å› å­ç­‰æƒå¹³å‡
    combined_factor = qualified_factors_df.mean(axis=1)
    target_values = targets_df[target_config['type']]
    
    # è®¡ç®—ç»„åˆIC
    aligned_df = pd.DataFrame({
        'factor': combined_factor,
        'target': target_values
    }).dropna()
    
    grouped = aligned_df.groupby(level='date')
    ic_series = grouped.apply(lambda x: x['factor'].corr(x['target'], method='spearman'))
    
    combined_ic = ic_series.mean()
    combined_icir = ic_series.mean() / ic_series.std() * np.sqrt(252)
    
    print(f"   ç»„åˆIC: {combined_ic:.4f}")
    print(f"   ç»„åˆICIR: {combined_icir:.2f}")
    
    if combined_ic < 0.03:
        print(f"   âš ï¸  ç»„åˆICåä½ï¼Œå»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–")
    else:
        print(f"   âœ… ç»„åˆICæ˜¾è‘—")
    
    # æœ€ç»ˆéªŒæ”¶ç»“æœ
    print("\n" + "=" * 80)
    if acceptance_passed:
        print("ğŸ‰ éªŒæ”¶é€šè¿‡ï¼å› å­å·¥å‚ v1 æ„å»ºæˆåŠŸ")
    else:
        print("âš ï¸  éƒ¨åˆ†éªŒæ”¶æŒ‡æ ‡æœªè¾¾æ ‡ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
    print("=" * 80)
    
    print(f"\nå®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    return qualified_factors_df, quality_reports, manager


if __name__ == "__main__":
    """è¿è¡Œå› å­å‡†å¤‡æµç¨‹"""
    
    # æµ‹è¯•å‚æ•°
    tickers = ['000001.SZ', '000002.SZ', '000063.SZ']  # æµ‹è¯•ç”¨è‚¡ç¥¨
    
    qualified_factors_df, quality_reports, manager = prepare_factors(
        config_path="configs/ml_baseline.yml",
        start_date="2020-01-01",
        end_date="2024-12-31",
        tickers=tickers
    )
    
    print("\nâœ… æµç¨‹æ‰§è¡Œå®Œæˆï¼")
