#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´çš„ç‰¹å¾+ç›®æ ‡ç”Ÿæˆæµç¨‹

åŠŸèƒ½ï¼š
1. åŠ è½½åŸå§‹æ•°æ®
2. ç”ŸæˆæŠ€æœ¯ç‰¹å¾
3. ç‰¹å¾é€‰æ‹©å’Œæ ‡å‡†åŒ–
4. ç”Ÿæˆç›®æ ‡å˜é‡
5. ä¿å­˜å®Œæ•´æ•°æ®é›†
"""

import os
import sys
import yaml
import argparse
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
ml_root = os.path.dirname(current_dir)
if ml_root not in sys.path:
    sys.path.insert(0, ml_root)

# å¯¼å…¥ç‰¹å¾å’Œç›®æ ‡å·¥ç¨‹æ¨¡å—
from features.feature_engineering import FeatureEngineer
from targets.target_engineering import TargetEngineer


def load_config(config_path: str) -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºåŸºäºml_rootçš„ç»å¯¹è·¯å¾„
    if not os.path.isabs(config_path):
        config_path = os.path.join(ml_root, config_path.replace("machine learning/", ""))
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config


def main(config_path: str = "configs/ml_baseline.yml"):
    """
    å®Œæ•´çš„æ•°æ®å‡†å¤‡æµç¨‹
    
    Parameters:
    -----------
    config_path : str
        é…ç½®æ–‡ä»¶è·¯å¾„
    """
    print("=" * 70)
    print("ğŸ”¨ æ•°æ®å‡†å¤‡æµç¨‹")
    print("=" * 70)
    
    # 1. åŠ è½½é…ç½®
    print("\nğŸ“‹ åŠ è½½é…ç½®...")
    config = load_config(config_path)
    
    # æ˜¾ç¤ºé¡¹ç›®ä¿¡æ¯
    project_info = config.get('project', {})
    if project_info:
        print(f"   ğŸ“¦ é¡¹ç›®: {project_info.get('name', 'N/A')}")
        print(f"   ğŸ“ æè¿°: {project_info.get('description', 'N/A')}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆè½¬æ¢ä¸ºç»å¯¹è·¯å¾„ï¼‰
    datasets_dir = os.path.join(ml_root, config['paths'].get('datasets_dir', 'ML output/datasets/baseline_v1'))
    scalers_dir = os.path.join(ml_root, config['paths'].get('scalers_dir', 'ML output/scalers/baseline_v1'))
    os.makedirs(datasets_dir, exist_ok=True)
    os.makedirs(scalers_dir, exist_ok=True)
    
    symbol = config['data']['symbol']
    start_date = config['data']['start_date']
    end_date = config['data']['end_date']
    
    print(f"   è‚¡ç¥¨ä»£ç : {symbol}")
    print(f"   æ—¶é—´èŒƒå›´: {start_date} ~ {end_date}")
    
    # 2. ç‰¹å¾å·¥ç¨‹
    print("\nğŸ”§ ç‰¹å¾å·¥ç¨‹...")
    feature_engineer = FeatureEngineer(use_talib=True, use_tsfresh=False)
    
    # åŠ è½½åŸå§‹æ•°æ®
    raw_data = feature_engineer.load_stock_data(symbol, start_date, end_date)
    
    # ç”Ÿæˆç‰¹å¾
    features_df = feature_engineer.prepare_features(
        raw_data,
        use_auto_features=False
    )
    
    # ç‰¹å¾é€‰æ‹©
    selection_results = feature_engineer.select_features(
        features_df,
        final_k=20,
        variance_threshold=0.01,
        correlation_threshold=0.9,
        train_ratio=0.8
    )
    
    selected_features = selection_results['final_features_df']
    
    # ç‰¹å¾æ ‡å‡†åŒ–
    scaler_path = os.path.join(scalers_dir, f"scaler_{symbol}.pkl")
    scale_results = feature_engineer.scale_features(
        selected_features,
        scaler_type='robust',
        train_ratio=0.8,
        save_path=scaler_path
    )
    
    scaled_features = scale_results['scaled_df']
    
    print(f"   âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆ: {len(selection_results['final_features'])} ä¸ªç‰¹å¾")
    print(f"   ğŸ’¾ æ ‡å‡†åŒ–å™¨ä¿å­˜åˆ°: {scaler_path}")
    
    # 3. ç›®æ ‡å·¥ç¨‹
    print("\nğŸ¯ ç›®æ ‡å·¥ç¨‹...")
    target_engineer = TargetEngineer(data_dir=datasets_dir)
    
    # ç”Ÿæˆç›®æ ‡å˜é‡
    complete_df = target_engineer.create_complete_dataset(
        features_df=scaled_features,
        periods=[1, 5, 10],
        price_col='close',
        include_labels=True,
        label_types=['binary']
    )
    
    # ä¿å­˜æ•°æ®é›†
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filepath = target_engineer.save_dataset(
        complete_df,
        symbol=symbol,
        suffix=f"complete_{timestamp}"
    )
    
    print(f"   âœ… ç›®æ ‡å·¥ç¨‹å®Œæˆ")
    
    # 4. æ€»ç»“
    print("\n" + "=" * 70)
    print("âœ… æ•°æ®å‡†å¤‡å®Œæˆï¼")
    print("=" * 70)
    print(f"\nğŸ“Š è¾“å‡ºæ–‡ä»¶:")
    print(f"   ç‰¹å¾æ ‡å‡†åŒ–: {scale_results['scaler_path']}")
    print(f"   å®Œæ•´æ•°æ®é›†: {filepath}")
    print(f"\nğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
    print(f"   ç‰¹å¾æ•°é‡: {len(selection_results['final_features'])}")
    print(f"   æ ·æœ¬æ•°é‡: {len(complete_df)}")
    print(f"   ç›®æ ‡å˜é‡: future_return_1d, future_return_5d, future_return_10d")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='æ•°æ®å‡†å¤‡æµç¨‹')
    parser.add_argument('--config', type=str, 
                       default='configs/ml_baseline.yml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    try:
        main(args.config)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
