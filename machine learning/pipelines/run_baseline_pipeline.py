#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Baseline æ¨¡å‹è®­ç»ƒç®¡é“ - Learning-to-Rank ä¸‰æ¡çº¿å¯¹æ¯”

åŠŸèƒ½ï¼š
1. Baseline Aï¼šå›å½’åŸå§‹æ”¶ç›Šï¼ˆLGBMRegressorï¼‰
2. Baseline Bï¼šReg-on-Rankï¼ˆLGBMRegressor + GaussRank æ ‡ç­¾ï¼‰
3. Sortingï¼šLambdaRankï¼ˆLGBMRankerï¼‰

æµç¨‹ï¼š
1. æ•°æ®åŠ è½½ï¼ˆå¤ç”¨ DataLoaderï¼‰
2. æ—¶åº CV åˆ‡åˆ†ï¼ˆPurged + Embargoï¼‰
3. ç‰¹å¾åˆ†å¸ƒæ¼‚ç§»æ£€æµ‹ï¼ˆPSIï¼‰- è®­ç»ƒå‰
4. ä¸‰æ¡çº¿æ¨¡å‹è®­ç»ƒ
5. æ¨ªæˆªé¢è¯„ä¼°ï¼ˆCrossSectionAnalyzerï¼‰
6. æ¨¡å‹é¢„æµ‹æ¼‚ç§»æ£€æµ‹ï¼ˆIC/Spreadï¼‰- è®­ç»ƒå
7. ç»“æœå¯¹æ¯”ä¸æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•ï¼š
    python run_baseline_pipeline.py
    python run_baseline_pipeline.py --task_type lambdarank
    python run_baseline_pipeline.py --compare_all  # è¿è¡Œä¸‰æ¡çº¿å¯¹æ¯”
    python run_baseline_pipeline.py --skip_drift   # è·³è¿‡æ¼‚ç§»æ£€æµ‹

è¾“å‡ºï¼š
    /ML output/reports/baseline_v1/ranking/
    â”œâ”€â”€ model_comparison.json           # ä¸‰æ¡çº¿å¯¹æ¯”ç»“æœ
    â”œâ”€â”€ feature_drift_report.json       # ç‰¹å¾åˆ†å¸ƒæ¼‚ç§»æ£€æµ‹ï¼ˆPSIï¼‰
    â”œâ”€â”€ prediction_drift_report.json    # æ¨¡å‹é¢„æµ‹æ¼‚ç§»æ£€æµ‹ï¼ˆIC/Spreadï¼‰
    â”œâ”€â”€ regression_results.json
    â”œâ”€â”€ regression_rank_results.json
    â”œâ”€â”€ lambdarank_results.json
    â”œâ”€â”€ {task_type}_predictions.parquet
    â””â”€â”€ {task_type}_model.pkl

åˆ›å»º: 2025-12-04 | ç‰ˆæœ¬: v1.2
"""

import os
import sys
import yaml
import json
import argparse
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Optional, Tuple

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
ml_root = os.path.dirname(current_dir)
if ml_root not in sys.path:
    sys.path.insert(0, ml_root)

# å¯¼å…¥æ¨¡å—
from data.data_loader import DataLoader
from data.time_series_cv import TimeSeriesCV
from targets.ranking_labels import RankingLabelFactory, create_ranking_labels
from models.lgbm_model import LightGBMModel
from models.lgbm_ranker import LightGBMRanker, prepare_ranking_data
from evaluation.cross_section_analyzer import CrossSectionAnalyzer
from evaluation.cross_section_metrics import calculate_forward_returns
from evaluation.drift_detector import DriftDetector
from backtest.simple_backtest import SimplePortfolioBacktester


def load_config(config_path: str = "configs/ml_baseline.yml") -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    if not os.path.isabs(config_path):
        config_path = os.path.join(ml_root, config_path)
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    return config


def prepare_data(config: dict) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    """
    å‡†å¤‡æ•°æ®ï¼šç‰¹å¾ã€è¿œæœŸæ”¶ç›Šã€ä»·æ ¼
    
    Returns:
    --------
    Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]
        (features, forward_returns, prices)
    """
    print("\n" + "=" * 70)
    print("å‡†å¤‡æ•°æ®")
    print("=" * 70)
    
    # è·å–é…ç½®
    data_config = config['data']
    target_config = config['target']
    symbols = data_config['symbol']
    if isinstance(symbols, str):
        symbols = [symbols]
    
    forward_periods = target_config['forward_periods']
    target_col = f"future_return_{forward_periods}d"
    
    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ä¸­æ€§åŒ–å› å­
    use_neutralized = config['features'].get('use_neutralized_features', False)
    
    if use_neutralized:
        # ===== ç›´æ¥åŠ è½½ä¸­æ€§åŒ–å› å­æ–‡ä»¶ï¼ˆå·²ç»æ˜¯å¤šè‚¡ç¥¨åˆå¹¶çš„ï¼‰ =====
        print("ğŸ“‚ åŠ è½½ä¸­æ€§åŒ–å› å­...")
        
        datasets_dir = os.path.join(ml_root, "ML output/datasets/baseline_v1")
        
        # æŸ¥æ‰¾ä¸­æ€§åŒ–å› å­æ–‡ä»¶
        neutral_files = [f for f in os.listdir(datasets_dir) 
                        if f.startswith('qualified_factors_neutralized_') and f.endswith('.parquet')]
        
        if not neutral_files:
            print("   âš ï¸ æœªæ‰¾åˆ°ä¸­æ€§åŒ–å› å­æ–‡ä»¶ï¼Œé™çº§ä½¿ç”¨åŸå§‹å› å­")
            use_neutralized = False
        else:
            neutral_files.sort(reverse=True)
            neutral_file = os.path.join(datasets_dir, neutral_files[0])
            print(f"   ğŸ“ˆ åŠ è½½: {neutral_files[0]}")
            
            features = pd.read_parquet(neutral_file)
            print(f"   âœ… ç‰¹å¾å½¢çŠ¶: {features.shape}")
            
            # åŠ è½½å¯¹åº”çš„ç›®æ ‡æ•°æ®ï¼ˆä» with_targets æ–‡ä»¶ï¼‰
            # ä¸­æ€§åŒ–å› å­çš„ç´¢å¼•åº”è¯¥æ˜¯ MultiIndex [date, ticker]
            if isinstance(features.index, pd.MultiIndex):
                # ä»ç´¢å¼•ä¸­æå–è‚¡ç¥¨åˆ—è¡¨
                available_tickers = features.index.get_level_values('ticker').unique().tolist()
                print(f"   ğŸ“‹ åŒ…å«è‚¡ç¥¨: {available_tickers[:5]}{'...' if len(available_tickers) > 5 else ''}")
                
                # åŠ è½½ç›®æ ‡æ•°æ®
                all_targets = []
                for ticker in available_tickers:
                    # æŸ¥æ‰¾åŒ¹é…çš„ with_targets æ–‡ä»¶ï¼ˆæ ¼å¼: with_targets_{ticker}_complete_YYYYMMDD_HHMMSS.csvï¼‰
                    target_files = [f for f in os.listdir(datasets_dir) 
                                   if f.startswith(f"with_targets_{ticker}_complete_") and f.endswith('.csv')]
                    
                    if target_files:
                        # ä½¿ç”¨æœ€æ–°çš„æ–‡ä»¶
                        target_files.sort(reverse=True)
                        target_file = os.path.join(datasets_dir, target_files[0])
                        
                        df = pd.read_csv(target_file, index_col=0, parse_dates=True)
                        if target_col in df.columns:
                            targets = df[[target_col]].copy()
                            targets['ticker'] = ticker
                            targets = targets.reset_index()
                            targets = targets.rename(columns={'index': 'date'})
                            all_targets.append(targets)
                
                if all_targets:
                    targets_df = pd.concat(all_targets, ignore_index=True)
                    
                    # ç¡®ä¿æ—¥æœŸæ ¼å¼ç»Ÿä¸€ï¼ˆå»é™¤æ—¶åŒºä¿¡æ¯ï¼‰
                    targets_df['date'] = pd.to_datetime(targets_df['date']).dt.tz_localize(None)
                    
                    targets_df = targets_df.set_index(['date', 'ticker'])
                    forward_returns = targets_df[[target_col]].rename(columns={target_col: f'ret_{forward_periods}d'})
                    
                    # ç¡®ä¿ç‰¹å¾ç´¢å¼•ä¹Ÿæ— æ—¶åŒº
                    if features.index.get_level_values('date').tz is not None:
                        features = features.reset_index()
                        features['date'] = features['date'].dt.tz_localize(None)
                        features = features.set_index(['date', 'ticker'])
                    
                    # å¯¹é½ç‰¹å¾å’Œç›®æ ‡
                    common_idx = features.index.intersection(forward_returns.index)
                    print(f"   ï¿½ å…±åŒç´¢å¼•æ•°: {len(common_idx)}")
                    
                    if len(common_idx) == 0:
                        raise ValueError("ç‰¹å¾å’Œç›®æ ‡æ²¡æœ‰å…±åŒç´¢å¼•ï¼Œè¯·æ£€æŸ¥æ—¥æœŸæ ¼å¼")
                    
                    features = features.loc[common_idx]
                    forward_returns = forward_returns.loc[common_idx]
                else:
                    raise FileNotFoundError("æ— æ³•åŠ è½½ç›®æ ‡æ•°æ®")
            else:
                raise ValueError("ä¸­æ€§åŒ–å› å­æ–‡ä»¶ç´¢å¼•æ ¼å¼é”™è¯¯ï¼Œåº”ä¸º MultiIndex [date, ticker]")
            
            print(f"âœ… ç‰¹å¾åŠ è½½å®Œæˆ: {features.shape}")
            print(f"âœ… ç›®æ ‡åŠ è½½å®Œæˆ: {len(forward_returns)}")
            
            # ===== åŠ è½½ä»·æ ¼æ•°æ®ç”¨äºå›æµ‹ï¼ˆä¸­æ€§åŒ–å› å­æ¨¡å¼ï¼‰ =====
            print("\nğŸ“‚ åŠ è½½ä»·æ ¼æ•°æ®ç”¨äºå›æµ‹...")
            prices = None
            
            # å‡†å¤‡ InfluxDB é…ç½®
            influxdb_config = data_config.get('influxdb', {})
            
            # åˆå§‹åŒ– MarketDataLoader
            if influxdb_config.get('enabled', False):
                try:
                    from data.market_data_loader import MarketDataLoader
                    
                    market_loader = MarketDataLoader(
                        url=influxdb_config['url'],
                        token=influxdb_config['token'],
                        org=influxdb_config['org'],
                        bucket=influxdb_config['bucket']
                    )
                    
                    all_prices = []
                    for ticker in available_tickers:
                        try:
                            price_df = market_loader.load_market_data(
                                symbol=ticker,
                                start_date=str(data_config['start_date']),
                                end_date=str(data_config['end_date'])
                            )
                            if not price_df.empty:
                                price_df['ticker'] = ticker
                                price_df = price_df.reset_index()
                                price_df = price_df.rename(columns={'index': 'date'})
                                price_df['date'] = pd.to_datetime(price_df['date']).dt.tz_localize(None)
                                price_df = price_df.set_index(['date', 'ticker'])
                                all_prices.append(price_df)
                                print(f"   âœ… {ticker}: {len(price_df)} æ¡ä»·æ ¼è®°å½•")
                        except Exception as e:
                            print(f"   âš ï¸ {ticker} ä»·æ ¼åŠ è½½å¤±è´¥: {e}")
                            continue
                    
                    if all_prices:
                        prices = pd.concat(all_prices)
                        required_cols = ['open', 'close']
                        missing_cols = [col for col in required_cols if col not in prices.columns]
                        if missing_cols:
                            print(f"   âš ï¸ ä»·æ ¼æ•°æ®ç¼ºå°‘åˆ—: {missing_cols}ï¼Œå›æµ‹å°†æ— æ³•è¿è¡Œ")
                            prices = None
                        else:
                            print(f"   âœ… ä»·æ ¼æ•°æ®åŠ è½½å®Œæˆ: {len(prices)} æ¡è®°å½•")
                except Exception as e:
                    print(f"   âš ï¸ ä»·æ ¼æ•°æ®åŠ è½½å¤±è´¥: {e}")
                    prices = None
            else:
                print("   âš ï¸ InfluxDB æœªå¯ç”¨ï¼Œæ— æ³•åŠ è½½ä»·æ ¼æ•°æ®")
            
            print(f"âœ… æ ·æœ¬æ€»æ•°: {len(features):,}")
            
            return features, forward_returns, prices
    
    # ===== åŸæœ‰é€»è¾‘ï¼šæŒ‰å•è‚¡ç¥¨åŠ è½½ =====
    # åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
    influxdb_config = data_config.get('influxdb', {}).copy()
    influxdb_config.pop('enabled', None)
    
    # æ•°æ®é›†ç›®å½•ï¼ˆwith_targets æ–‡ä»¶åœ¨è¿™é‡Œï¼‰
    datasets_dir = os.path.join(ml_root, config['paths'].get('datasets_dir', 'ML output/datasets/baseline_v1'))
    
    loader = DataLoader(
        data_root=datasets_dir,  # ä½¿ç”¨ datasets ç›®å½•
        enable_snapshot=data_config['snapshot']['enabled'],
        enable_filtering=True,
        enable_influxdb=data_config['influxdb']['enabled'],
        influxdb_config=influxdb_config,
        filter_config=data_config['universe']
    )
    
    # åŠ è½½å¤šä¸ªè‚¡ç¥¨çš„æ•°æ®
    all_features = []
    all_targets = []
    
    for symbol in symbols:
        try:
            features, targets = loader.load_features_and_targets(
                symbol=symbol,
                target_col=target_col,
                use_scaled=config['features']['use_scaled_features'],
                use_neutralized=False  # è¿™é‡Œä¸å†ä½¿ç”¨ä¸­æ€§åŒ–ï¼Œå› ä¸ºä¸Šé¢å·²ç»å¤„ç†
            )
            all_features.append(features)
            all_targets.append(targets)
            print(f"   âœ… {symbol}: {len(features)} æ ·æœ¬")
        except Exception as e:
            print(f"   âš ï¸ {symbol} åŠ è½½å¤±è´¥: {e}")
            continue
    
    if not all_features:
        raise ValueError("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•è‚¡ç¥¨æ•°æ®")
    
    # åˆå¹¶æ‰€æœ‰è‚¡ç¥¨
    features = pd.concat(all_features, axis=0)
    targets = pd.concat(all_targets, axis=0)
    
    print(f"âœ… ç‰¹å¾åŠ è½½å®Œæˆ: {features.shape}")
    print(f"âœ… ç›®æ ‡åŠ è½½å®Œæˆ: {len(targets)}")
    
    # æ„é€  forward_returns DataFrameï¼ˆè¯„ä¼°éœ€è¦ï¼‰
    forward_returns = targets.to_frame(f'ret_{forward_periods}d')
    
    # ===== åŠ è½½ä»·æ ¼æ•°æ®ç”¨äºå›æµ‹ =====
    print("\nğŸ“‚ åŠ è½½ä»·æ ¼æ•°æ®ç”¨äºå›æµ‹...")
    prices = None
    
    if loader.market_data_loader is not None:
        # ä» InfluxDB åŠ è½½ä»·æ ¼æ•°æ®
        try:
            all_prices = []
            for symbol in symbols:
                try:
                    price_df = loader.market_data_loader.load_market_data(
                        symbol=symbol,
                        start_date=str(data_config['start_date']),
                        end_date=str(data_config['end_date'])
                    )
                    if not price_df.empty:
                        # æ·»åŠ  ticker åˆ—å¹¶è®¾ç½® MultiIndex
                        price_df['ticker'] = symbol
                        price_df = price_df.reset_index()
                        price_df = price_df.rename(columns={'index': 'date'})
                        price_df['date'] = pd.to_datetime(price_df['date'])
                        price_df = price_df.set_index(['date', 'ticker'])
                        all_prices.append(price_df)
                        print(f"   âœ… {symbol}: {len(price_df)} æ¡ä»·æ ¼è®°å½•")
                except Exception as e:
                    print(f"   âš ï¸ {symbol} ä»·æ ¼åŠ è½½å¤±è´¥: {e}")
                    continue
            
            if all_prices:
                prices = pd.concat(all_prices)
                # ç¡®ä¿åŒ…å« open å’Œ close åˆ—
                required_cols = ['open', 'close']
                missing_cols = [col for col in required_cols if col not in prices.columns]
                if missing_cols:
                    print(f"   âš ï¸ ä»·æ ¼æ•°æ®ç¼ºå°‘åˆ—: {missing_cols}ï¼Œå›æµ‹å°†æ— æ³•è¿è¡Œ")
                    prices = None
                else:
                    print(f"   âœ… ä»·æ ¼æ•°æ®åŠ è½½å®Œæˆ: {len(prices)} æ¡è®°å½•")
        except Exception as e:
            print(f"   âš ï¸ ä»·æ ¼æ•°æ®åŠ è½½å¤±è´¥: {e}")
            prices = None
    else:
        print("   âš ï¸ MarketDataLoader æœªåˆå§‹åŒ–ï¼Œæ— æ³•åŠ è½½ä»·æ ¼æ•°æ®")
    
    print(f"âœ… æ ·æœ¬æ€»æ•°: {len(features):,}")
    
    return features, forward_returns, prices


def run_single_task(task_type: str,
                    config: dict,
                    features: pd.DataFrame,
                    forward_returns: pd.DataFrame,
                    train_idx: pd.Index,
                    valid_idx: pd.Index,
                    test_idx: pd.Index,
                    output_dir: str) -> Dict:
    """
    è¿è¡Œå•ä¸ªä»»åŠ¡ç±»å‹
    
    Parameters:
    -----------
    task_type : str
        ä»»åŠ¡ç±»å‹ï¼š'regression', 'regression_rank', 'lambdarank'
    config : dict
        é…ç½®å­—å…¸
    features : pd.DataFrame
        ç‰¹å¾æ•°æ®
    forward_returns : pd.DataFrame
        è¿œæœŸæ”¶ç›Š
    train_idx, valid_idx, test_idx : pd.Index
        åˆ‡åˆ†ç´¢å¼•
    output_dir : str
        è¾“å‡ºç›®å½•
        
    Returns:
    --------
    dict
        ç»“æœæ±‡æ€»
    """
    print(f"\n{'='*70}")
    print(f"ä»»åŠ¡ç±»å‹: {task_type}")
    print(f"{'='*70}")
    
    # è·å–ç›®æ ‡åˆ—å
    target_col = f"ret_{config['target']['forward_periods']}d"
    
    # æ’åºé…ç½®
    ranking_config = config.get('ranking', {})
    
    # åˆ›å»ºæ ‡ç­¾
    label_factory = RankingLabelFactory(
        n_bins=ranking_config.get('lambdarank', {}).get('n_bins', 5),
        rank_method=ranking_config.get('regression_rank', {}).get('rank_method', 'zscore')
    )
    
    min_samples = ranking_config.get('regression_rank', {}).get('min_samples_per_day', 30)
    label_result = label_factory.create_labels(
        forward_returns, task_type, target_col, min_samples
    )
    
    labels = label_result['labels']
    # æ³¨æ„ï¼šgroups åœ¨åˆ‡åˆ†åä¼šé‡æ–°è®¡ç®—ï¼Œè¿™é‡Œä¸éœ€è¦ä¿ç•™
    
    # å¯¹é½ç‰¹å¾ä¸æ ‡ç­¾
    X_aligned, y_aligned = label_factory.align_features_with_labels(features, labels)
    
    # æŒ‰åˆ‡åˆ†ç´¢å¼•è·å–è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†
    train_common = train_idx.intersection(X_aligned.index)
    valid_common = valid_idx.intersection(X_aligned.index)
    test_common = test_idx.intersection(X_aligned.index)
    
    X_train = X_aligned.loc[train_common].sort_index(level='date')
    y_train = y_aligned.loc[train_common].sort_index(level='date')
    X_valid = X_aligned.loc[valid_common].sort_index(level='date')
    y_valid = y_aligned.loc[valid_common].sort_index(level='date')
    X_test = X_aligned.loc[test_common].sort_index(level='date')
    # y_test ç”¨äºæœªæ¥è®¡ç®—æµ‹è¯•é›†æ’åºæŸå¤±ï¼ˆå¦‚ NDCGï¼‰ï¼Œå½“å‰è¯„ä¼°ç”¨åŸå§‹æ”¶ç›Š
    y_test = y_aligned.loc[test_common].sort_index(level='date')
    
    print(f"è®­ç»ƒé›†: {len(X_train):,} æ ·æœ¬")
    print(f"éªŒè¯é›†: {len(X_valid):,} æ ·æœ¬")
    print(f"æµ‹è¯•é›†: {len(X_test):,} æ ·æœ¬")
    
    # æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©æ¨¡å‹
    if task_type == 'lambdarank':
        # LambdaRank éœ€è¦ group
        train_groups = X_train.groupby(level='date').size().tolist()
        valid_groups = X_valid.groupby(level='date').size().tolist()
        
        model_config = config['models'].get('lightgbm_ranker', {}).get('params', {})
        model = LightGBMRanker(params=model_config)
        
        train_result = model.fit(
            X_train, y_train,
            X_valid, y_valid,
            groups=train_groups,
            valid_groups=valid_groups
        )
    else:
        # å›å½’æ¨¡å‹ï¼ˆregression æˆ– regression_rankï¼‰
        model_config = config['models'].get('lightgbm', {}).get('params', {})
        model = LightGBMModel(params=model_config)
        
        train_result = model.fit(X_train, y_train, X_valid, y_valid)
    
    # é¢„æµ‹
    pred_train = model.predict(X_train)
    pred_valid = model.predict(X_valid)
    pred_test = model.predict(X_test)
    
    # å°†é¢„æµ‹å€¼è½¬ä¸º Seriesï¼ˆä¿æŒ MultiIndexï¼‰
    pred_train_series = pd.Series(pred_train, index=X_train.index, name='score')
    pred_valid_series = pd.Series(pred_valid, index=X_valid.index, name='score')
    pred_test_series = pd.Series(pred_test, index=X_test.index, name='score')
    
    # åˆå¹¶æ‰€æœ‰é¢„æµ‹
    all_predictions = pd.concat([pred_train_series, pred_valid_series, pred_test_series])
    all_predictions = all_predictions.to_frame('score')
    
    # ä½¿ç”¨ CrossSectionAnalyzer è¯„ä¼°
    # æ³¨æ„ï¼šè¯„ä¼°æ—¶ç»Ÿä¸€ä½¿ç”¨åŸå§‹æ”¶ç›Šä½œä¸º forward_returns
    test_forward_returns = forward_returns.loc[test_common]
    
    print("\nğŸ“Š æµ‹è¯•é›†æ¨ªæˆªé¢è¯„ä¼°...")
    
    analyzer = CrossSectionAnalyzer(
        factors=pred_test_series.to_frame('model_score'),
        forward_returns=test_forward_returns
    )
    analyzer.analyze()
    
    results = analyzer.get_results()
    
    # æå–å…³é”®æŒ‡æ ‡
    ic_summary = results.get('ic_summary', {})
    spreads = results.get('spreads', {})
    
    # æ„å»ºç»“æœæ±‡æ€»
    summary = {
        'task_type': task_type,
        'train_samples': len(X_train),
        'valid_samples': len(X_valid),
        'test_samples': len(X_test),
        'training_result': train_result,
        'ic_summary': {},
        'spreads': {}
    }
    
    # è½¬æ¢ IC ç»Ÿè®¡
    for key, value in ic_summary.items():
        if isinstance(value, dict):
            summary['ic_summary'][str(key)] = {
                k: float(v) if isinstance(v, (np.floating, np.integer)) else v
                for k, v in value.items()
            }
    
    # è½¬æ¢ Spread
    for key, value in spreads.items():
        if hasattr(value, 'mean'):
            summary['spreads'][str(key)] = {
                'mean': float(value.mean()),
                'std': float(value.std()),
                'sharpe': float(value.mean() / value.std()) if value.std() != 0 else 0
            }
    
    # ä¿å­˜ç»“æœ
    result_path = os.path.join(output_dir, f'{task_type}_results.json')
    with open(result_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"âœ… ç»“æœå·²ä¿å­˜: {result_path}")
    
    # ä¿å­˜é¢„æµ‹
    pred_path = os.path.join(output_dir, f'{task_type}_predictions.parquet')
    all_predictions.to_parquet(pred_path)
    print(f"âœ… é¢„æµ‹å·²ä¿å­˜: {pred_path}")
    
    # ä¿å­˜æ¨¡å‹
    model_path = os.path.join(output_dir, f'{task_type}_model.pkl')
    model.save(model_path)
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {model_path}")
    
    return summary


def compare_results(results: Dict[str, Dict], output_dir: str) -> Dict:
    """
    å¯¹æ¯”ä¸‰æ¡çº¿çš„ç»“æœ
    
    Parameters:
    -----------
    results : Dict[str, Dict]
        å„ä»»åŠ¡ç±»å‹çš„ç»“æœ
    output_dir : str
        è¾“å‡ºç›®å½•
        
    Returns:
    --------
    dict
        å¯¹æ¯”æ±‡æ€»
    """
    print("\n" + "=" * 70)
    print("ä¸‰æ¡çº¿å¯¹æ¯”")
    print("=" * 70)
    
    comparison = {
        'timestamp': datetime.now().isoformat(),
        'tasks': list(results.keys()),
        'metrics': {}
    }
    
    # æ”¶é›†å„ä»»åŠ¡çš„å…³é”®æŒ‡æ ‡
    for task_type, result in results.items():
        ic_summary = result.get('ic_summary', {})
        spreads = result.get('spreads', {})
        
        # æå–ç¬¬ä¸€ä¸ªå› å­çš„ IC
        first_ic_key = list(ic_summary.keys())[0] if ic_summary else None
        if first_ic_key:
            ic_stats = ic_summary[first_ic_key]
            comparison['metrics'][task_type] = {
                'mean_ic': ic_stats.get('mean', 0),
                'icir': ic_stats.get('icir', 0),
                'icir_annual': ic_stats.get('icir_annual', 0),
                't_stat': ic_stats.get('t_stat', 0),
                'ic_positive_ratio': ic_stats.get('positive_ratio', 0)
            }
        
        # æå– Spread
        first_spread_key = list(spreads.keys())[0] if spreads else None
        if first_spread_key:
            spread_stats = spreads[first_spread_key]
            comparison['metrics'][task_type]['spread_mean'] = spread_stats.get('mean', 0)
            comparison['metrics'][task_type]['spread_sharpe'] = spread_stats.get('sharpe', 0)
    
    # æ‰“å°å¯¹æ¯”è¡¨æ ¼
    print("\nğŸ“Š å…³é”®æŒ‡æ ‡å¯¹æ¯”:")
    print("-" * 80)
    print(f"{'ä»»åŠ¡ç±»å‹':<20} {'Mean IC':>12} {'ICIR':>12} {'ICIR(å¹´åŒ–)':>12} {'Spread':>12}")
    print("-" * 80)
    
    for task_type, metrics in comparison['metrics'].items():
        print(f"{task_type:<20} "
              f"{metrics.get('mean_ic', 0):>12.4f} "
              f"{metrics.get('icir', 0):>12.4f} "
              f"{metrics.get('icir_annual', 0):>12.4f} "
              f"{metrics.get('spread_mean', 0):>12.4f}")
    
    print("-" * 80)
    
    # è®¡ç®—æå‡æ¯”ä¾‹
    if 'regression' in comparison['metrics'] and len(comparison['metrics']) > 1:
        baseline_ic = comparison['metrics']['regression'].get('mean_ic', 0)
        baseline_icir = comparison['metrics']['regression'].get('icir', 0)
        
        print("\nğŸ“ˆ ç›¸å¯¹å›å½’åŸºçº¿çš„æå‡:")
        for task_type, metrics in comparison['metrics'].items():
            if task_type == 'regression':
                continue
            
            ic_improvement = (abs(metrics.get('mean_ic', 0)) - abs(baseline_ic)) / abs(baseline_ic) * 100 if baseline_ic != 0 else 0
            icir_improvement = (abs(metrics.get('icir', 0)) - abs(baseline_icir)) / abs(baseline_icir) * 100 if baseline_icir != 0 else 0
            
            print(f"  {task_type}: IC æå‡ {ic_improvement:+.1f}%, ICIR æå‡ {icir_improvement:+.1f}%")
            
            comparison['metrics'][task_type]['ic_improvement_vs_baseline'] = ic_improvement
            comparison['metrics'][task_type]['icir_improvement_vs_baseline'] = icir_improvement
    
    # ä¿å­˜å¯¹æ¯”ç»“æœ
    comparison_path = os.path.join(output_dir, 'model_comparison.json')
    with open(comparison_path, 'w', encoding='utf-8') as f:
        json.dump(comparison, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… å¯¹æ¯”ç»“æœå·²ä¿å­˜: {comparison_path}")
    
    return comparison


def run_feature_drift_detection(features: pd.DataFrame,
                                 train_idx: pd.Index,
                                 valid_idx: pd.Index,
                                 test_idx: pd.Index,
                                 output_dir: str,
                                 drift_threshold: float = 0.2,
                                 max_features: Optional[int] = None) -> Dict:
    """
    è¿è¡Œç‰¹å¾åˆ†å¸ƒæ¼‚ç§»æ£€æµ‹ï¼ˆè®­ç»ƒå‰ï¼‰
    
    ä½¿ç”¨ PSI æ£€æµ‹ç‰¹å¾åˆ†å¸ƒæ˜¯å¦å‘ç”Ÿå˜åŒ–ï¼Œç”¨äºï¼š
    - å‘ç°æ•°æ®è´¨é‡é—®é¢˜
    - æ£€æµ‹å¸‚åœºç¯å¢ƒå˜åŒ–
    - å†³å®šæ˜¯å¦éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹
    
    Parameters:
    -----------
    features : pd.DataFrame
        ç‰¹å¾æ•°æ®
    train_idx, valid_idx, test_idx : pd.Index
        åˆ‡åˆ†ç´¢å¼•
    output_dir : str
        è¾“å‡ºç›®å½•
    drift_threshold : float
        æ¼‚ç§»é˜ˆå€¼ï¼ˆPSI >= 0.2 è¡¨ç¤ºæ˜¾è‘—æ¼‚ç§»ï¼‰
    max_features : int, optional
        æœ€å¤šæ£€æµ‹çš„ç‰¹å¾æ•°é‡ï¼ŒNone è¡¨ç¤ºæ£€æµ‹æ‰€æœ‰ç‰¹å¾
        
    Returns:
    --------
    dict
        æ¼‚ç§»æ£€æµ‹ç»“æœ
    """
    print("\n" + "=" * 70)
    print("ç‰¹å¾åˆ†å¸ƒæ¼‚ç§»æ£€æµ‹ (PSI)")
    print("=" * 70)
    
    # ä½¿ç”¨ DriftDetector æ¨¡å—
    detector = DriftDetector(drift_threshold=drift_threshold)
    
    # æŒ‰ç´¢å¼•åˆ‡åˆ†ç‰¹å¾
    train_features = features.loc[train_idx]
    valid_features = features.loc[valid_idx]
    test_features = features.loc[test_idx]
    
    # æ£€æµ‹ç‰¹å¾åˆ†å¸ƒæ¼‚ç§»
    drift_results = detector.detect_feature_drift(
        train_features=train_features,
        valid_features=valid_features,
        test_features=test_features,
        max_features=max_features
    )
    
    # æ‰“å°æ‘˜è¦
    print(f"   æ£€æµ‹ç‰¹å¾æ•°: {drift_results['n_checked']}")
    print(f"   æ¼‚ç§»ç‰¹å¾æ•°: {drift_results['n_drifted']}")
    drifted = drift_results['drifted_features']
    if drifted:
        print(f"   æ¼‚ç§»ç‰¹å¾: {drifted[:5]}{'...' if len(drifted) > 5 else ''}")
    
    # ä¿å­˜ç»“æœ
    drift_path = os.path.join(output_dir, 'feature_drift_report.json')
    with open(drift_path, 'w', encoding='utf-8') as f:
        json.dump(drift_results, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… ç‰¹å¾æ¼‚ç§»æŠ¥å‘Šå·²ä¿å­˜: {drift_path}")
    
    return drift_results


def run_prediction_drift_detection(predictions: Dict[str, pd.Series],
                                    forward_returns: pd.DataFrame,
                                    train_idx: pd.Index,
                                    valid_idx: pd.Index,
                                    test_idx: pd.Index,
                                    output_dir: str,
                                    drift_threshold: float = 0.2) -> Dict:
    """
    è¿è¡Œæ¨¡å‹é¢„æµ‹æ¼‚ç§»æ£€æµ‹ï¼ˆè®­ç»ƒåï¼‰
    
    æ¯”è¾ƒ Train/Valid/Test çš„ IC å’Œ Spread å·®å¼‚ï¼Œç”¨äºï¼š
    - éªŒè¯æ¨¡å‹æ³›åŒ–èƒ½åŠ›
    - æ£€æµ‹è¿‡æ‹Ÿåˆ
    - æ»¡è¶³ç ”ç©¶å®ªç« éªŒæ”¶æ ‡å‡†ï¼ˆValid vs Test å·®å¼‚ < 20%ï¼‰
    
    Parameters:
    -----------
    predictions : Dict[str, pd.Series]
        å„ä»»åŠ¡ç±»å‹çš„é¢„æµ‹ç»“æœ {task_type: pred_series}
    forward_returns : pd.DataFrame
        è¿œæœŸæ”¶ç›Š
    train_idx, valid_idx, test_idx : pd.Index
        åˆ‡åˆ†ç´¢å¼•
    output_dir : str
        è¾“å‡ºç›®å½•
    drift_threshold : float
        æ¼‚ç§»é˜ˆå€¼ï¼ˆé»˜è®¤ 20%ï¼‰
        
    Returns:
    --------
    dict
        é¢„æµ‹æ¼‚ç§»æ£€æµ‹ç»“æœ
    """
    print("\n" + "=" * 70)
    print("æ¨¡å‹é¢„æµ‹æ¼‚ç§»æ£€æµ‹ (IC/Spread)")
    print("=" * 70)
    
    detector = DriftDetector(drift_threshold=drift_threshold)
    
    all_drift_reports = {}
    
    for task_type, pred_series in predictions.items():
        print(f"\nğŸ“Š æ£€æµ‹ {task_type}...")
        
        # è·å–å„åˆ†å‰²çš„é¢„æµ‹å’Œæ”¶ç›Š
        train_common = train_idx.intersection(pred_series.index)
        valid_common = valid_idx.intersection(pred_series.index)
        test_common = test_idx.intersection(pred_series.index)
        
        if len(train_common) == 0 or len(valid_common) == 0 or len(test_common) == 0:
            print(f"   âš ï¸ {task_type} æ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
            continue
        
        # æ„å»ºå› å­ DataFrame
        factors = pred_series.to_frame('model_score')
        
        # åˆ†åˆ«åˆ†æå„åˆ†å‰²
        train_analyzer = CrossSectionAnalyzer(
            factors=factors.loc[train_common],
            forward_returns=forward_returns.loc[train_common]
        )
        train_analyzer.analyze()
        train_results = train_analyzer.get_results()
        
        valid_analyzer = CrossSectionAnalyzer(
            factors=factors.loc[valid_common],
            forward_returns=forward_returns.loc[valid_common]
        )
        valid_analyzer.analyze()
        valid_results = valid_analyzer.get_results()
        
        test_analyzer = CrossSectionAnalyzer(
            factors=factors.loc[test_common],
            forward_returns=forward_returns.loc[test_common]
        )
        test_analyzer.analyze()
        test_results = test_analyzer.get_results()
        
        # ä½¿ç”¨ DriftDetector çš„ detect_drift æ–¹æ³•
        ret_col = list(forward_returns.columns)[0]
        period = ret_col.replace('ret_', '')
        
        drift_report = detector.detect_drift(
            train_results=train_results,
            valid_results=valid_results,
            test_results=test_results,
            factor_name='model_score',
            period=period
        )
        
        all_drift_reports[task_type] = drift_report
    
    # ä¿å­˜ç»“æœ
    drift_path = os.path.join(output_dir, 'prediction_drift_report.json')
    
    # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
    def convert_to_native(obj):
        if isinstance(obj, (np.bool_, bool)):
            return bool(obj)
        elif isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, pd.Series):
            return obj.to_dict()
        elif isinstance(obj, pd.Timestamp):
            return obj.isoformat()
        elif isinstance(obj, dict):
            return {k: convert_to_native(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [convert_to_native(i) for i in obj]
        return obj
    
    with open(drift_path, 'w', encoding='utf-8') as f:
        json.dump(convert_to_native(all_drift_reports), f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… é¢„æµ‹æ¼‚ç§»æŠ¥å‘Šå·²ä¿å­˜: {drift_path}")
    
    # æ±‡æ€»ç»“æœ
    print("\nğŸ“Š é¢„æµ‹æ¼‚ç§»æ£€æµ‹æ±‡æ€»:")
    print("-" * 60)
    for task_type, report in all_drift_reports.items():
        status = "âœ… é€šè¿‡" if report.get('overall_pass', False) else "âŒ æœªé€šè¿‡"
        print(f"   {task_type}: {status}")
    
    return all_drift_reports


def run_portfolio_backtest(predictions: Dict[str, pd.Series],
                           prices: pd.DataFrame,
                           output_dir: str,
                           top_k: int = 30,
                           compare_modes: bool = True) -> Dict:
    """
    è¿è¡Œç»„åˆå›æµ‹ï¼ˆé˜¶æ®µäºŒï¼šé—­ç¯å›æµ‹ï¼‰
    
    æ”¯æŒ A/B æµ‹è¯•ï¼š
    - Close-to-Close (ç†æƒ³æƒ…å†µï¼Œæœ‰å‰è§†åå·®)
    - Open-to-Open (ç°å®æƒ…å†µï¼ŒT+1 æ‰§è¡Œ)
    
    Parameters:
    -----------
    predictions : Dict[str, pd.Series]
        å„ä»»åŠ¡ç±»å‹çš„é¢„æµ‹ç»“æœ {task_type: pred_series}
    prices : pd.DataFrame
        ä»·æ ¼æ•°æ®ï¼ŒMultiIndex [date, ticker]ï¼Œå¿…é¡»åŒ…å« 'open' å’Œ 'close' åˆ—
    output_dir : str
        è¾“å‡ºç›®å½•
    top_k : int
        Top-K é€‰è‚¡æ•°é‡
    compare_modes : bool
        æ˜¯å¦å¯¹æ¯”ä¸¤ç§æ‰§è¡Œæ¨¡å¼
        
    Returns:
    --------
    Dict
        å„ä»»åŠ¡ç±»å‹çš„å›æµ‹ç»“æœ
    """
    print("\n" + "=" * 70)
    print("ç»„åˆå›æµ‹ (Simple Portfolio Backtest)")
    print("=" * 70)
    
    if prices is None:
        print("âš ï¸ ä»·æ ¼æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡å›æµ‹")
        print("   æç¤ºï¼šè¯·ç¡®ä¿ DataLoader åŠ è½½äº†åŒ…å« 'open' å’Œ 'close' åˆ—çš„ä»·æ ¼æ•°æ®")
        return {}
    
    # æ£€æŸ¥ä»·æ ¼æ•°æ®æ˜¯å¦åŒ…å«å¿…è¦åˆ—
    required_cols = ['open', 'close']
    missing_cols = [col for col in required_cols if col not in prices.columns]
    if missing_cols:
        print(f"âš ï¸ ä»·æ ¼æ•°æ®ç¼ºå°‘åˆ—: {missing_cols}ï¼Œè·³è¿‡å›æµ‹")
        return {}
    
    all_backtest_results = {}
    
    for task_type, pred_series in predictions.items():
        print(f"\nğŸ“Š å›æµ‹ {task_type}...")
        
        try:
            backtester = SimplePortfolioBacktester(top_k=top_k)
            
            if compare_modes:
                # A/B æµ‹è¯•ï¼šå¯¹æ¯”ä¸¤ç§æ‰§è¡Œæ¨¡å¼
                result = backtester.compare_modes(
                    predictions=pred_series,
                    prices=prices,
                    save_dir=output_dir
                )
                all_backtest_results[task_type] = result
                
                # ä¿å­˜ç»Ÿè®¡ç»“æœ
                stats_path = os.path.join(output_dir, f'{task_type}_backtest_stats.json')
                stats_to_save = {
                    'close_to_close': result['close_to_close']['stats'],
                    'open_to_open': result['open_to_open']['stats'],
                    'comparison': {k: float(v) if isinstance(v, (np.floating, float)) else v 
                                   for k, v in result['comparison'].items() 
                                   if not isinstance(v, dict)}
                }
                with open(stats_path, 'w', encoding='utf-8') as f:
                    json.dump(stats_to_save, f, indent=2, ensure_ascii=False, default=str)
                print(f"   âœ… å›æµ‹ç»Ÿè®¡å·²ä¿å­˜: {stats_path}")
                
            else:
                # å•æ¨¡å¼å›æµ‹
                result = backtester.run(pred_series, prices)
                all_backtest_results[task_type] = result
                
                # ç»˜åˆ¶å¹¶ä¿å­˜å›¾è¡¨
                plot_path = os.path.join(output_dir, f'{task_type}_backtest.png')
                backtester.plot(result, save_path=plot_path)
                
        except Exception as e:
            print(f"   âŒ {task_type} å›æµ‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    return all_backtest_results


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Baseline æ¨¡å‹è®­ç»ƒç®¡é“')
    parser.add_argument('--config', type=str, default='configs/ml_baseline.yml',
                        help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--task_type', type=str, default=None,
                        choices=['regression', 'regression_rank', 'lambdarank'],
                        help='ä»»åŠ¡ç±»å‹ï¼ˆé»˜è®¤ä»é…ç½®è¯»å–ï¼‰')
    parser.add_argument('--compare_all', action='store_true',
                        help='è¿è¡Œä¸‰æ¡çº¿å¯¹æ¯”')
    parser.add_argument('--skip_drift', action='store_true',
                        help='è·³è¿‡æ¼‚ç§»æ£€æµ‹')
    parser.add_argument('--skip_backtest', action='store_true',
                        help='è·³è¿‡ç»„åˆå›æµ‹')
    parser.add_argument('--backtest_top_k', type=int, default=30,
                        help='å›æµ‹ Top-K é€‰è‚¡æ•°é‡')
    
    args = parser.parse_args()
    
    print("=" * 70)
    print("Baseline æ¨¡å‹è®­ç»ƒç®¡é“ (Learning-to-Rank)")
    print("=" * 70)
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # åŠ è½½é…ç½®
    config = load_config(args.config)
    print(f"âœ… é…ç½®åŠ è½½å®Œæˆ: {args.config}")
    
    # ç¡®å®šä»»åŠ¡ç±»å‹
    if args.compare_all:
        task_types = ['regression', 'regression_rank', 'lambdarank']
    elif args.task_type:
        task_types = [args.task_type]
    else:
        task_types = [config.get('ranking', {}).get('task_type', 'regression')]
    
    print(f"ğŸ“‹ ä»»åŠ¡ç±»å‹: {task_types}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = os.path.join(ml_root, config['paths']['reports_dir'], 'ranking')
    os.makedirs(output_dir, exist_ok=True)
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    # å‡†å¤‡æ•°æ®
    features, forward_returns, prices = prepare_data(config)
    
    # æ—¶åºåˆ‡åˆ†
    cv = TimeSeriesCV.from_config(config)
    train_idx, valid_idx, test_idx = cv.single_split(features)
    
    print(f"\nğŸ“Š æ—¶åºåˆ‡åˆ† (Purged + Embargo):")
    print(f"   è®­ç»ƒé›†: {len(train_idx):,}")
    print(f"   éªŒè¯é›†: {len(valid_idx):,}")
    print(f"   æµ‹è¯•é›†: {len(test_idx):,}")
    
    # ç‰¹å¾åˆ†å¸ƒæ¼‚ç§»æ£€æµ‹ï¼ˆè®­ç»ƒå‰ï¼‰
    if not args.skip_drift:
        drift_threshold = config.get('split', {}).get('drift_threshold', 0.2)
        run_feature_drift_detection(
            features=features,
            train_idx=train_idx,
            valid_idx=valid_idx,
            test_idx=test_idx,
            output_dir=output_dir,
            drift_threshold=drift_threshold
        )
    
    # è¿è¡Œå„ä»»åŠ¡
    all_results = {}
    all_predictions = {}  # æ”¶é›†é¢„æµ‹ç»“æœç”¨äºæ¼‚ç§»æ£€æµ‹
    
    for task_type in task_types:
        try:
            result = run_single_task(
                task_type=task_type,
                config=config,
                features=features,
                forward_returns=forward_returns,
                train_idx=train_idx,
                valid_idx=valid_idx,
                test_idx=test_idx,
                output_dir=output_dir
            )
            all_results[task_type] = result
            
            # åŠ è½½é¢„æµ‹ç»“æœç”¨äºæ¼‚ç§»æ£€æµ‹
            pred_path = os.path.join(output_dir, f'{task_type}_predictions.parquet')
            if os.path.exists(pred_path):
                pred_df = pd.read_parquet(pred_path)
                all_predictions[task_type] = pred_df['score']
                
        except Exception as e:
            print(f"âŒ ä»»åŠ¡ {task_type} å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # æ¨¡å‹é¢„æµ‹æ¼‚ç§»æ£€æµ‹ï¼ˆè®­ç»ƒåï¼‰
    if not args.skip_drift and all_predictions:
        drift_threshold = config.get('split', {}).get('drift_threshold', 0.2)
        run_prediction_drift_detection(
            predictions=all_predictions,
            forward_returns=forward_returns,
            train_idx=train_idx,
            valid_idx=valid_idx,
            test_idx=test_idx,
            output_dir=output_dir,
            drift_threshold=drift_threshold
        )
    
    # å¯¹æ¯”ç»“æœ
    if len(all_results) > 1:
        compare_results(all_results, output_dir)
    
    # ========== ç»„åˆå›æµ‹ (é˜¶æ®µäºŒ) ==========
    if not args.skip_backtest and all_predictions:
        # å°è¯•åŠ è½½ä»·æ ¼æ•°æ®ç”¨äºå›æµ‹
        # å¦‚æœ prepare_data æ²¡æœ‰è¿”å› pricesï¼Œå°è¯•ä» InfluxDB æˆ–æ–‡ä»¶åŠ è½½
        if prices is None:
            print("\nğŸ“‚ å°è¯•åŠ è½½ä»·æ ¼æ•°æ®ç”¨äºå›æµ‹...")
            try:
                # å°è¯•ä» DataLoader åŠ è½½ä»·æ ¼æ•°æ®
                data_config = config['data']
                influxdb_config = data_config.get('influxdb', {}).copy()
                influxdb_config.pop('enabled', None)
                
                loader = DataLoader(
                    enable_influxdb=data_config['influxdb']['enabled'],
                    influxdb_config=influxdb_config
                )
                
                # è·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç 
                all_tickers = list(set(
                    idx[1] for pred in all_predictions.values() 
                    for idx in pred.index
                ))
                
                # åŠ è½½ä»·æ ¼æ•°æ®
                prices_list = []
                for ticker in all_tickers[:10]:  # é™åˆ¶æ•°é‡é¿å…è¿‡æ…¢
                    try:
                        price_df = loader.load_market_data(ticker)
                        if price_df is not None and 'open' in price_df.columns:
                            prices_list.append(price_df)
                    except:
                        continue
                
                if prices_list:
                    prices = pd.concat(prices_list)
                    print(f"   âœ… åŠ è½½ä»·æ ¼æ•°æ®: {len(prices)} æ¡è®°å½•")
                else:
                    print("   âš ï¸ æ— æ³•åŠ è½½ä»·æ ¼æ•°æ®ï¼Œè·³è¿‡å›æµ‹")
                    prices = None
                    
            except Exception as e:
                print(f"   âš ï¸ åŠ è½½ä»·æ ¼æ•°æ®å¤±è´¥: {e}")
                prices = None
        
        if prices is not None:
            backtest_results = run_portfolio_backtest(
                predictions=all_predictions,
                prices=prices,
                output_dir=output_dir,
                top_k=args.backtest_top_k,
                compare_modes=True  # é»˜è®¤è¿›è¡Œ A/B æµ‹è¯•
            )
    
    print("\n" + "=" * 70)
    print("âœ… Baseline æ¨¡å‹è®­ç»ƒå®Œæˆ")
    print("=" * 70)


if __name__ == "__main__":
    main()
