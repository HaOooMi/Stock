#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨ªæˆªé¢å› å­è¯„ä¼°ç¤ºä¾‹è„šæœ¬

å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ¨ªæˆªé¢è¯„ä¼°æ¡†æ¶è¿›è¡Œå› å­åˆ†æ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import numpy as np
from datetime import datetime

# å¯¼å…¥æ¨ªæˆªé¢è¯„ä¼°æ¨¡å—
from evaluation.cross_section_analyzer import CrossSectionAnalyzer
from evaluation.visualization import create_factor_tearsheet_plots
from evaluation.tearsheet import generate_full_tearsheet


def load_demo_data():
    """
    åŠ è½½æ¼”ç¤ºæ•°æ®
    
    å®é™…ä½¿ç”¨æ—¶ï¼Œè¯·æ›¿æ¢ä¸ºçœŸå®æ•°æ®åŠ è½½é€»è¾‘
    """
    print("ğŸ“¦ åŠ è½½æ¼”ç¤ºæ•°æ®...")
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    np.random.seed(42)
    
    # æ—¶é—´èŒƒå›´ï¼š1å¹´
    dates = pd.date_range('2023-01-01', '2023-12-31', freq='D')
    # è‚¡ç¥¨æ± ï¼š100åªè‚¡ç¥¨
    tickers = [f'Stock_{i:03d}' for i in range(100)]
    
    # åˆ›å»ºMultiIndex
    index = pd.MultiIndex.from_product(
        [dates, tickers],
        names=['date', 'ticker']
    )
    
    # 1. ä»·æ ¼æ•°æ®ï¼ˆæ¨¡æ‹Ÿï¼‰
    prices = pd.DataFrame({
        'close': 100 + np.random.randn(len(index)).cumsum() * 0.1
    }, index=index)
    
    # 2. å› å­æ•°æ®ï¼ˆæ·»åŠ ä¸€äº›é¢„æµ‹èƒ½åŠ›ï¼‰
    # è®¡ç®—çœŸå®æ”¶ç›Šï¼ˆç”¨äºæ„é€ æœ‰é¢„æµ‹èƒ½åŠ›çš„å› å­ï¼‰
    returns_true = prices['close'].groupby(level='ticker').pct_change()
    
    factors = pd.DataFrame({
        'factor_momentum': returns_true.shift(1) + np.random.randn(len(index)) * 0.02,  # åŠ¨é‡å› å­
        'factor_value': np.random.randn(len(index)) * 0.01,  # ä»·å€¼å› å­ï¼ˆéšæœºï¼Œå¼±å› å­ï¼‰
        'factor_quality': returns_true.shift(2) * 0.5 + np.random.randn(len(index)) * 0.015,  # è´¨é‡å› å­
    }, index=index)
    
    # 3. å¸‚å€¼æ•°æ®ï¼ˆå¯é€‰ï¼Œç”¨äºä¸­æ€§åŒ–ï¼‰
    market_cap = pd.DataFrame({
        'market_cap': np.random.lognormal(20, 2, len(index))
    }, index=index)
    
    # 4. è¡Œä¸šæ•°æ®ï¼ˆå¯é€‰ï¼Œç”¨äºä¸­æ€§åŒ–ï¼‰
    industries = ['é‡‘è', 'ç§‘æŠ€', 'æ¶ˆè´¹', 'åŒ»è¯', 'å·¥ä¸š', 'èƒ½æº', 'ææ–™', 'é€šä¿¡']
    industry = pd.DataFrame({
        'industry': np.random.choice(industries, len(index))
    }, index=index)
    
    # 5. å¯äº¤æ˜“æ€§è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰
    # ä¾‹å¦‚ï¼šå‰”é™¤åœç‰Œã€æ¶¨è·Œåœã€STç­‰
    tradable_mask = pd.DataFrame({
        'tradable': np.random.rand(len(index)) > 0.05  # 95%å¯äº¤æ˜“
    }, index=index)
    
    print(f"   âœ… ä»·æ ¼æ•°æ®: {prices.shape}")
    print(f"   âœ… å› å­æ•°æ®: {factors.shape}, å› å­æ•°: {len(factors.columns)}")
    print(f"   âœ… å¸‚å€¼æ•°æ®: {market_cap.shape}")
    print(f"   âœ… è¡Œä¸šæ•°æ®: {industry.shape}")
    
    return prices, factors, market_cap, industry, tradable_mask


def run_cross_section_analysis(prices, factors, market_cap, industry, tradable_mask,
                               output_dir='./ML output/reports/baseline_v1/factors'):
    """
    æ‰§è¡Œæ¨ªæˆªé¢åˆ†æ
    
    Parameters:
    -----------
    prices : pd.DataFrame
        ä»·æ ¼æ•°æ®
    factors : pd.DataFrame
        å› å­æ•°æ®
    market_cap : pd.DataFrame
        å¸‚å€¼æ•°æ®
    industry : pd.DataFrame
        è¡Œä¸šæ•°æ®
    tradable_mask : pd.DataFrame
        å¯äº¤æ˜“æ€§æ ‡è®°
    output_dir : str
        è¾“å‡ºç›®å½•
    """
    print("\n" + "=" * 70)
    print("æ¨ªæˆªé¢å› å­è¯„ä¼°æµç¨‹")
    print("=" * 70)
    
    # æ­¥éª¤1ï¼šåˆ›å»ºåˆ†æå™¨
    print("\næ­¥éª¤1: åˆ›å»ºCrossSectionAnalyzer")
    print("-" * 70)
    
    analyzer = CrossSectionAnalyzer(
        factors=factors,
        prices=prices,
        tradable_mask=tradable_mask,
        market_cap=market_cap,
        industry=industry
    )
    
    # æ­¥éª¤2ï¼šå› å­é¢„å¤„ç†ï¼ˆå¯é€‰ï¼‰
    print("\næ­¥éª¤2: å› å­é¢„å¤„ç†")
    print("-" * 70)
    print("é…ç½®:")
    print("  - Winsorize: True (1%-99%)")
    print("  - æ ‡å‡†åŒ–: True (Z-score)")
    print("  - ä¸­æ€§åŒ–: False (æ¼”ç¤ºæ—¶å…³é—­ï¼Œå®ç›˜å»ºè®®å¼€å¯)")
    
    analyzer.preprocess(
        winsorize=True,
        standardize=True,
        neutralize=False,  # å®ç›˜æ—¶å»ºè®®è®¾ä¸ºTrue
        winsorize_params={'lower_quantile': 0.01, 'upper_quantile': 0.99},
        standardize_params={'method': 'z_score', 'cross_section': True}
    )
    
    # æ­¥éª¤3ï¼šè®¡ç®—è¿œæœŸæ”¶ç›Š
    print("\næ­¥éª¤3: è®¡ç®—è¿œæœŸæ”¶ç›Š")
    print("-" * 70)
    
    analyzer.calculate_returns(
        periods=[1, 5, 10, 20],  # 1æ—¥ã€5æ—¥ã€10æ—¥ã€20æ—¥
        method='simple'  # æˆ–'log'
    )
    
    # æ­¥éª¤4ï¼šæ‰§è¡Œæ¨ªæˆªé¢åˆ†æ
    print("\næ­¥éª¤4: æ‰§è¡Œæ¨ªæˆªé¢åˆ†æ")
    print("-" * 70)
    
    analyzer.analyze(
        n_quantiles=5,  # åˆ†5æ¡£
        ic_method='spearman',  # Rank IC
        spread_method='top_minus_mean',  # Top - Meanï¼ˆå®ç›˜æ›´è´´åˆï¼‰
        periods_per_year=252  # å¹´åŒ–å‚æ•°
    )
    
    # æ­¥éª¤5ï¼šæŸ¥çœ‹æ±‡æ€»ç»“æœ
    print("\næ­¥éª¤5: æŸ¥çœ‹æ±‡æ€»ç»“æœ")
    print("-" * 70)
    
    analyzer.summary()
    
    # æ­¥éª¤6ï¼šç”ŸæˆæŠ¥å‘Š
    print("\næ­¥éª¤6: ç”ŸæˆæŠ¥å‘Šå’Œå›¾è¡¨")
    print("-" * 70)
    
    results = analyzer.get_results()
    
    # ä¸ºæ¯ä¸ªå› å­å’Œæ”¶ç›ŠæœŸç»„åˆç”ŸæˆæŠ¥å‘Š
    factor_names = factors.columns.tolist()
    return_periods = ['ret_1d', 'ret_5d', 'ret_10d', 'ret_20d']
    
    for factor_name in factor_names:
        for return_period in return_periods:
            key = (factor_name, return_period)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
            if 'ic_summary' not in results or key not in results['ic_summary']:
                print(f"   âš ï¸  è·³è¿‡ {factor_name} @ {return_period}ï¼ˆæ— æ•°æ®ï¼‰")
                continue
            
            print(f"\n   ğŸ“Š ç”ŸæˆæŠ¥å‘Š: {factor_name} @ {return_period}")
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            factor_output_dir = os.path.join(output_dir, factor_name)
            os.makedirs(factor_output_dir, exist_ok=True)
            
            # ç”Ÿæˆå›¾è¡¨
            plot_paths = create_factor_tearsheet_plots(
                results,
                factor_name,
                return_period,
                factor_output_dir
            )
            
            # ç”ŸæˆHTMLæŠ¥å‘Šå’ŒCSV
            generate_full_tearsheet(
                results,
                factor_name,
                return_period,
                factor_output_dir,
                plot_paths
            )
    
    print("\n" + "=" * 70)
    print("âœ… æ¨ªæˆªé¢åˆ†æå®Œæˆï¼")
    print(f"ğŸ“ æŠ¥å‘Šç›®å½•: {output_dir}")
    print("=" * 70)
    
    return analyzer, results


def verify_results(results):
    """
    éªŒæ”¶æ£€æŸ¥
    
    è¦æ±‚ï¼š
    1. ICä¸æ‰‹ç®—ä¸€è‡´
    2. åˆ†å±‚æ”¶ç›Šå›¾ã€ICèµ°å»Šå›¾ã€æ¢æ‰‹æ›²çº¿è¾“å‡ºé½å…¨
    """
    print("\n" + "=" * 70)
    print("éªŒæ”¶æ£€æŸ¥")
    print("=" * 70)
    
    checks_passed = []
    checks_failed = []
    
    # æ£€æŸ¥1ï¼šICè®¡ç®—
    if 'ic_summary' in results and len(results['ic_summary']) > 0:
        checks_passed.append("âœ… ICç»Ÿè®¡è®¡ç®—å®Œæˆ")
        
        # æ£€æŸ¥ICçš„åˆç†æ€§
        first_key = list(results['ic_summary'].keys())[0]
        ic_summary = results['ic_summary'][first_key]
        
        if 'mean' in ic_summary and not np.isnan(ic_summary['mean']):
            checks_passed.append(f"âœ… ICå‡å€¼æœ‰æ•ˆ: {ic_summary['mean']:.4f}")
        else:
            checks_failed.append("âŒ ICå‡å€¼æ— æ•ˆ")
    else:
        checks_failed.append("âŒ ICç»Ÿè®¡æœªç”Ÿæˆ")
    
    # æ£€æŸ¥2ï¼šåˆ†ä½æ•°æ”¶ç›Š
    if 'quantile_returns' in results and len(results['quantile_returns']) > 0:
        checks_passed.append("âœ… åˆ†ä½æ•°æ”¶ç›Šè®¡ç®—å®Œæˆ")
    else:
        checks_failed.append("âŒ åˆ†ä½æ•°æ”¶ç›Šæœªç”Ÿæˆ")
    
    # æ£€æŸ¥3ï¼šç´¯è®¡æ”¶ç›Š
    if 'cumulative_returns' in results and len(results['cumulative_returns']) > 0:
        checks_passed.append("âœ… ç´¯è®¡æ”¶ç›Šè®¡ç®—å®Œæˆ")
    else:
        checks_failed.append("âŒ ç´¯è®¡æ”¶ç›Šæœªç”Ÿæˆ")
    
    # æ£€æŸ¥4ï¼šSpread
    if 'spreads' in results and len(results['spreads']) > 0:
        checks_passed.append("âœ… Spreadè®¡ç®—å®Œæˆ")
    else:
        checks_failed.append("âŒ Spreadæœªç”Ÿæˆ")
    
    # æ£€æŸ¥5ï¼šæ¢æ‰‹ç‡
    if 'turnover_stats' in results and len(results['turnover_stats']) > 0:
        checks_passed.append("âœ… æ¢æ‰‹ç‡è®¡ç®—å®Œæˆ")
    else:
        checks_failed.append("âŒ æ¢æ‰‹ç‡æœªç”Ÿæˆ")
    
    # æ‰“å°ç»“æœ
    print("\né€šè¿‡çš„æ£€æŸ¥:")
    for check in checks_passed:
        print(f"  {check}")
    
    if checks_failed:
        print("\næœªé€šè¿‡çš„æ£€æŸ¥:")
        for check in checks_failed:
            print(f"  {check}")
    
    print("\n" + "=" * 70)
    
    if len(checks_failed) == 0:
        print("ğŸ‰ æ‰€æœ‰éªŒæ”¶æ£€æŸ¥é€šè¿‡ï¼")
    else:
        print(f"âš ï¸  {len(checks_failed)}/{len(checks_passed) + len(checks_failed)} é¡¹æ£€æŸ¥æœªé€šè¿‡")
    
    print("=" * 70)


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("æ¨ªæˆªé¢å› å­è¯„ä¼°ç¤ºä¾‹")
    print("=" * 70)
    print(f"è¿è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # 1. åŠ è½½æ•°æ®
    prices, factors, market_cap, industry, tradable_mask = load_demo_data()
    
    # 2. æ‰§è¡Œåˆ†æ
    analyzer, results = run_cross_section_analysis(
        prices,
        factors,
        market_cap,
        industry,
        tradable_mask,
        output_dir='./ML output/reports/baseline_v1/factors'
    )
    
    # 3. éªŒæ”¶
    verify_results(results)
    
    print("\n" + "=" * 70)
    print("ğŸ‰ ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
    print("=" * 70)
    
    print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
    print("   1. æŸ¥çœ‹HTMLæŠ¥å‘Šä»¥äº†è§£å› å­è¡¨ç°")
    print("   2. æ£€æŸ¥ICæ—¶é—´åºåˆ—çš„ç¨³å®šæ€§")
    print("   3. è§‚å¯Ÿåˆ†ä½æ•°æ”¶ç›Šçš„å•è°ƒæ€§")
    print("   4. è¯„ä¼°Spreadçš„å¤æ™®æ¯”")
    print("   5. è€ƒè™‘æ¢æ‰‹ç‡å¯¹äº¤æ˜“æˆæœ¬çš„å½±å“")
    
    print("\nğŸ“š å®ç›˜ä½¿ç”¨å»ºè®®:")
    print("   1. å¼€å¯ä¸­æ€§åŒ–ï¼ˆneutralize=Trueï¼‰")
    print("   2. ä½¿ç”¨çœŸå®çš„å¸‚å€¼å’Œè¡Œä¸šæ•°æ®")
    print("   3. æ·»åŠ å¯äº¤æ˜“æ€§è¿‡æ»¤ï¼ˆåœç‰Œã€æ¶¨è·Œåœã€STç­‰ï¼‰")
    print("   4. å®šæœŸå›æµ‹ä»¥éªŒè¯å› å­æœ‰æ•ˆæ€§")
    print("   5. ç»„åˆå¤šä¸ªæœ‰æ•ˆå› å­ä»¥æå‡ç¨³å®šæ€§")


if __name__ == '__main__':
    main()
