#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœºå™¨å­¦ä¹ åŸºçº¿è®­ç»ƒä¸»è„šæœ¬

é˜¶æ®µ12ï¼šæœºå™¨å­¦ä¹ åŸºçº¿ï¼ˆå›å½’/æ’åºï¼‰
- å›å½’ç›®æ ‡ï¼šfuture_return_5d
- æ¨¡å‹ï¼šRidge, RandomForestRegressor, LightGBM
- é¢„æµ‹æµ‹è¯•æ®µ â†’ åˆ†5æ¡¶ â†’ ç»Ÿè®¡æ¯æ¡¶çœŸå®æ”¶ç›Š
- è¾“å‡ºï¼šreports/model_bucket_performance.csv
- ç”ŸæˆåŸºäº"Topæ¡¶"ç­–ç•¥æ”¶ç›Šå¯¹æ¯”

éªŒæ”¶ï¼š
- Topæ¡¶æ”¶ç›Š > å…¨ä½“å‡å€¼
- Spreadï¼ˆTop - Bottomï¼‰ä¸ºæ­£
"""

import os
import sys
import yaml
import argparse
import pandas as pd
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
ml_root = os.path.dirname(current_dir)
if ml_root not in sys.path:
    sys.path.insert(0, ml_root)

# å¯¼å…¥æ¨¡å—
from data.data_loader import DataLoader
from models.ridge_model import RidgeModel
from models.rf_model import RandomForestModel
try:
    from models.lgbm_model import LightGBMModel
    HAS_LIGHTGBM = True
except ImportError:
    HAS_LIGHTGBM = False
    print("âš ï¸ LightGBMæœªå®‰è£…ï¼Œå°†è·³è¿‡è¯¥æ¨¡å‹")

from evaluation.metrics import calculate_metrics
from evaluation.bucketing import bucket_predictions, analyze_bucket_performance
from evaluation.reporting import generate_report
from utils.splitting import time_series_split
from utils.logger import setup_logger


def load_config(config_path: str) -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºåŸºäºml_rootçš„ç»å¯¹è·¯å¾„
    if not os.path.isabs(config_path):
        config_path = os.path.join(ml_root, config_path.replace("machine learning/", ""))
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config


def main(config_path: str = "configs/ml_baseline.yml"):
    """
    ä¸»è®­ç»ƒæµç¨‹
    
    Parameters:
    -----------
    config_path : str
        é…ç½®æ–‡ä»¶è·¯å¾„
    """
    print("=" * 70)
    print("ğŸš€ æœºå™¨å­¦ä¹ åŸºçº¿è®­ç»ƒ")
    print("=" * 70)
    
    # 1. åŠ è½½é…ç½®
    print("\nğŸ“‹ åŠ è½½é…ç½®...")
    config = load_config(config_path)
    
    # æ˜¾ç¤ºé¡¹ç›®ä¿¡æ¯
    project_info = config.get('project', {})
    if project_info:
        print(f"   ğŸ“¦ é¡¹ç›®: {project_info.get('name', 'N/A')}")
        print(f"   ğŸ“ æè¿°: {project_info.get('description', 'N/A')}")
        print(f"   ğŸ”– ç‰ˆæœ¬: {project_info.get('version', 'N/A')}")
    print(f"   âœ… é…ç½®åŠ è½½å®Œæˆ")
    
    # è§„èŒƒåŒ–è·¯å¾„å¹¶åˆ›å»ºè¾“å‡ºç›®å½•
    paths = config['paths']
    for key, path in list(paths.items()):
        if path and isinstance(path, str):
            # å°†ç›¸å¯¹è·¯å¾„è½¬æ¢ä¸ºç›¸å¯¹äº ml_root çš„ç»å¯¹è·¯å¾„
            normalized_path = path if os.path.isabs(path) else os.path.join(ml_root, path)
            paths[key] = normalized_path
            if 'baseline_v1' in normalized_path:
                os.makedirs(normalized_path, exist_ok=True)
    print(f"   ğŸ“ è¾“å‡ºç›®å½•å·²åˆ›å»º")
    
    # è®¾ç½®éšæœºç§å­
    random_seed = config['runtime']['random_seed']
    np.random.seed(random_seed)
    print(f"   ğŸ² éšæœºç§å­: {random_seed}")
    
    # 2. åŠ è½½æ•°æ®
    print("\nğŸ“Š åŠ è½½æ•°æ®...")
    # ä½¿ç”¨ datasets_dir ä½œä¸ºæ•°æ®æ ¹ç›®å½•ï¼ˆè½¬æ¢ä¸ºç»å¯¹è·¯å¾„ï¼‰
    data_root = config['paths'].get('datasets_dir', os.path.join(ml_root, 'ML output/datasets/baseline_v1'))
    data_loader = DataLoader(data_root)
    
    features, targets = data_loader.load_features_and_targets(
        symbol=config['data']['symbol'],
        target_col=config['target']['name'],
        use_scaled=config['features']['use_scaled_features']
    )
    
    print(f"   âœ… æ•°æ®åŠ è½½å®Œæˆ")
    print(f"      ç‰¹å¾æ•°: {features.shape[1]}")
    print(f"      æ ·æœ¬æ•°: {len(features)}")
    
    # æ£€æµ‹æ˜¯å¦ä¸ºå•è‚¡ç¥¨åœºæ™¯
    n_symbols = features.index.get_level_values('ticker').nunique()
    is_cross_section = n_symbols > 1
    print(f"      è‚¡ç¥¨æ•°: {n_symbols} ({'å¤šè‚¡ç¥¨æ¨ªæˆªé¢' if is_cross_section else 'å•è‚¡ç¥¨æ—¶åº'})")
    
    # 3. æ•°æ®åˆ‡åˆ†
    print("\nğŸ“… æ•°æ®åˆ‡åˆ†...")
    # åˆå¹¶ç‰¹å¾å’Œç›®æ ‡ä»¥ä¾¿åˆ‡åˆ†
    full_data = features.copy()
    full_data['target'] = targets
    
    splits = time_series_split(
        full_data,
        train_ratio=config['split']['train_ratio'],
        valid_ratio=config['split']['valid_ratio'],
        test_ratio=config['split']['test_ratio'],
        purge_days=config['split']['purge_days']
    )
    
    # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
    X_train = splits['train'].drop('target', axis=1)
    y_train = splits['train']['target']
    
    X_valid = splits['valid'].drop('target', axis=1) if len(splits['valid']) > 0 else None
    y_valid = splits['valid']['target'] if len(splits['valid']) > 0 else None
    
    X_test = splits['test'].drop('target', axis=1)
    y_test = splits['test']['target']
    
    print(f"   âœ… æ•°æ®åˆ‡åˆ†å®Œæˆ")
    
    # 4. æ¨¡å‹è®­ç»ƒ
    print("\nğŸ¤– æ¨¡å‹è®­ç»ƒ...")
    models_config = config['models']
    models = {}
    training_results = {}
    
    # Ridge
    if models_config['ridge']['enabled']:
        print("\nğŸ“Œ è®­ç»ƒRidgeæ¨¡å‹")
        ridge_model = RidgeModel(params=models_config['ridge']['params'])
        ridge_results = ridge_model.fit(X_train, y_train, X_valid, y_valid)
        models['Ridge'] = ridge_model
        training_results['Ridge'] = ridge_results
    
    # RandomForest
    if models_config['random_forest']['enabled']:
        print("\nğŸŒ² è®­ç»ƒRandomForestæ¨¡å‹")
        rf_model = RandomForestModel(params=models_config['random_forest']['params'])
        rf_results = rf_model.fit(X_train, y_train, X_valid, y_valid)
        models['RandomForest'] = rf_model
        training_results['RandomForest'] = rf_results
    
    # LightGBM
    if models_config['lightgbm']['enabled'] and HAS_LIGHTGBM:
        print("\nğŸ’¡ è®­ç»ƒLightGBMæ¨¡å‹")
        lgbm_model = LightGBMModel(params=models_config['lightgbm']['params'])
        lgbm_results = lgbm_model.fit(X_train, y_train, X_valid, y_valid)
        models['LightGBM'] = lgbm_model
        training_results['LightGBM'] = lgbm_results
    
    print(f"\nâœ… æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œå…±{len(models)}ä¸ªæ¨¡å‹")
    
    # 5. æµ‹è¯•é›†é¢„æµ‹ä¸è¯„ä¼°
    print("\nğŸ¯ æµ‹è¯•é›†é¢„æµ‹ä¸è¯„ä¼°...")
    
    all_predictions = []
    model_metrics = {}
    
    for model_name, model in models.items():
        print(f"\n   ğŸ“Š è¯„ä¼° {model_name} æ¨¡å‹")
        
        # é¢„æµ‹
        y_pred = model.predict(X_test)
        
        # è®¡ç®—æŒ‡æ ‡
        metrics = calculate_metrics(y_test, y_pred)
        model_metrics[model_name] = metrics
        
        print(f"      MSE: {metrics['mse']:.6f}")
        print(f"      MAE: {metrics['mae']:.6f}")
        print(f"      IC: {metrics['ic']:.4f} (p={metrics['ic_pvalue']:.4f})")
        print(f"      Rank IC: {metrics['rank_ic']:.4f} (p={metrics['rank_ic_pvalue']:.4f})")
        
        # ä¿å­˜é¢„æµ‹
        pred_df = pd.DataFrame({
            'y_true': y_test,
            'y_pred': y_pred,
            'model': model_name
        }, index=y_test.index)
        
        all_predictions.append(pred_df)
    
    # 6. åˆ†æ¡¶åˆ†æ
    print("\nğŸ“Š åˆ†æ¡¶åˆ†æ...")
    
    bucket_results = []
    
    for model_name, model in models.items():
        print(f"\n   ğŸª£ {model_name} åˆ†æ¡¶åˆ†æ")
        
        # è·å–è¯¥æ¨¡å‹çš„é¢„æµ‹
        model_pred = [p for p in all_predictions if p['model'].iloc[0] == model_name][0]
        
        # åˆ†æ¡¶
        bucketed = bucket_predictions(
            model_pred,
            n_buckets=config['evaluation']['n_buckets'],
            method=config['evaluation']['bucket_method'],
            cross_section=is_cross_section  # æ ¹æ®è‚¡ç¥¨æ•°è‡ªåŠ¨é€‰æ‹©åˆ†æ¡¶æ–¹å¼
        )
        
        # åˆ†ææ¡¶è¡¨ç°
        bucket_stats = analyze_bucket_performance(bucketed)
        bucket_stats['model'] = model_name
        
        bucket_results.append(bucket_stats)
    
    # åˆå¹¶æ‰€æœ‰æ¨¡å‹çš„åˆ†æ¡¶ç»“æœ
    all_bucket_stats = pd.concat(bucket_results, ignore_index=True)
    
    # 7. éªŒæ”¶æ£€æŸ¥
    print("\nâœ… éªŒæ”¶æ£€æŸ¥...")
    
    validation_results = {}
    
    for model_name in models.keys():
        model_buckets = all_bucket_stats[all_bucket_stats['model'] == model_name]
        
        if len(model_buckets) >= 2:
            top_bucket = model_buckets.iloc[-1]
            bottom_bucket = model_buckets.iloc[0]
            
            top_mean = top_bucket['mean_y_true']
            bottom_mean = bottom_bucket['mean_y_true']
            spread = top_mean - bottom_mean
            
            overall_mean = y_test.mean()
            
            top_vs_mean = top_mean > overall_mean
            spread_positive = spread > 0
            
            validation_results[model_name] = {
                'top_mean': float(top_mean),
                'bottom_mean': float(bottom_mean),
                'overall_mean': float(overall_mean),
                'spread': float(spread),
                'top_vs_mean': bool(top_vs_mean),
                'spread_positive': bool(spread_positive),
                'pass': bool(top_vs_mean and spread_positive)
            }
            
            print(f"\n   {model_name}:")
            print(f"      Topæ¡¶ > å…¨ä½“å‡å€¼: {'âœ…' if top_vs_mean else 'âŒ'} ({top_mean:.6f} vs {overall_mean:.6f})")
            print(f"      Spread > 0: {'âœ…' if spread_positive else 'âŒ'} ({spread:.6f})")
            print(f"      éªŒæ”¶ç»“æœ: {'âœ… é€šè¿‡' if (top_vs_mean and spread_positive) else 'âŒ æœªé€šè¿‡'}")
    
    # 8. ä¿å­˜æ¨¡å‹
    if config['output']['save_models']:
        print("\nğŸ’¾ ä¿å­˜æ¨¡å‹...")
        
        for model_name, model in models.items():
            # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©ä¿å­˜è·¯å¾„
            if 'ridge' in model_name.lower():
                save_dir = config['paths'].get('models_ridge', config['paths']['models_dir'])
            elif 'forest' in model_name.lower() or 'rf' in model_name.lower():
                save_dir = config['paths'].get('models_rf', config['paths']['models_dir'])
            elif 'lgbm' in model_name.lower() or 'lightgbm' in model_name.lower():
                save_dir = config['paths'].get('models_lgbm', config['paths']['models_dir'])
            else:
                save_dir = config['paths']['models_dir']
            
            os.makedirs(save_dir, exist_ok=True)
            model_file = os.path.join(save_dir, f"{model_name.lower()}_model.pkl")
            model.save(model_file, format=config['output']['model_format'])
            print(f"   âœ… {model_name} å·²ä¿å­˜åˆ°: {model_file}")
    
    # 9. ç”ŸæˆæŠ¥å‘Š
    print("\nğŸ“ ç”ŸæˆæŠ¥å‘Š...")
    
    # åˆå¹¶æ‰€æœ‰é¢„æµ‹
    all_predictions_df = pd.concat(all_predictions, ignore_index=False)
    
    # å‡†å¤‡æŠ¥å‘Šæ•°æ®
    report_data = {
        'model_metrics': model_metrics,
        'bucket_performance': all_bucket_stats,
        'predictions': all_predictions_df,
        'validation': validation_results,
        'training_results': training_results
    }
    
    # ç”ŸæˆæŠ¥å‘Š
    reports_eval_dir = config['paths'].get('reports_evaluation', config['paths']['reports_dir'])
    os.makedirs(reports_eval_dir, exist_ok=True)
    
    generate_report(
        report_data,
        reports_eval_dir,
        config['output']['bucket_performance'],
        config['output']['predictions_file'],
        config['output']['summary_file']
    )
    
    print(f"   ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {reports_eval_dir}")
    
    # 10. æ€»ç»“
    print("\n" + "=" * 70)
    print("ğŸ‰ è®­ç»ƒæµç¨‹å®Œæˆï¼")
    print("=" * 70)
    
    print(f"\nğŸ“Š æ¨¡å‹æ•°é‡: {len(models)}")
    print(f"ğŸ“ˆ æµ‹è¯•æ ·æœ¬: {len(y_test)}")
    
    # æ˜¾ç¤ºæœ€ä½³æ¨¡å‹
    best_model = None
    best_ic = -999
    
    for model_name, metrics in model_metrics.items():
        if metrics['rank_ic'] > best_ic:
            best_ic = metrics['rank_ic']
            best_model = model_name
    
    if best_model:
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model}")
        print(f"   Rank IC: {best_ic:.4f}")
        
        if best_model in validation_results:
            val = validation_results[best_model]
            print(f"   Topæ¡¶æ”¶ç›Š: {val['top_mean']:.4f}")
            print(f"   Spread: {val['spread']:.4f}")
            print(f"   éªŒæ”¶: {'âœ… é€šè¿‡' if val['pass'] else 'âŒ æœªé€šè¿‡'}")
    
    print(f"\nğŸ“ æŠ¥å‘Šç›®å½•: {config['paths']['reports_dir']}")
    print("\n" + "=" * 70)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='æœºå™¨å­¦ä¹ åŸºçº¿è®­ç»ƒ')
    parser.add_argument('--config', type=str, 
                       default='configs/ml_baseline.yml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    try:
        main(args.config)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
