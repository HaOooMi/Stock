#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç›®æ ‡å·¥ç¨‹æ¨¡å— - ç”Ÿæˆæœºå™¨å­¦ä¹ ç›®æ ‡å˜é‡

åŠŸèƒ½ï¼š
1. åŸºäºæ”¶ç›˜ä»·ç”Ÿæˆæœªæ¥æ”¶ç›Šç‡ç›®æ ‡
2. ç”Ÿæˆåˆ†ç±»æ ‡ç­¾ï¼ˆæ¶¨è·Œã€åˆ†ä½æ•°ï¼‰
3. ä¿å­˜å¸¦ç›®æ ‡çš„å®Œæ•´æ•°æ®é›†
4. é˜²æ­¢æ•°æ®æ³„æ¼ï¼ˆæ­£ç¡®çš„æ—¶é—´åºåˆ—å¤„ç†ï¼‰


"""

import os
import sys
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Union
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
if project_root not in sys.path:
    sys.path.insert(0, project_root)


class TargetEngineer:
    """
    ç›®æ ‡å·¥ç¨‹ç±» - ç”Ÿæˆæœºå™¨å­¦ä¹ ç›®æ ‡å˜é‡
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. åŸºäºä»·æ ¼æ•°æ®ç”Ÿæˆæœªæ¥æ”¶ç›Šç‡ç›®æ ‡
    2. ç”Ÿæˆåˆ†ç±»æ ‡ç­¾ï¼ˆäºŒåˆ†ç±»ã€å¤šåˆ†ç±»ï¼‰
    3. æ•°æ®å®Œæ•´æ€§éªŒè¯
    4. é˜²æ­¢æ—¶é—´åºåˆ—æ•°æ®æ³„æ¼
    """
    
    def __init__(self, data_dir: str = "machine learning/ML output"):
        """
        åˆå§‹åŒ–ç›®æ ‡å·¥ç¨‹å™¨
        
        Parameters:
        -----------
        data_dir : str, default="data"
            æ•°æ®ä¿å­˜ç›®å½•
        """
        # è®¾ç½®æ•°æ®ç›®å½•
        if os.path.isabs(data_dir):
            # å¦‚æœæ˜¯ç»å¯¹è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
            self.data_dir = data_dir
        else:
            # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œç›¸å¯¹äºå½“å‰å·¥ä½œç›®å½•
            self.data_dir = os.path.abspath(data_dir)
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(self.data_dir, exist_ok=True)
        
        print("ğŸ¯ ç›®æ ‡å·¥ç¨‹å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   ğŸ“ æ•°æ®ç›®å½•: {self.data_dir}")

    def generate_future_returns(self, data: pd.DataFrame, 
                               periods: List[int] = [1, 5, 10],
                               price_col: str = 'close') -> pd.DataFrame:
        """
        ç”Ÿæˆæœªæ¥æ”¶ç›Šç‡ç›®æ ‡å˜é‡
        
        Parameters:
        -----------
        data : pd.DataFrame
            åŒ…å«ä»·æ ¼æ•°æ®çš„DataFrameï¼Œéœ€è¦æœ‰æ—¶é—´ç´¢å¼•
        periods : list, default=[1, 5, 10]
            æœªæ¥æ”¶ç›Šç‡çš„æ—¶é—´çª—å£ï¼ˆå¤©æ•°ï¼‰
        price_col : str, default='close'
            ç”¨äºè®¡ç®—æ”¶ç›Šç‡çš„ä»·æ ¼åˆ—å
            
        Returns:
        --------
        pd.DataFrame
            åŒ…å«åŸæ•°æ®å’Œæœªæ¥æ”¶ç›Šç‡ç›®æ ‡çš„DataFrame
        """
        print("ğŸ“ˆ ç”Ÿæˆæœªæ¥æ”¶ç›Šç‡ç›®æ ‡...")
        
        if price_col not in data.columns:
            raise ValueError(f"ä»·æ ¼åˆ— '{price_col}' ä¸å­˜åœ¨äºæ•°æ®ä¸­")
        
        # å¤åˆ¶æ•°æ®ä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
        result_df = data.copy()
        
        # ç¡®ä¿æ•°æ®æŒ‰æ—¶é—´æ’åº
        if not result_df.index.is_monotonic_increasing:
            result_df = result_df.sort_index()
            print("   ğŸ“… æ•°æ®å·²æŒ‰æ—¶é—´æ’åº")
        
        print(f"   ğŸ”¢ ç”Ÿæˆ {len(periods)} ä¸ªæ—¶é—´çª—å£çš„æœªæ¥æ”¶ç›Šç‡")
        
        # ç”Ÿæˆå„ä¸ªæ—¶é—´çª—å£çš„æœªæ¥æ”¶ç›Šç‡
        for period in periods:
            target_col = f'future_return_{period}d'
            
            # è®¡ç®—æœªæ¥æ”¶ç›Šç‡ï¼šshift(-period) è¡¨ç¤ºå‘å‰ç§»åŠ¨periodå¤©
            # å³ï¼šä»Šå¤©çš„ç›®æ ‡ = (periodå¤©åçš„ä»·æ ¼ - ä»Šå¤©ä»·æ ¼) / ä»Šå¤©ä»·æ ¼
            future_prices = result_df[price_col].shift(-period)
            current_prices = result_df[price_col]
            
            # è®¡ç®—æ”¶ç›Šç‡
            result_df[target_col] = (future_prices - current_prices) / current_prices
            
            # ç»Ÿè®¡æœ‰æ•ˆç›®æ ‡æ•°é‡
            valid_targets = result_df[target_col].notna().sum()
            total_samples = len(result_df)
            nan_samples = total_samples - valid_targets
            
            print(f"   ğŸ“Š {target_col}: æœ‰æ•ˆæ ·æœ¬ {valid_targets}, NaNæ ·æœ¬ {nan_samples} (å°¾éƒ¨{period}è¡Œ)")
        
        # éªŒè¯å°¾éƒ¨NaNçš„æ­£ç¡®æ€§
        self._verify_future_returns(result_df, periods)
        
        print(f"âœ… æœªæ¥æ”¶ç›Šç‡ç”Ÿæˆå®Œæˆ")
        return result_df
    
    def generate_classification_labels(self, data: pd.DataFrame,
                                     target_cols: Optional[List[str]] = None,
                                     label_type: str = 'binary',
                                     quantiles: Optional[List[float]] = None) -> pd.DataFrame:
        """
        åŸºäºæœªæ¥æ”¶ç›Šç‡ç”Ÿæˆåˆ†ç±»æ ‡ç­¾
        
        Parameters:
        -----------
        data : pd.DataFrame
            åŒ…å«æœªæ¥æ”¶ç›Šç‡çš„æ•°æ®
        target_cols : list, optional
            æœªæ¥æ”¶ç›Šç‡åˆ—ååˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨æ£€æµ‹
        label_type : str, default='binary'
            æ ‡ç­¾ç±»å‹: 'binary'(æ¶¨è·Œ) æˆ– 'quantile'(åˆ†ä½æ•°)
        quantiles : list, optional
            åˆ†ä½æ•°é˜ˆå€¼ï¼Œç”¨äºquantileç±»å‹ï¼Œé»˜è®¤ä¸º[0.2, 0.8]
            
        Returns:
        --------
        pd.DataFrame
            åŒ…å«åˆ†ç±»æ ‡ç­¾çš„æ•°æ®
        """
        print("ğŸ·ï¸ ç”Ÿæˆåˆ†ç±»æ ‡ç­¾...")
        
        result_df = data.copy()
        
        # è‡ªåŠ¨æ£€æµ‹æœªæ¥æ”¶ç›Šç‡åˆ—
        if target_cols is None:
            target_cols = [col for col in data.columns if col.startswith('future_return_')]
        
        if not target_cols:
            raise ValueError("æœªæ‰¾åˆ°æœªæ¥æ”¶ç›Šç‡åˆ—ï¼Œè¯·å…ˆç”Ÿæˆæœªæ¥æ”¶ç›Šç‡")
        
        print(f"   ğŸ¯ ä¸º {len(target_cols)} ä¸ªç›®æ ‡ç”Ÿæˆ {label_type} æ ‡ç­¾")
        
        if label_type == 'binary':
            # äºŒåˆ†ç±»ï¼šæ¶¨(1) è·Œ(0)
            for col in target_cols:
                label_col = col.replace('future_return_', 'label_binary_')
                result_df[label_col] = (result_df[col] > 0).astype(float)
                
                # ç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ
                valid_labels = result_df[label_col].notna()
                if valid_labels.sum() > 0:
                    up_ratio = (result_df.loc[valid_labels, label_col] == 1).mean()
                    print(f"   ğŸ“Š {label_col}: ä¸Šæ¶¨æ¯”ä¾‹ {up_ratio:.2%}")
        
        elif label_type == 'quantile':
            # åˆ†ä½æ•°åˆ†ç±»
            if quantiles is None:
                quantiles = [0.2, 0.8]  # é»˜è®¤åˆ†ä¸º3ç±»ï¼šä½20%ï¼Œä¸­é—´60%ï¼Œé«˜20%
            
            for col in target_cols:
                label_col = col.replace('future_return_', 'label_quantile_')
                
                # è®¡ç®—åˆ†ä½æ•°é˜ˆå€¼ï¼ˆåªä½¿ç”¨æœ‰æ•ˆæ•°æ®ï¼‰
                valid_data = result_df[col].dropna()
                if len(valid_data) == 0:
                    print(f"   âš ï¸ {col} æ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œè·³è¿‡åˆ†ä½æ•°æ ‡ç­¾ç”Ÿæˆ")
                    continue
                
                thresholds = [valid_data.quantile(q) for q in quantiles]
                
                # ç”Ÿæˆåˆ†ä½æ•°æ ‡ç­¾
                labels = pd.cut(result_df[col], 
                              bins=[-np.inf] + thresholds + [np.inf], 
                              labels=list(range(len(quantiles) + 1)),
                              include_lowest=True).astype(float)
                
                result_df[label_col] = labels
                
                # ç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ
                valid_labels = result_df[label_col].notna()
                if valid_labels.sum() > 0:
                    label_counts = result_df.loc[valid_labels, label_col].value_counts().sort_index()
                    print(f"   ğŸ“Š {label_col} åˆ†å¸ƒ: {dict(label_counts)}")
        
        else:
            raise ValueError("label_type å¿…é¡»æ˜¯ 'binary' æˆ– 'quantile'")
        
        print(f"âœ… åˆ†ç±»æ ‡ç­¾ç”Ÿæˆå®Œæˆ")
        return result_df

    def create_complete_dataset(self, features_df: pd.DataFrame,
                               periods: List[int] = [1, 5, 10],
                               price_col: str = 'close',
                               include_labels: bool = True,
                               label_types: List[str] = ['binary']) -> pd.DataFrame:
        """
        åˆ›å»ºåŒ…å«ç‰¹å¾å’Œç›®æ ‡çš„å®Œæ•´æ•°æ®é›†
        
        Parameters:
        -----------
        features_df : pd.DataFrame
            ç‰¹å¾æ•°æ®ï¼ˆæ¥è‡ªç‰¹å¾å·¥ç¨‹ï¼‰
        periods : list, default=[1, 5, 10]
            æœªæ¥æ”¶ç›Šç‡æ—¶é—´çª—å£
        price_col : str, default='close'
            ä»·æ ¼åˆ—å
        include_labels : bool, default=True
            æ˜¯å¦åŒ…å«åˆ†ç±»æ ‡ç­¾
        label_types : list, default=['binary']
            æ ‡ç­¾ç±»å‹åˆ—è¡¨
            
        Returns:
        --------
        pd.DataFrame
            å®Œæ•´çš„æœºå™¨å­¦ä¹ æ•°æ®é›†
        """
        print("ğŸ”¨ åˆ›å»ºå®Œæ•´æ•°æ®é›†...")
        
        # 1. ç”Ÿæˆæœªæ¥æ”¶ç›Šç‡
        complete_df = self.generate_future_returns(features_df, periods, price_col)
        
        # 2. ç”Ÿæˆåˆ†ç±»æ ‡ç­¾ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if include_labels:
            for label_type in label_types:
                complete_df = self.generate_classification_labels(
                    complete_df, 
                    label_type=label_type
                )
        
        # 3. æ•°æ®è´¨é‡ç»Ÿè®¡
        self._print_dataset_summary(complete_df, periods)
        
        return complete_df
    
    def save_dataset(self, data: pd.DataFrame, symbol: str, 
                     suffix: str = "") -> str:
        """
        ä¿å­˜å®Œæ•´æ•°æ®é›†åˆ°CSVæ–‡ä»¶
        
        Parameters:
        -----------
        data : pd.DataFrame
            è¦ä¿å­˜çš„æ•°æ®
        symbol : str
            è‚¡ç¥¨ä»£ç 
        suffix : str, optional
            æ–‡ä»¶ååç¼€
            
        Returns:
        --------
        str
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        print("ğŸ’¾ ä¿å­˜æ•°æ®é›†...")
        
        # æ„å»ºæ–‡ä»¶å
        if suffix:
            filename = f"with_targets_{symbol}_{suffix}.csv"
        else:
            filename = f"with_targets_{symbol}.csv"
        
        filepath = os.path.join(self.data_dir, filename)
        
        # ä¿å­˜æ•°æ®
        data.to_csv(filepath, index=True, encoding='utf-8-sig')
        
        file_size = os.path.getsize(filepath) / 1024 / 1024  # MB
        print(f"âœ… æ•°æ®é›†å·²ä¿å­˜: {filename}")
        print(f"   ğŸ“ è·¯å¾„: {filepath}")
        print(f"   ğŸ“Š å¤§å°: {file_size:.2f} MB")
        print(f"   ğŸ”¢ å½¢çŠ¶: {data.shape}")
        
        return filepath
    
    def _verify_future_returns(self, data: pd.DataFrame, periods: List[int]):
        """éªŒè¯æœªæ¥æ”¶ç›Šç‡çš„æ­£ç¡®æ€§ï¼ˆé˜²æ­¢æ•°æ®æ³„æ¼ï¼‰"""
        print("\nğŸ” éªŒè¯ç›®æ ‡å˜é‡æ­£ç¡®æ€§...")
        
        for period in periods:
            target_col = f'future_return_{period}d'
            if target_col not in data.columns:
                continue
                
            # æ£€æŸ¥å°¾éƒ¨NaN
            total_rows = len(data)
            nan_count = data[target_col].isna().sum()
            
            # å°¾éƒ¨åº”è¯¥æœ‰periodè¡ŒNaN
            tail_nans = data[target_col].tail(period).isna().sum()
            
            print(f"   ğŸ“Š {target_col}:")
            print(f"      æ€»NaNæ•°: {nan_count}")
            print(f"      å°¾éƒ¨{period}è¡ŒNaN: {tail_nans}/{period}")
            
            if tail_nans != period:
                print(f"      âš ï¸ è­¦å‘Š: å°¾éƒ¨NaNæ•°é‡ä¸åŒ¹é…é¢„æœŸ")
            
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†æ­£ç¡®çš„shiftï¼ˆä¸åº”è¯¥æœ‰è´Ÿshiftæ³„æ¼ï¼‰
            # è¿™é‡Œæˆ‘ä»¬éªŒè¯ç¬¬ä¸€ä¸ªéNaNå€¼çš„ä½ç½®
            first_valid = data[target_col].first_valid_index()
            last_valid = data[target_col].last_valid_index()
            
            if first_valid is not None and last_valid is not None:
                valid_count = data[target_col].notna().sum()
                expected_valid = total_rows - period
                
                if valid_count == expected_valid:
                    print(f"      âœ… æ•°æ®æ³„æ¼æ£€æŸ¥é€šè¿‡")
                else:
                    print(f"      âš ï¸ æœ‰æ•ˆæ•°æ®é‡å¼‚å¸¸: {valid_count} vs æœŸæœ› {expected_valid}")

    def _print_dataset_summary(self, data: pd.DataFrame, periods: List[int]):
        """æ‰“å°æ•°æ®é›†æ‘˜è¦"""
        print("\nğŸ“‹ æ•°æ®é›†æ‘˜è¦:")
        print("=" * 50)
        
        # åŸºæœ¬ä¿¡æ¯
        print(f"ğŸ“Š æ•°æ®å½¢çŠ¶: {data.shape}")
        print(f"ğŸ“… æ—¶é—´èŒƒå›´: {data.index.min().date()} ~ {data.index.max().date()}")
        
        # ç‰¹å¾åˆ—ç»Ÿè®¡
        feature_cols = [col for col in data.columns 
                       if not col.startswith('future_return_') 
                       and not col.startswith('label_')]
        target_cols = [col for col in data.columns if col.startswith('future_return_')]
        label_cols = [col for col in data.columns if col.startswith('label_')]
        
        print(f"ğŸ”¢ ç‰¹å¾æ•°é‡: {len(feature_cols)}")
        print(f"ğŸ¯ ç›®æ ‡æ•°é‡: {len(target_cols)}")
        print(f"ğŸ·ï¸ æ ‡ç­¾æ•°é‡: {len(label_cols)}")
        
        # ç›®æ ‡å˜é‡ç»Ÿè®¡
        if target_cols:
            print("\nğŸ“ˆ ç›®æ ‡å˜é‡ç»Ÿè®¡:")
            for col in target_cols:
                valid_count = data[col].notna().sum()
                mean_return = data[col].mean()
                std_return = data[col].std()
                print(f"   {col}: æœ‰æ•ˆæ ·æœ¬ {valid_count}, å‡å€¼ {mean_return:.4f}, æ ‡å‡†å·® {std_return:.4f}")
        
        # è®­ç»ƒæ ·æœ¬ä¼°ç®—ï¼ˆæ’é™¤å°¾éƒ¨NaNï¼‰
        if periods:
            max_period = max(periods)
            trainable_samples = len(data) - max_period
            print(f"\nğŸ“ ä¼°ç®—å¯è®­ç»ƒæ ·æœ¬: {trainable_samples} (æ’é™¤å°¾éƒ¨{max_period}è¡Œ)")
        
        print("=" * 50)


def main():
    """
    ç¤ºä¾‹ç”¨æ³• - æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ç›®æ ‡å·¥ç¨‹å™¨
    """
    print("ğŸ¯ ç›®æ ‡å·¥ç¨‹ç¤ºä¾‹")
    print("=" * 50)
    
    try:
        # åˆå§‹åŒ–ç›®æ ‡å·¥ç¨‹å™¨
        target_engineer = TargetEngineer()
        
        # è¿™é‡Œéœ€è¦ä»ç‰¹å¾å·¥ç¨‹è·å–æ•°æ®
        # ç¤ºä¾‹ï¼šå‡è®¾å·²æœ‰ç‰¹å¾æ•°æ®
        print("âš ï¸ è¿™æ˜¯ç¤ºä¾‹ä»£ç ï¼Œéœ€è¦å®é™…çš„ç‰¹å¾æ•°æ®")
        print("è¯·ä» FeatureEngineer è·å–ç‰¹å¾æ•°æ®åè°ƒç”¨:")
        print()
        print("# ç¤ºä¾‹ç”¨æ³•:")
        print("from feature_engineering import FeatureEngineer")
        print("from target_engineering import TargetEngineer")
        print()
        print("# 1. è·å–ç‰¹å¾æ•°æ®")
        print("engineer = FeatureEngineer()")
        print("data = engineer.load_stock_data('000001', '2023-01-01', '2024-12-31')")
        print("features_df = engineer.prepare_features(data)")
        print()
        print("# 2. ç”Ÿæˆç›®æ ‡å˜é‡")
        print("target_engineer = TargetEngineer()")
        print("complete_df = target_engineer.create_complete_dataset(")
        print("    features_df, ")
        print("    periods=[1, 5, 10],")
        print("    include_labels=True,")
        print("    label_types=['binary', 'quantile']")
        print(")")
        print()
        print("# 3. ä¿å­˜æ•°æ®é›†")
        print("filepath = target_engineer.save_dataset(complete_df, '000001')")
        print("print(f'æ•°æ®é›†å·²ä¿å­˜åˆ°: {filepath}')")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        raise


if __name__ == "__main__":
    main()
