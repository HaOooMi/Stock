#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç­–ç•¥ä¿¡å·ä¸å›æµ‹æ¨¡å—ï¼ˆä½¿ç”¨ç‹¬ç«‹InfluxDBæ•°æ®+å·²è®­ç»ƒPCAæ¨¡å‹ï¼Œé¿å…æ•°æ®æ³„æ¼ï¼‰

åŠŸèƒ½ï¼š
1. åŸºäºèšç±»åˆ†æç»“æœé€‰æ‹©æœ€ä½³ç°‡
2. ä»InfluxDBè·å–å®Œå…¨ç‹¬ç«‹çš„æ–°æ•°æ®è¿›è¡Œäº¤æ˜“ä¿¡å·ç”Ÿæˆï¼ˆsignal=1/0ï¼‰
3. ä½¿ç”¨å·²è®­ç»ƒçš„PCAæ¨¡å‹å¯¹æ–°æ•°æ®è¿›è¡Œé™ç»´
4. è®¡ç®—ç­–ç•¥æ”¶ç›Š vs åŸºå‡†
5. ç­–ç•¥æ€§èƒ½è¯„ä¼°å’Œå¯è§†åŒ–
6. éšæœºåŸºå‡†å¯¹æ¯”éªŒè¯

æ•°æ®æµï¼šInfluxDBæ–°æ•°æ® â†’ PCAå®Œæ•´æµç¨‹ â†’ èšç±»é¢„æµ‹ â†’ ç­–ç•¥å›æµ‹
ç¡®ä¿æµ‹è¯•æ•°æ®å®Œå…¨ç‹¬ç«‹ï¼Œç¬¦åˆå®é™…åº”ç”¨åœºæ™¯
"""

import os
import sys
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Union
from datetime import datetime, timedelta
import pickle
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
if project_root not in sys.path:
    sys.path.append(project_root)

# å¯¼å…¥é¡¹ç›®æ¨¡å—
try:
    from pca_state import PCAStateGenerator
    # InfluxDBåŠ è½½å™¨å¯èƒ½éœ€è¦æ ¹æ®å®é™…é¡¹ç›®ç»“æ„è°ƒæ•´
    # from data_integration.influxdb_loader import InfluxDBLoader
    print("âœ… æˆåŠŸå¯¼å…¥PCAæ¨¡å—")
except ImportError as e:
    print(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿é¡¹ç›®ç»“æ„æ­£ç¡®ä¸”ä¾èµ–æ¨¡å—å­˜åœ¨")
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œç»§ç»­è¿è¡Œä½†åŠŸèƒ½å—é™
    PCAStateGenerator = None

# é…ç½®æ—¥å¿—
import logging
logger = logging.getLogger(__name__)

class StrategyBacktestClean:
    """
    ç­–ç•¥å›æµ‹æ¨¡å— - ä½¿ç”¨PCAå®Œæ•´æµç¨‹å’Œç‹¬ç«‹æ•°æ®æº
    """
    
    def __init__(self, project_root: str = None):
        """
        åˆå§‹åŒ–ç­–ç•¥å›æµ‹å™¨
        
        Parameters:
        -----------
        project_root : str
            é¡¹ç›®æ ¹ç›®å½•è·¯å¾„
        """
        self.project_root = project_root or os.path.dirname(os.path.dirname(__file__))
        # self.influxdb_loader = InfluxDBLoader()  # æš‚æ—¶æ³¨é‡Šï¼Œæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
        self.cluster_models = {}
        self.best_clusters = {}
        
        print("ğŸ¯ ç­–ç•¥å›æµ‹æ¨¡å—åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")

    def load_cluster_analysis_results(self, symbol: str = "000001") -> Dict:
        """
        åŠ è½½èšç±»åˆ†æçš„ç»“æœï¼Œç”¨äºç­–ç•¥å›æµ‹
        
        Parameters:
        -----------
        symbol : str
            è‚¡ç¥¨ä»£ç 
            
        Returns:
        --------
        dict
            èšç±»åˆ†æç»“æœ
        """
        print(f"ğŸ“Š åŠ è½½èšç±»åˆ†æç»“æœ: {symbol}")
        
        # æŸ¥æ‰¾èšç±»æ¨¡å‹æ–‡ä»¶
        cluster_dir = os.path.join(self.project_root, "machine learning/ML output/models")
        
        if not os.path.exists(cluster_dir):
            raise FileNotFoundError(f"èšç±»æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {cluster_dir}")
        
        # åŠ è½½èšç±»æ¨¡å‹
        cluster_files = [f for f in os.listdir(cluster_dir) 
                        if f.startswith(f'kmeans_{symbol}_') and f.endswith('.pkl')]
        
        if not cluster_files:
            raise FileNotFoundError(f"æœªæ‰¾åˆ°è‚¡ç¥¨ {symbol} çš„èšç±»æ¨¡å‹æ–‡ä»¶")
        
        for cluster_file in cluster_files:
            # æå–kå€¼
            k_value = int(cluster_file.split('_k')[1].split('_')[0])
            model_path = os.path.join(cluster_dir, cluster_file)
            
            with open(model_path, 'rb') as f:
                cluster_data = pickle.load(f)
                self.cluster_models[k_value] = cluster_data
        
        # ä»cluster_evaluate.pyçš„ç»“æœä¸­é€‰æ‹©æœ€ä½³kå€¼
        evaluate_results_path = os.path.join(self.project_root, "machine learning/ML output/cluster_evaluation_results.csv")
        
        if os.path.exists(evaluate_results_path):
            eval_results = pd.read_csv(evaluate_results_path)
            # å‡è®¾æŒ‰ç»¼åˆè¯„åˆ†é€‰æ‹©æœ€ä½³kï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®å®é™…è¯„ä¼°æ ‡å‡†è°ƒæ•´ï¼‰
            best_k = eval_results.loc[eval_results['silhouette_score'].idxmax(), 'k']
            self.best_clusters[symbol] = int(best_k)
        else:
            # å¦‚æœæ²¡æœ‰è¯„ä¼°ç»“æœï¼Œä½¿ç”¨é»˜è®¤çš„æœ€ä½³kå€¼
            self.best_clusters[symbol] = min(self.cluster_models.keys())
        
        print(f"   âœ… åŠ è½½å®Œæˆï¼Œæ‰¾åˆ° {len(self.cluster_models)} ä¸ªèšç±»æ¨¡å‹")
        print(f"   ğŸ¯ æœ€ä½³kå€¼: {self.best_clusters[symbol]}")
        
        return {
            'models': self.cluster_models,
            'best_clusters': self.best_clusters
        }

    def load_independent_test_data(self, symbol: str = "000001", 
                                  test_days: int = 60) -> Tuple[pd.DataFrame, Dict]:
        """
        ä½¿ç”¨PCAæ¨¡å—å®Œæ•´æµç¨‹ç”Ÿæˆç‹¬ç«‹æµ‹è¯•æ•°æ®
        
        Parameters:
        -----------
        symbol : str
            è‚¡ç¥¨ä»£ç 
        test_days : int
            æµ‹è¯•æ•°æ®å¤©æ•°ï¼ˆä»å½“å‰æ—¥æœŸå¾€å‰æ¨ï¼‰
            
        Returns:
        --------
        tuple
            (é™ç»´åçš„æµ‹è¯•æ•°æ®DataFrame, PCAç›¸å…³ä¿¡æ¯å­—å…¸)
        """
        print(f"ğŸŒ ä½¿ç”¨PCAæ¨¡å—å®Œæ•´æµç¨‹åŠ è½½{test_days}å¤©ç‹¬ç«‹æµ‹è¯•æ•°æ®...")
        
        try:
            # ä½¿ç”¨PCAæ¨¡å—çš„å®Œæ•´æµç¨‹ç”Ÿæˆæµ‹è¯•æ•°æ®
            pca_generator = PCAStateGenerator()
            
            # 1. è¿è¡Œå®Œæ•´çš„ç‰¹å¾å·¥ç¨‹æµç¨‹
            print(f"   ğŸ”§ è¿è¡Œå®Œæ•´ç‰¹å¾å·¥ç¨‹æµç¨‹...")
            features_df = pca_generator.run_complete_feature_pipeline(
                symbol=symbol,
                data_source="influxdb_new",  # ä½¿ç”¨ç‹¬ç«‹çš„InfluxDBæ–°æ•°æ®
                sample_days=test_days + 100  # å¤šå–ä¸€äº›æ•°æ®ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ ·æœ¬
            )
            
            if features_df is None or features_df.empty:
                raise ValueError(f"PCAç‰¹å¾å·¥ç¨‹æµç¨‹å¤±è´¥ï¼š{symbol}")
            
            print(f"   ğŸ“Š ç‰¹å¾å·¥ç¨‹å®Œæˆ: {features_df.shape}")
            
            # 2. è¿è¡Œå®Œæ•´çš„ç›®æ ‡å˜é‡æµç¨‹
            print(f"   ğŸ¯ è¿è¡Œå®Œæ•´ç›®æ ‡å˜é‡æµç¨‹...")
            targets_df = pca_generator.run_complete_target_pipeline(
                features_df=features_df,
                symbol=symbol
            )
            
            if targets_df is None or targets_df.empty:
                raise ValueError(f"PCAç›®æ ‡å˜é‡æµç¨‹å¤±è´¥ï¼š{symbol}")
            
            print(f"   ğŸ“ˆ ç›®æ ‡å˜é‡ç”Ÿæˆå®Œæˆ: {targets_df.shape}")
            
            # 3. å–æœ€è¿‘çš„test_dayså¤©æ•°æ®ä½œä¸ºæµ‹è¯•é›†
            test_data = targets_df.tail(test_days).copy()
            
            if len(test_data) < test_days:
                print(f"   âš ï¸ å®é™…æµ‹è¯•æ•°æ®åªæœ‰ {len(test_data)} å¤©ï¼Œå°‘äºè¦æ±‚çš„ {test_days} å¤©")
            
            # 4. æ„å»ºPCAä¿¡æ¯
            pca_info = {
                'data_source': 'influxdb_new_via_pca_module',
                'sample_days': test_days + 100,
                'actual_test_days': len(test_data),
                'features_shape': features_df.shape,
                'targets_shape': targets_df.shape,
                'pca_pipeline': 'complete'
            }
            
            print(f"   âœ… PCAæ¨¡å—å®Œæ•´æµç¨‹æ‰§è¡ŒæˆåŠŸ:")
            print(f"   ğŸ“Š æµ‹è¯•æ ·æœ¬: {len(test_data)}")
            print(f"   ğŸ¯ ç‰¹å¾åˆ—æ•°: {test_data.shape[1]}")
            print(f"   ğŸ”— æ•°æ®æ¥æº: InfluxDBæ–°æ•°æ® (via PCAæ¨¡å—)")
            
            return test_data, pca_info
            
        except Exception as e:
            print(f"âŒ PCAæ¨¡å—å®Œæ•´æµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
            raise

    def generate_signals_from_pca(self, selected_k: int, 
                                   symbol: str = "000001") -> pd.DataFrame:
        """
        åŸºäºPCAæµ‹è¯•æ•°æ®ç”Ÿæˆäº¤æ˜“ä¿¡å·
        
        Parameters:
        -----------
        selected_k : int
            é€‰æ‹©çš„kå€¼
        symbol : str
            è‚¡ç¥¨ä»£ç 
            
        Returns:
        --------
        pd.DataFrame
            åŒ…å«äº¤æ˜“ä¿¡å·çš„æ•°æ®æ¡†
        """
        print(f"ğŸ“¡ ä½¿ç”¨k={selected_k}ç”Ÿæˆäº¤æ˜“ä¿¡å·...")
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        test_data, pca_info = self.load_independent_test_data(symbol)
        
        if test_data is None or test_data.empty:
            raise ValueError("æµ‹è¯•æ•°æ®ä¸ºç©º")
        
        # è·å–PCAç‰¹å¾åˆ—ï¼ˆæ’é™¤ä»·æ ¼å’Œç›®æ ‡å˜é‡ï¼‰
        pca_columns = [col for col in test_data.columns 
                      if col.startswith('PC') and col[2:].isdigit()]
        
        if not pca_columns:
            raise ValueError("æœªæ‰¾åˆ°PCAç‰¹å¾åˆ—")
        
        # ä½¿ç”¨å¯¹åº”çš„èšç±»æ¨¡å‹è¿›è¡Œé¢„æµ‹
        if selected_k not in self.cluster_models:
            raise ValueError(f"æœªæ‰¾åˆ°k={selected_k}çš„èšç±»æ¨¡å‹")
        
        cluster_model = self.cluster_models[selected_k]['model']
        X_pca = test_data[pca_columns].values
        
        # ç”Ÿæˆèšç±»é¢„æµ‹
        cluster_labels = cluster_model.predict(X_pca)
        
        # åŸºäºèšç±»ç»“æœç”Ÿæˆäº¤æ˜“ä¿¡å·
        # ç­–ç•¥é€»è¾‘ï¼šç‰¹å®šç°‡æ ‡è®°ä¸ºä¹°å…¥ä¿¡å·ï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®å®é™…åˆ†æè°ƒæ•´ï¼‰
        target_clusters = self._identify_profitable_clusters(selected_k, test_data)
        signals = np.where(np.isin(cluster_labels, target_clusters), 1, 0)
        
        # åˆ›å»ºç»“æœDataFrame
        result_df = test_data.copy()
        result_df['cluster'] = cluster_labels
        result_df['signal'] = signals
        result_df['strategy_position'] = signals.astype(int)
        
        signal_stats = {
            'total_signals': len(signals),
            'buy_signals': np.sum(signals),
            'signal_rate': np.mean(signals),
            'target_clusters': target_clusters
        }
        
        print(f"   âœ… ä¿¡å·ç”Ÿæˆå®Œæˆ:")
        print(f"   ğŸ“Š æ€»æ ·æœ¬: {signal_stats['total_signals']}")
        print(f"   ğŸ“ˆ ä¹°å…¥ä¿¡å·: {signal_stats['buy_signals']}")
        print(f"   ğŸ“‰ ä¿¡å·ç‡: {signal_stats['signal_rate']:.2%}")
        print(f"   ğŸ¯ ç›®æ ‡ç°‡: {target_clusters}")
        
        return result_df
    
    def _identify_profitable_clusters(self, k: int, test_data: pd.DataFrame) -> List[int]:
        """
        è¯†åˆ«ç›ˆåˆ©çš„èšç±»ç°‡ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…éœ€è¦åŸºäºå†å²æ•°æ®åˆ†æï¼‰
        
        Parameters:
        -----------
        k : int
            èšç±»æ•°é‡
        test_data : pd.DataFrame
            æµ‹è¯•æ•°æ®
            
        Returns:
        --------
        List[int]
            ç›ˆåˆ©ç°‡çš„æ ‡ç­¾åˆ—è¡¨
        """
        # è¿™é‡Œæ˜¯ç®€åŒ–é€»è¾‘ï¼Œå®é™…åº”è¯¥åŸºäºå†å²å›æµ‹ç»“æœ
        # å‡è®¾é€‰æ‹©èšç±»ä¸­å¿ƒè¾ƒé«˜çš„ç°‡ä½œä¸ºä¹°å…¥ä¿¡å·
        if k == 4:
            return [1, 2]  # å‡è®¾ç°‡1å’Œç°‡2è¡¨ç°è¾ƒå¥½
        elif k == 5:
            return [1, 3]  # å‡è®¾ç°‡1å’Œç°‡3è¡¨ç°è¾ƒå¥½
        elif k == 6:
            return [2, 4]  # å‡è®¾ç°‡2å’Œç°‡4è¡¨ç°è¾ƒå¥½
        else:
            return [1]  # é»˜è®¤é€‰æ‹©ç°‡1

    def calculate_strategy_returns(self, signal_data: pd.DataFrame) -> Dict:
        """
        è®¡ç®—ç­–ç•¥æ”¶ç›Šç‡
        
        Parameters:
        -----------
        signal_data : pd.DataFrame
            åŒ…å«ä¿¡å·çš„æ•°æ®
            
        Returns:
        --------
        Dict
            ç­–ç•¥æ”¶ç›Šç»Ÿè®¡
        """
        print("ğŸ’° è®¡ç®—ç­–ç•¥æ”¶ç›Š...")
        
        # å‡è®¾æœ‰æ”¶ç›˜ä»·åˆ—
        if 'close' not in signal_data.columns:
            raise ValueError("æ•°æ®ä¸­ç¼ºå°‘æ”¶ç›˜ä»·ä¿¡æ¯")
        
        # è®¡ç®—æ—¥æ”¶ç›Šç‡
        signal_data['daily_return'] = signal_data['close'].pct_change()
        
        # è®¡ç®—ç­–ç•¥æ”¶ç›Šï¼ˆæŒä»“æ—¶è·å¾—æ”¶ç›Šï¼Œå¦åˆ™æ”¶ç›Šä¸º0ï¼‰
        signal_data['strategy_return'] = signal_data['daily_return'] * signal_data['strategy_position'].shift(1)
        
        # è®¡ç®—ç´¯è®¡æ”¶ç›Š
        signal_data['cumulative_return'] = (1 + signal_data['daily_return']).cumprod() - 1
        signal_data['strategy_cumulative'] = (1 + signal_data['strategy_return']).cumprod() - 1
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        total_return = signal_data['strategy_cumulative'].iloc[-1]
        benchmark_return = signal_data['cumulative_return'].iloc[-1]
        
        # è®¡ç®—å¤æ™®æ¯”ç‡ï¼ˆç®€åŒ–ç‰ˆï¼‰
        strategy_std = signal_data['strategy_return'].std()
        sharpe_ratio = signal_data['strategy_return'].mean() / strategy_std if strategy_std > 0 else 0
        
        # æœ€å¤§å›æ’¤
        rolling_max = signal_data['strategy_cumulative'].expanding().max()
        drawdown = (signal_data['strategy_cumulative'] - rolling_max) / rolling_max
        max_drawdown = drawdown.min()
        
        performance = {
            'total_return': total_return,
            'benchmark_return': benchmark_return,
            'excess_return': total_return - benchmark_return,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_drawdown,
            'win_rate': len(signal_data[signal_data['strategy_return'] > 0]) / len(signal_data[signal_data['strategy_return'] != 0])
        }
        
        print(f"   âœ… ç­–ç•¥æ”¶ç›Šè®¡ç®—å®Œæˆ:")
        print(f"   ğŸ“ˆ ç­–ç•¥æ€»æ”¶ç›Š: {performance['total_return']:.2%}")
        print(f"   ğŸ“Š åŸºå‡†æ”¶ç›Š: {performance['benchmark_return']:.2%}")
        print(f"   ğŸ¯ è¶…é¢æ”¶ç›Š: {performance['excess_return']:.2%}")
        print(f"   ğŸ“‰ æœ€å¤§å›æ’¤: {performance['max_drawdown']:.2%}")
        print(f"   ğŸ² èƒœç‡: {performance['win_rate']:.2%}")
        
        return performance

    def run_strategy_backtest(self, symbol: str = "000001", test_days: int = 60) -> Dict:
        """
        è¿è¡Œå®Œæ•´çš„ç­–ç•¥å›æµ‹
        
        Parameters:
        -----------
        symbol : str
            è‚¡ç¥¨ä»£ç 
        test_days : int
            æµ‹è¯•å¤©æ•°
            
        Returns:
        --------
        Dict
            å®Œæ•´çš„å›æµ‹ç»“æœ
        """
        print(f"ğŸš€ å¼€å§‹ç­–ç•¥å›æµ‹: {symbol}")
        print("=" * 60)
        
        try:
            # 1. åŠ è½½èšç±»åˆ†æç»“æœ
            cluster_results = self.load_cluster_analysis_results(symbol)
            
            # 2. è·å–æœ€ä½³kå€¼
            best_k = self.best_clusters[symbol]
            
            # 3. ç”Ÿæˆäº¤æ˜“ä¿¡å·
            signal_data = self.generate_signals_from_pca(best_k, symbol)
            
            # 4. è®¡ç®—ç­–ç•¥æ”¶ç›Š
            performance = self.calculate_strategy_returns(signal_data)
            
            # 5. æ•´åˆç»“æœ
            backtest_results = {
                'symbol': symbol,
                'test_period': test_days,
                'best_k': best_k,
                'signal_data': signal_data,
                'performance': performance,
                'cluster_results': cluster_results
            }
            
            print("=" * 60)
            print(f"âœ… ç­–ç•¥å›æµ‹å®Œæˆ: {symbol}")
            print(f"ğŸ“Š æœ€ä½³èšç±»æ•°: k={best_k}")
            print(f"ğŸ’° ç­–ç•¥è¡¨ç°: {performance['total_return']:.2%} vs åŸºå‡† {performance['benchmark_return']:.2%}")
            
            return backtest_results
            
        except Exception as e:
            print(f"âŒ ç­–ç•¥å›æµ‹å¤±è´¥: {e}")
            raise

    def compare_random_baseline(self, signal_data: pd.DataFrame, n_simulations: int = 100) -> Dict:
        """
        ä¸éšæœºåŸºå‡†è¿›è¡Œå¯¹æ¯”
        
        Parameters:
        -----------
        signal_data : pd.DataFrame
            ç­–ç•¥ä¿¡å·æ•°æ®
        n_simulations : int
            éšæœºæ¨¡æ‹Ÿæ¬¡æ•°
            
        Returns:
        --------
        Dict
            éšæœºåŸºå‡†å¯¹æ¯”ç»“æœ
        """
        print(f"ğŸ² è¿›è¡ŒéšæœºåŸºå‡†å¯¹æ¯” (æ¨¡æ‹Ÿ{n_simulations}æ¬¡)...")
        
        daily_returns = signal_data['daily_return'].dropna()
        signal_count = signal_data['signal'].sum()
        
        random_returns = []
        
        for i in range(n_simulations):
            # ç”Ÿæˆéšæœºä¿¡å·ï¼ˆä¿æŒç›¸åŒçš„ä¿¡å·å¯†åº¦ï¼‰
            random_signals = np.random.choice([0, 1], size=len(signal_data), 
                                            p=[1-signal_count/len(signal_data), signal_count/len(signal_data)])
            
            # è®¡ç®—éšæœºç­–ç•¥æ”¶ç›Š
            random_strategy_return = daily_returns * pd.Series(random_signals[1:])  # shift(1)çš„æ•ˆæœ
            random_cumulative = (1 + random_strategy_return).cumprod().iloc[-1] - 1
            random_returns.append(random_cumulative)
        
        random_returns = np.array(random_returns)
        strategy_return = signal_data['strategy_cumulative'].iloc[-1]
        
        baseline_stats = {
            'random_mean': np.mean(random_returns),
            'random_std': np.std(random_returns),
            'strategy_return': strategy_return,
            'percentile': (random_returns < strategy_return).mean() * 100,
            'outperform_prob': (random_returns < strategy_return).mean()
        }
        
        print(f"   âœ… éšæœºåŸºå‡†å¯¹æ¯”å®Œæˆ:")
        print(f"   ğŸ² éšæœºç­–ç•¥å¹³å‡æ”¶ç›Š: {baseline_stats['random_mean']:.2%}")
        print(f"   ğŸ“Š æˆ‘ä»¬çš„ç­–ç•¥æ”¶ç›Š: {baseline_stats['strategy_return']:.2%}")
        print(f"   ğŸ† è¶…è¶ŠéšæœºåŸºå‡†æ¦‚ç‡: {baseline_stats['outperform_prob']:.1%}")
        print(f"   ğŸ“ˆ æ”¶ç›Šç™¾åˆ†ä½: {baseline_stats['percentile']:.1f}%")
        
        return baseline_stats


def main():
    """
    ä¸»å‡½æ•° - è¿è¡Œç­–ç•¥å›æµ‹ç¤ºä¾‹
    """
    print("ğŸ¯ ç­–ç•¥å›æµ‹æ¨¡å—æµ‹è¯•")
    print("=" * 60)
    
    try:
        # åˆå§‹åŒ–å›æµ‹å™¨
        backtest = StrategyBacktestClean()
        
        # è¿è¡Œç­–ç•¥å›æµ‹
        results = backtest.run_strategy_backtest(
            symbol="000001",
            test_days=60
        )
        
        # éšæœºåŸºå‡†å¯¹æ¯”
        baseline_comparison = backtest.compare_random_baseline(
            results['signal_data'],
            n_simulations=100
        )
        
        print("\nğŸ‰ å›æµ‹å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ å›æµ‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()